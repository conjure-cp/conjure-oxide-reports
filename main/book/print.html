<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Conjure Oxide</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "coal";
            window.path_to_searchindex_js = "searchindex-78c1d72e.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-b9ef563d.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Conjure Oxide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="conjure-oxide"><a class="header" href="#conjure-oxide">Conjure Oxide</a></h1>
<p>Welcome to the documentation of Conjure Oxide, a next generation constraints
modelling tool written in Rust. It supports models written in the Essence and
Essence Prime constraints modelling languages.</p>
<p>Conjure Oxide is in the early stages of development, so most Essence language
features are not supported yet. However, it does currently support most of
Essence Prime.</p>
<p>This site contains the user documentation for Conjure Oxide; other useful links can be found on the <a href="#useful-links">useful links</a> page.</p>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>The project is primarily developed by students and staff at the University of
St Andrews, but we also welcome outside contributors; for more information see the
<a href="#contributors-guide">contributor’s guide</a>.</p>
<!-- original link: https://github.com/conjure-cp/conjure-oxide/blob/main/CONTRIBUTING.md -->
<h2 id="licence"><a class="header" href="#licence">Licence</a></h2>
<p>The Conjure Oxide source and documentation are released under the <a href="https://github.com/conjure-cp/conjure-oxide/blob/main/LICENSE">Mozilla Public Licence v2.0</a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>To install Conjure Oxide, either <a href="#installation">build it from source</a>, or use a <a href="#installation">nightly release</a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="quick-start-guide-to-running-your-first-essence-model"><a class="header" href="#quick-start-guide-to-running-your-first-essence-model">Quick Start Guide to Running your first Essence Model</a></h1>
<p>This guide walks you through running your first Essence model with Conjure Oxide.</p>
<h2 id="your-first-problem"><a class="header" href="#your-first-problem">Your First Problem</a></h2>
<p>Create a file called <code>my_problem.essence</code> with the following content:</p>
<pre><code class="language-essence">find x : int(1..3)
find y : int(2..5)

such that x &gt; y
</code></pre>
<p>If you are curious about more complex models, you can check out the models that we use to test Conjure Oxide, available in the <code>tests-integration/tests/integration</code> directory of the repository.</p>
<h2 id="running-with-different-solvers"><a class="header" href="#running-with-different-solvers">Running with Different Solvers</a></h2>
<h3 id="sat-solver"><a class="header" href="#sat-solver">SAT Solver</a></h3>
<pre><code class="language-bash">cargo run -- solve --solver sat my_problem.essence
</code></pre>
<blockquote class="blockquote-tag blockquote-tag-warning">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg>Warning</p>
<p>Currently, running the command above will cause the following error:</p>
<p><code>model invalid: Only Boolean Decision Variables supported</code></p>
<p>This because the SAT option for the solver argument only currently enables the base (boolean) rule set and does not specify an integer SAT ruleset to include. This is something we are currently working on, and should be resolved soon.</p>
</blockquote>
<h3 id="minion-solver"><a class="header" href="#minion-solver">Minion Solver</a></h3>
<pre><code class="language-bash">cargo run -- solve --solver minion my_problem.essence
</code></pre>
<p><strong>Expected output for both solvers:</strong></p>
<pre><code class="language-json">Solutions:
[
  {
    "x": {
      "Int": 3
    },
    "y": {
      "Int": 2
    }
  }
]
</code></pre>
<h2 id="understanding-what-happened"><a class="header" href="#understanding-what-happened">Understanding What Happened</a></h2>
<p>Conjure Oxide transformed your high-level Essence model through several steps:</p>
<ol>
<li><strong>Parsing</strong> - Your Essence file was parsed into an internal AST</li>
<li><strong>Rule Application</strong> - Backend-specific rules transformed the model</li>
<li><strong>Solving</strong> - The transformed model was sent to the solver</li>
<li><strong>Solution Extraction</strong> - The solver’s output was converted back to Essence format</li>
</ol>
<p>Want to see exactly what rules were applied? Check out the <a href="#logging">Logging guide</a>.</p>
<h2 id="functional-programming-style"><a class="header" href="#functional-programming-style">Functional Programming Style</a></h2>
<p>For developers who come from programming languages like Scala or Haskell, or those who favour a functional programming style, we have a <a href="#functional-rust-1">Functional Rust</a> guide that you might find useful.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="logging"><a class="header" href="#logging">Logging</a></h1>
<p><strong>This document is a work in progress - for a full list of logging options,
see Conjure Oxide’s <code>--help</code> output.</strong></p>
<h2 id="to-stderr"><a class="header" href="#to-stderr">To <code>stderr</code></a></h2>
<p>Using <code>--verbose</code>, and the <code>RUST_LOG</code> environment variable, you can control the
contents, and formatting of, Conjure Oxide’s <code>stderr</code> output:</p>
<ul>
<li>
<p><strong><code>--verbose</code></strong> changes the formatting of the logs for improved readability,
including printing source locations and line numbers for log events. It also
enables the printing of the log levels <code>INFO</code> and above.</p>
</li>
<li>
<p>The <strong><code>RUST_LOG</code></strong> environment variable can be used to customise the
log levels that are printed depending on the module . For more
information, see:
<a href="https://docs.rs/env_logger/latest/env_logger/#enabling-logging">https://docs.rs/env_logger/latest/env_logger/#enabling-logging</a>.</p>
</li>
</ul>
<h3 id="example-logging-rule-applications"><a class="header" href="#example-logging-rule-applications">Example: Logging Rule Applications</a></h3>
<p>Different log levels provide different information about the rules applied to
the model:</p>
<ul>
<li>
<p><code>INFO</code> provides information on the rules that were applied to the model.</p>
</li>
<li>
<p><code>TRACE</code> additionally prints the rules that were attempted and why they were
not applicable.</p>
</li>
</ul>
<p>To see TRACE logs in a pretty format (mainly useful for
debugging):</p>
<pre><code class="language-sh">$ RUST_LOG=trace conjure-oxide solve --verbose &lt;model&gt;
</code></pre>
<p>Or, using cargo:</p>
<pre><code class="language-sh">$ RUST_LOG=trace cargo run -- solve --verbose &lt;model&gt;
</code></pre>
<h3 id="example-tracing-sat-solver-rules"><a class="header" href="#example-tracing-sat-solver-rules">Example: Tracing SAT Solver Rules</a></h3>
<p>When working with the SAT solver, you can trace the complete transformation pipeline:</p>
<pre><code class="language-bash">RUST_LOG=TRACE cargo run -- solve --solver sat my_problem.essence --verbose
</code></pre>
<p>This will show:</p>
<ul>
<li>Integer-to-boolean conversions</li>
<li>Operation transformations</li>
<li>Tseitin transformations</li>
<li>All rules that were tried and applied</li>
</ul>
<p>For more detailed testing output (including JSON traces and rewritten models), run specific tests:</p>
<pre><code class="language-bash">cargo test &lt;test_name&gt;
</code></pre>
<p>This generates <code>.json</code> and <code>.txt</code> files containing rule traces, parsed Essence, solutions, and the rewritten model.</p>
<div style="break-before: page; page-break-before: always;"></div><!-- maturity: draft
authors: Jamie Melton, Georgii Skorokhod, Özgür Akgün
created: 24-10-25
---- -->
<h1 id="contributors-guide"><a class="header" href="#contributors-guide">Contributors Guide</a></h1>
<p>We love your input! We want to make contributing to this project as easy and transparent as possible, whether it’s:</p>
<ul>
<li>Reporting a bug</li>
<li>Discussing the current state of the code</li>
<li>Submitting a fix</li>
<li>Proposing new features</li>
<li>Becoming a maintainer</li>
</ul>
<h2 id="contributing-1"><a class="header" href="#contributing-1">Contributing</a></h2>
<p>This project is open-source: you can find the source code on
<a href="https://github.com/conjure-cp/conjure-oxide">Github</a>, and issues, questions,
or feature requests can be posted on the <a href="https://github.com/conjure-cp/conjure-oxide/issues">Github issue
tracker</a>.</p>
<p>Currently, Conjure Oxide has been primarily developed by students and staff at the <a href="https://www.st-andrews.ac.uk/">University of St Andrews</a>. That being said, we welcome and encourage contributions from individuals outside the University. Over the course of this section, we will expand further into <strong>how</strong> you can contribute.</p>
<p>For more detailed information reguarding our contributing process, please refer to <a href="https://github.com/conjure-cp/conjure-oxide/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<h2 id="licence-1"><a class="header" href="#licence-1">Licence</a></h2>
<p>This project is entirely open-source, with all code released under the <a href="https://www.mozilla.org/en-US/MPL/2.0/">MPL 2.0</a> license, unless stated otherwise.</p>
<hr>
<p><em>This section had been adapted from the ‘home’ page of the conjure-oxide wiki, and <a href="https://github.com/conjure-cp/conjure-oxide/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></em></p>
<div style="break-before: page; page-break-before: always;"></div><!-- TODO: Edit this -->
<h1 id="how-we-work"><a class="header" href="#how-we-work">How We Work</a></h1>
<p>This is our Constitution, but in contrast to a real constitution of a company we intend this document to be a living document. Please feel free to suggest edits and improvements.</p>
<h2 id="principles"><a class="header" href="#principles">Principles</a></h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Good_faith">Assume good faith</a>.</li>
<li>Take responsibility for your work.</li>
<li>Look for opportunites to help others.</li>
<li>Make it easy for others to help you.</li>
</ul>
<h2 id="social-contract"><a class="header" href="#social-contract">Social contract</a></h2>
<p>We agree to adhere to the following guidelines when engaging in group work.</p>
<ul>
<li>We communicate in English as a common, shared language.</li>
<li>We include all group members in meetings, group chats, messages, and social events.</li>
<li>We turn up on time to meetings.</li>
<li>We pay attention and contribute to group discussions.</li>
<li>We contribute to the group tasks.</li>
<li>We listen to each other’s opinions.</li>
<li>We share ideas and do not disregard other people’s thoughts or feelings.</li>
<li>We are respectful towards one another and treat each other with care and courtesy.</li>
<li>We complete tasks on time and to the best of our ability.</li>
<li>We do not make assumptions about individual abilities.</li>
</ul>
<h2 id="logistics"><a class="header" href="#logistics">Logistics</a></h2>
<ul>
<li><strong>GitHub</strong>: We use GitHub as our main platform for code collaboration and version control.</li>
<li><strong>Teams</strong>: We use Teams for day to day communications.</li>
<li><strong>Weekly report</strong>: We use a web form to provide an update to the supervisors every week. This is not assessed and doesn’t strictly follow the reflective writing methods. However, <a href="https://reflection.ed.ac.uk/reflectors-toolkit/reflecting-on-experience/gibbs-reflective-cycle">this resource on the Gibbs reflective cycle</a> may still be helpful when approaching the weekly form and how to use the form effectively.</li>
<li><strong>Weekly meetings</strong>: The whole group meets once a week. Before this meeting everyone fills in the weekly report. We take minutes at these meetings.</li>
</ul>
<h2 id="best-practices-for-collaboration"><a class="header" href="#best-practices-for-collaboration">Best Practices for Collaboration</a></h2>
<h3 id="1-start-with-early-pull-requests-prs"><a class="header" href="#1-start-with-early-pull-requests-prs">1. Start with Early Pull Requests (PRs)</a></h3>
<ul>
<li>Don’t wait until everything is perfect; submitting early PRs allows the team to provide feedback sooner. This helps catch potential issues early and encourages collaboration.</li>
<li>Even if your code isn’t complete, opening a draft PR can be a good way to start discussions and ensure alignment.</li>
</ul>
<h3 id="2-show-dont-tell"><a class="header" href="#2-show-dont-tell">2. Show, Don’t Tell</a></h3>
<ul>
<li>Share your experiences and insights! Use GitHub or Microsoft Teams to share updates, challenges, and breakthroughs with the rest of the team.</li>
<li>Showing real examples means other can more easily help you, it can help others understand your approach and may inspire new ideas.</li>
<li>High-level explanations can inadvertantly hide important details. Showing the actual artefact (whether it’s code, a design document or something else) together with your high-level commentary eliminates this risk.</li>
</ul>
<h3 id="3-begin-with-specifications"><a class="header" href="#3-begin-with-specifications">3. Begin with Specifications</a></h3>
<ul>
<li>Before you start coding, document your plan. Write out specifications or create a rough outline of what you’re working on, including examples where possible.</li>
<li>Having a clear plan makes it easier to get feedback and helps others understand the purpose and scope of your work.</li>
</ul>
<h3 id="4-share-failures-as-much-as-successes"><a class="header" href="#4-share-failures-as-much-as-successes">4. Share Failures as Much as Successes</a></h3>
<ul>
<li>When something doesn’t work, share it! Learning from mistakes and discussing setbacks is invaluable.</li>
<li>A failed attempt can often be as educational as a successful one, and it may prevent others from encountering the same issue.</li>
</ul>
<h3 id="5-ask-good-questions"><a class="header" href="#5-ask-good-questions">5. Ask Good Questions</a></h3>
<ul>
<li>Don’t hesitate to reach out when you’re stuck, but try to ask thoughtful, specific questions.</li>
<li>Providing context and sharing what you’ve tried will help others give more helpful answers.</li>
</ul>
<h2 id="final-thoughts"><a class="header" href="#final-thoughts">Final Thoughts</a></h2>
<ul>
<li><strong>Collaboration</strong> is key to our success, so feel free to communicate openly.</li>
<li><strong>Continuous improvement</strong> is encouraged—keep looking for ways to improve your code, processes, and knowledge.</li>
</ul>
<hr>
<p><em>This section had been taken from the ‘How we work’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div><!-- maturity: draft
authors: Georgii Skorokhod, Niklas Dewally
created: 31-03-25
---- -->
<h1 id="setting-up-your-development-environment"><a class="header" href="#setting-up-your-development-environment">Setting up your development environment</a></h1>
<p>Conjure Oxide supports Linux and Mac.</p>
<p>Windows users should install <a href="https://learn.microsoft.com/en-us/windows/wsl/setup/environment#set-up-your-linux-username-and-password">WSL</a> and follow the Linux (Ubuntu) instructions below:</p>
<details><summary><b>Linux (Debian/Ubuntu)</b></summary>
<p><strong>The following software is required:</strong></p>
<ul>
<li>The latest version of stable Rust, installed using <a href="https://www.rust-lang.org/tools/install">Rustup</a>.</li>
<li>A C/C++ compilation toolchain and libraries:
<ul>
<li>Debian, Ubuntu and derivatives: <code>sudo apt install build-essential libclang-dev</code></li>
<li>Fedora: <code>sudo dnf group install c-development</code> and <code>sudo dnf install clang-devel</code></li>
</ul>
</li>
</ul>
<ul>
<li><a href="https://github.com/conjure-cp/conjure">Conjure</a>.
<ul>
<li><strong>Ensure that Conjure is placed early in your PATH to avoid conflicts with ImageMagick’s <code>conjure</code> command!</strong></li>
</ul>
</li>
</ul>
</details>
<details><summary><b>MacOS</b></summary>
<p><strong>The following software is required:</strong></p>
<ul>
<li>the latest version of stable Rust, installed using <a href="https://www.rust-lang.org/tools/install">Rustup</a>.</li>
<li>an XCode Command Line Tools installation (installable using <code>xcode-select --install</code>)</li>
<li>CMake: <code>brew install cmake</code> (for SAT solving)</li>
<li><a href="https://github.com/conjure-cp/conjure">Conjure</a>.</li>
</ul>
</details>
<details><summary><b>St Andrews CS Linux Systems</b></summary>
<ol>
<li>
<p>Download and install the <em>pre-built binaries</em> for <a href="https://github.com/conjure-cp/conjure">Conjure</a>. Place these in <code>/cs/home/&lt;username&gt;/usr/bin</code> or elsewhere in your <code>$PATH</code>.</p>
</li>
<li>
<p>Install <code>rustup</code> and the latest version of Rust through <code>rustup</code>.
<em>The school provided Rust version does not work</em>.</p>
<ul>
<li>By default, <code>rustup</code> installs to your local home directory; therefore, you may need to re-install <code>rustup</code> and Rust after restarting a machine or when using a new lab PC.</li>
</ul>
</li>
</ol>
</details>
<hr>
<h3 id="improving-compilation-speed"><a class="header" href="#improving-compilation-speed">Improving Compilation Speed</a></h3>
<p>Installing <a href="https://github.com/mozilla/sccache">sccache</a> improves compilation speeds of this project by caching crates and C/C++ dependencies system-wide.</p>
<ul>
<li>Install <a href="https://github.com/mozilla/sccache">sccache</a> and follow the setup instructions for Rust. Minion detects and uses sccache out of the box, so no C++ specific installation steps are required.</li>
</ul>
<hr>
<p><em>This section had been taken from the ‘Setting up your development environment’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="pull-requests"><a class="header" href="#pull-requests">Pull Requests</a></h1>
<blockquote class="blockquote-tag blockquote-tag-tip">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M8 1.5c-2.363 0-4 1.69-4 3.75 0 .984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75 0 0 1-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456 0 0 0-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863 0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751 0 0 1-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304 0-2.06-1.637-3.75-4-3.75ZM5.75 12h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM6 15.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 0 1.5h-2.5a.75.75 0 0 1-.75-.75Z"></path></svg>Tip</p>
<p>We Use <a href="https://guides.github.com/introduction/flow/index.html">Github Flow</a>, so All Code Changes Happen Through Pull Requests</p>
</blockquote>
<p>Our development process is as follows:</p>
<ol>
<li>Make a fork.</li>
<li>Create a branch on your fork, do not develop on main.</li>
<li>Create a pull request as soon as you want others to be able to see your progress, comment, and/or help:
<ul>
<li>Err on the side of creating the pull request too early instead of too late.
Having an active PR makes your work visible, allows others to help you and give feedback. Request reviews from people who have worked on similar parts of the project.</li>
<li>Keep the PR in draft status until you think it’s ready to be merged.</li>
</ul>
</li>
<li>Assign PR to reviewer(s) when it’s ready to be merged.
<ul>
<li>Only Oz (@ozgurakgun) can merge PR’s, so add him as a reviewer when you want your PR to be merged.</li>
<li>During reviewing, avoid force-pushing to the pull request, as this makes reviewing more difficult.
Details on how to update a PR are given below.</li>
</ul>
</li>
<li>Once Oz has approved the PR:
<ul>
<li>Update your PR to main by rebase or merge. This can be done through the Github UI or locally.</li>
<li>Cleanup your git history (see below) or request your PR to be squash merged.</li>
</ul>
</li>
</ol>
<h1 id="style"><a class="header" href="#style">Style</a></h1>
<ul>
<li>Run <code>cargo fmt</code> in the project directory to automatically format code</li>
<li>Use <code>cargo clippy</code> to lint the code and identify any common issues</li>
</ul>
<p>See: [[Documentation Style]] and [[Rust Coding Style]] (TODO)</p>
<h1 id="commit-and-pr-titles"><a class="header" href="#commit-and-pr-titles">Commit and PR Titles</a></h1>
<p>We use <a href="https://gist.github.com/joshbuchea/6f47e86d2510bce28f8e7f42ae84c716">Semantic PR / Commit messages</a>.</p>
<p>Format: <code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;</code>
(<code>&lt;scope&gt;</code> is optional)</p>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<pre><code>feat(parser): add letting statements
^--^ ^----^   ^--------------------^
|    |        |
|    |        +--&gt; Summary in present tense.
|    |
|    +--&gt; Area of the project affected by the change.
|
+-------&gt; Type: chore, docs, feat, fix, refactor, style, or test.
</code></pre>
<h2 id="types"><a class="header" href="#types">Types</a></h2>
<ul>
<li><code>feat</code>: new features for the end user</li>
<li><code>chore</code>: changes to build scripts, CI, dependency updates; does not affect production code</li>
<li><code>fix</code>: fixing bugs in production code</li>
<li><code>style</code>: purely stylistic changes to the code (e.g. indentation, semicolons, etc) that do not affect behaviour</li>
<li><code>refactor</code>: changes of production code that do not add new features or fix specific bugs</li>
<li><code>test</code>: adding, updating, or refactoring test code</li>
<li><code>doc</code>: adding or updating documentation</li>
</ul>
<h1 id="pr-messages"><a class="header" href="#pr-messages">PR Messages</a></h1>
<p>Your pull request should contain a brief description explaining:</p>
<ul>
<li>What changes you are making</li>
<li>Why they are necessary</li>
<li>Any significant changes that may break other people’s work</li>
</ul>
<p>Additionally, you can link your PR to an issue. For example: <code>closes issue #42</code>.</p>
<h1 id="amending-your-pr-and-force-pushes"><a class="header" href="#amending-your-pr-and-force-pushes">Amending your PR and Force Pushes</a></h1>
<p>You should avoid rebasing, amending, and force-pushing changes during PR review.
This makes code review difficult by removing the context around code review comments and changes to a commit.</p>
<p>The recommended way to update PRs is to use git’s <a href="https://git-scm.com/docs/git-commit#Documentation/git-commit.txt---fixupamendrewordltcommitgt">built-in support for fixups</a>.</p>
<p>To make a change to a commit (e.g. addressing a code review comment):</p>
<pre><code class="language-sh">git commit --fixup &lt;commit&gt;
git push
</code></pre>
<p>Once your PR is ready to merge, these fixup commits can be merged into their original commits like so:</p>
<pre><code class="language-sh">git rebase --autosquash main
git push --force
</code></pre>
<p>We have CI checks to block accidental merging of <code>fixup!</code> commits.</p>
<p>See:</p>
<ul>
<li>https://rietta.com/blog/git-rebase-autosquash-code-reviews/</li>
<li>https://git-scm.com/docs/git-commit#Documentation/git-commit.txt—fixupamendrewordltcommitgt</li>
</ul>
<h1 id="before-your-pr-is-merged"><a class="header" href="#before-your-pr-is-merged">Before your PR is merged</a></h1>
<p>When your PR is approved, you may need to <a href="https://git-scm.com/docs/git-rebase#_description">rebase</a> your branch onto main before it can be merged. Rebasing essentially adds all the latest commits from main to your branch if it has fallen behind main.</p>
<p>To do this:</p>
<ol>
<li>Make sure that your <code>main</code> branch is synced to the main repo</li>
<li>Switch to the branch you’re making the PR from</li>
<li>Do:
<pre><code class="language-sh">git rebase main
git push --force
</code></pre>
</li>
</ol>
<h1 id="optional-cleaning-up-your-git-history"><a class="header" href="#optional-cleaning-up-your-git-history">(Optional) Cleaning up your Git history</a></h1>
<p>Additionally, if you are proficient with git, you can use interactive rebase to clean up your commit history.
This allows you to reorder, drop, or amend commits arbitrarily.</p>
<p>See:</p>
<ul>
<li><a href="https://about.gitlab.com/blog/2020/11/23/keep-git-history-clean-with-interactive-rebase/">How to keep your Git history clean with interactive rebase</a></li>
<li><a href="https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History">7.6 Git Tools - Rewriting History</a></li>
</ul>
<p>There are some GUI tools to help you do that, such as the <a href="https://github.com/apps/desktop">GitHub Client</a>, <a href="https://www.gitkraken.com/">GitKraken</a>, various VS Code extensions, etc.</p>
<blockquote class="blockquote-tag blockquote-tag-warning">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg>Warning</p>
<p>Interactive rebase and force-pushing overwrites your git history, so it can be destructive.
This is also not a requirement!</p>
</blockquote>
<h1 id="squashing-prs"><a class="header" href="#squashing-prs">Squashing PRs</a></h1>
<p>Alternatively, you can ask for the PR to be “squashed”.
This combines all your commits into one merge commit.
Squashing PRs helps keep the commit history on main clean and logical without requiring you to go back and  manually edit your commits!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="creating-documentation"><a class="header" href="#creating-documentation">Creating Documentation</a></h1>
<p>As an organisation, we want Conjure Oxide to be thoroughly documented so that new members of our growing team can integrate smoothly. Whether you are currently on a project or not, contributing to our documentation is essential to achieving this goal.</p>
<p>To make creating and implementing documentation as smooth as possible, we ask that you follow the workflow as outlined below.</p>
<h2 id="documentation-work-flow"><a class="header" href="#documentation-work-flow">Documentation Work Flow</a></h2>
<ol>
<li>
<p>Identify the documentation you will write.</p>
<p>In many cases, documentation contributors will be writing about projects they are currently working on or have already completed.
However, there are still plenty of opportunities to contribute to documentation, even if you are not actively involved in a project or are seeking a small side project.
In such cases, please refer to <a href="https://github.com/conjure-cp/conjure-oxide/issues/1334">issue #1334</a>, which tracks all documentation writing tasks.
All unassigned child issues are available for anyone to work on!</p>
<p>You may come across instances where important or useful documentation is missing from this book. If you notice such gaps and would like to address them as a side project, we encourage you to do so!</p>
</li>
<li>
<p>If the issue is not already present, open a child issue on our documentation tracking issue <a href="https://github.com/conjure-cp/conjure-oxide/issues/1334">#1334</a>.</p>
<p>Make the title of this issue the name of the documentation you will be writing.</p>
</li>
<li>
<p>Link your child issue to a pr request.</p>
<h4 id="file-type-and-naming-convention"><a class="header" href="#file-type-and-naming-convention">File type and naming convention:</a></h4>
<p>All documentation for the Conjure Oxide book should be written in markdown. If you’re unfamiliar with markdown or need a refresher on its syntax, we recommend reviewing <a href="https://www.markdownguide.org/getting-started/">this guide</a>.</p>
<p>When naming your documentation file, match the file name as closely as possible to the heading of the documentation and use underscores (‘_’) to replace spaces. For example, if your documentation page is titled “Creating Documentation,” name the file <code>creating_documentation.md</code>.</p>
<h4 id="where-to-place-documentation"><a class="header" href="#where-to-place-documentation">Where to place documentation:</a></h4>
<p>Place all documentation files in an appropriate location within the <code>/docs/src</code> directory. Each markdown file should be stored in the directory that matches its section in the documentation structure. For example, this file is located at <code>/docs/src/developers_guide/contributors_guide/</code>.</p>
<p>If you know where your documentation belongs in the book, please place it in the appropriate directory. However, it’s not required to know the exact location—moving files is quick and easy. If you’re unsure where your documentation should go, place the file in <code>/docs/src/misc</code> so it can be relocated later to a more suitable section.</p>
<h4 id="viewing-documentation-on-the-book"><a class="header" href="#viewing-documentation-on-the-book">Viewing documentation on the book:</a></h4>
<p>You must ensure that the documentation you write formats as expected in the book. To do so, follow these steps:</p>
<ul>
<li>Open <code>/docs/src/SUMMARY.md</code>.</li>
<li>If you have a definite location for your documentation, link the documentation in the appropriate section using the following format: <code>[ Section title ](path/to/file)</code>.</li>
<li>If you are unsure where your documentation should reside, place the documentation at any location, <strong>but remember to delete this link once you’re happy with your document’s formatting</strong>.</li>
<li>In your terminal, ensure that you are in the <code>/docs</code> directory and type in the following command <code>mdbooks serve --open</code></li>
</ul>
<blockquote>
<p><strong>Important</strong></p>
<p>Be sure to assign yourself and any other contributors working on the documentation to your child issue and pull request. This helps us keep track of who is responsible for each piece of documentation and ensures proper assignment.</p>
</blockquote>
</li>
<li>
<p>Once you are happy with your documentation, request a review from one or more other members of your team.</p>
<blockquote>
<p><strong>Important</strong></p>
<p>Place any contributors to the documentation and the date where the documentation was last updated in a comment on the first and second lines of the file.
For instance:</p>
<p><code>[//]: # (Author: Jamie Melton)</code></p>
<p><code>[//]: # (Last Updated: 09/12/2025)</code></p>
<p>has been placed at the top of this file.</p>
</blockquote>
</li>
<li>
<p>When your team is happy with this documentation, request a review from the current book editors.</p>
<p>The current book editors are: <em>JamieASM</em> and <em>HKhan-5</em>.</p>
</li>
<li>
<p>Assuming no adjustments are required, the documentation will then be merged in, and the child issue will be closed.</p>
</li>
</ol>
<hr>
<h2 id="still-unsure"><a class="header" href="#still-unsure">Still unsure?</a></h2>
<p>If you have any questions or concerns, please post them on the documentation discussion board. A book editor will respond to you promptly.
Likewise, if you have suggestions for improving or streamlining this process, feel free to share your ideas with the book editors! Your feedback is always welcome.</p>
<div style="break-before: page; page-break-before: always;"></div>
<blockquote>
<p><em>“Omit needless words”</em></p>
<p>(c) William Strunk</p>
</blockquote>
<h1 id="key-points"><a class="header" href="#key-points">Key Points</a></h1>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<p>See:</p>
<ul>
<li>the <a href="https://github.com/rust-lang/rfcs/blob/master/text/1574-more-api-documentation-conventions.md">Rust doc style conventions</a></li>
</ul>
<h2 id="dos"><a class="header" href="#dos">Do’s</a></h2>
<p>Our documentation is inline with the code. The reader is likely to skim it while scrolling through the file and trying to understand what it does. So, our doc strings should:</p>
<ul>
<li>Be as brief and clear as possible</li>
<li>Ideally, fit comfortably on a standard monitor without obscuring the code</li>
<li>Contain key information about the method / structure, such as:
<ul>
<li>A single sentence explaining its purpose</li>
<li>A brief overview of arguments / return types</li>
<li>Example snippets for non-trivial methods</li>
</ul>
</li>
<li>Explain any details that are <strong>not</strong> obvious from the method signature, such as:
<ul>
<li>Details of the method’s “contract” that can’t be easily encoded in the type system
<blockquote>
<p>(E.g: <em>“The input must be a sorted slice of positive integers”</em>; <em>“The given expression will be modified in-place”</em>)</p>
</blockquote>
</li>
<li>Non-trivial situations where the method may <code>panic!</code> or cause unintended behaviour
<blockquote>
<p>(E.g: <em>“Panics if the connection terminates while the stream is being read”</em>)</p>
</blockquote>
</li>
<li>Any <code>unsafe</code> things a method does
<blockquote>
<p>(E.g: <em>“We type-cast the given pointer with <code>mem::transmute</code>. This is safe because…”</em>)</p>
</blockquote>
</li>
<li>Special cases</li>
</ul>
</li>
</ul>
<h2 id="donts"><a class="header" href="#donts">Don’ts</a></h2>
<p>Documentation generally should <strong>not</strong>:</p>
<ul>
<li>Repeat itself</li>
<li>Use long, vague, or overly complex sentences</li>
<li>Re-state things that are obvious from the types / signature of the method</li>
<li>Explain implementation details</li>
<li>Explain high-level architectural decisions
(Consider making a wiki page or opening an RFC issue instead!)</li>
</ul>
<p>And finally…
Please, don’t ask ChatGPT to document your code for you!
I know that writing documentation can be tedious, but you can always:</p>
<ul>
<li>Write a one-sentence doc string for now and come back to it later</li>
<li>Ask others if you don’t quite understand what a method does</li>
</ul>
<h1 id="types-and-tests-are-documentation"><a class="header" href="#types-and-tests-are-documentation">Types and Tests are Documentation</a></h1>
<p>Documentation is great, but we should also use the type system and other rust features to our advantage!</p>
<ul>
<li>
<p>A lot of things (e.g: error conditions, thread safety, state) can be encoded in the types of arguments / return values.
This is usually better than just <code>panic!</code>-ing and adding a doc string to explain why.</p>
</li>
<li>
<p>Tests are also a great way to illustrate the behaviour of your code and any special cases - and they also help with catching bugs!</p>
</li>
</ul>
<h1 id="example-snippets"><a class="header" href="#example-snippets">Example Snippets</a></h1>
<p>For non-trivial methods and user-facing API’s, it may be useful to include an example.
Examples should be minimal but complete snippets of code that illustrate a method’s behaviour.</p>
<p>If you wrap your example in a code block:</p>
<pre><code class="language-markdown">```rust ... ```
</code></pre>
<p>Our CI will even run it and complain if the example does not compile / contains an error!</p>
<p>However, don’t feel obliged to include an example for every method!
For simple methods they may not be necessary.</p>
<h1 id="examples"><a class="header" href="#examples">Examples</a></h1>
<p>⚠️ Good but a bit wordy:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Checks if the OPTIMIZATIONS environment variable is set to "1".
///
/// # Returns
/// - true if the environment variable is set to "1".
/// - false if the environment variable is not set or set to any other value.
fn optimizations_enabled() -&gt; bool {
    match env::var("OPTIMIZATIONS") {
        Ok(val) =&gt; val == "1",
        Err(_) =&gt; false, // Assume optimizations are disabled if the environment variable is not set
    }
}
<span class="boring">}</span></code></pre>
<p>✅ Since everything else is obvious from the signature, we can just say:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Checks if the OPTIMIZATIONS environment variable is set to "1"
fn optimizations_enabled() -&gt; bool { ... }
<span class="boring">}</span></code></pre>
<p>⚠️ Not bad, but sounds a bit robotic</p>
<pre><code class="language-markdown"># Side-Effects
- When the model is rewritten, related data structures such as the symbol table (which tracks variable names and types)
  or other top-level constraints may also be updated to reflect these changes. These updates are applied to the returned model,
  ensuring that all related components stay consistent and aligned with the changes made during the rewrite.
- The function collects statistics about the rewriting process, including the number of rule applications
  and the total runtime of the rewriter. These statistics are then stored in the model's context for
  performance monitoring and analysis.
</code></pre>
<p>✅ Same idea but shorter</p>
<pre><code class="language-markdown"># Side-Effects
- Rules can apply side-effects to the model (e.g. adding new constraints or variables).
  The original model is cloned and a modified copy is returned.
- Rule engine statistics (e.g. number of rule applications, run time) are collected and stored in the new model's context.
</code></pre>
<p>⚠️ A bit too detailed</p>
<pre><code class="language-markdown"># Parameters
- `expression`: A reference to the [`Expression`] that will be evaluated against the given rules. This is the main
   target for rule transformations and is expected to remain unchanged during the function execution.
- `model`: A reference to the [`Model`] that provides context for rule evaluation, such as constraints and symbols.
  Rules may depend on information in the model to determine if they can be applied.
- `rules`: A vector of references to [`Rule`]s that define the transformations to be applied to the expression.
  Each rule is applied independently, and all applicable rules are collected.
- `stats`: A mutable reference to [`RewriterStats`] used to track statistics about rule application, such as
  the number of attempts and successful applications.
</code></pre>
<p>✅ Just describing the meaning of arguments will do</p>
<p>(Details of the rewriting process belong on the wiki, and details of underlying types such as <code>Model</code> or <code>Expression</code> are already documented next to their implementations)</p>
<pre><code class="language-markdown">- `expression`: A reference to the [`Expression`] to evaluate.
- `model`: A reference to the [`Model`] for access to the symbol table and context.
- `rules`: A vector of references to [`Rule`]s to try.
- `stats`: A mutable reference to [`RewriterStats`] used to track the number of rule applications and other statistics.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="coding-resources-and-conventions"><a href="#coding-resources-and-conventions" class="header">Coding Resources and Conventions</a></h1>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<ul>
<li>
<p>PR: Pull request. It’s a proposal to merge code changes into the <a href="https://github.com/conjure-cp/conjure-oxide/tree/main">main</a> branch, and allows collaborators to review and suggest modifications before it’s accepted.</p>
</li>
<li>
<p>Branch: A branch contains a different history of code changes (commits). You can start a new branch A’ off of any branch A and push new commits to A’ without affecting the contents of A. Merging branch A’ into A adds all new changes from A’ to A.</p>
</li>
<li>
<p>RFC: Request for Comments. It is a design proposal, often written before or alongside major changes.</p>
</li>
<li>
<p>Essence: A high level constraint modelling language. Essence is <em>delcarative</em>, i.e. it states the problem rather than how to solve it. It also lets us model things at the class level.</p>
<ul>
<li>
<p>A class-level model (i.e. description of a problem) may have some parameters. To get from a class-level model to an instance model, we provide concrete values for all the parameters.</p>
<p>The following describes a problem class:</p>
<pre><code>given N: int
find x
such that x &lt; N
</code></pre>
<p>The following are instances of that class:</p>
<pre><code>letting N be 3
find x
such that x &lt; N
</code></pre>
<pre><code>letting N be 42
find x
such that x &lt; N
</code></pre>
</li>
</ul>
</li>
<li>
<p>Conjure: Constraint modelling tool that translates Essence problem descriptions into Essence’ models that constraint solvers can execute.</p>
</li>
<li>
<p>Essence’ (Essence prime): Intermediate representation automatically generated by Conjure</p>
</li>
<li>
<p><a href="https://www-users.york.ac.uk/peter.nightingale/savilerow/">Savile Row:</a> It transforms high level Essence’ constraint models and outputs solver-specific model that can be executed. Written in Java.</p>
</li>
<li>
<p>Minion: Constraint solver. It takes low level constraint models (like Savile Row output) and searches for solutions. Specifically, it has its own input language that is <a href="https://math.chapman.edu/~jipsen/talks/Milan2010/MinionManual09.pdf">extensively documented.</a></p>
</li>
</ul>
<p>For an in-depth glossary of GitHub terms, see the <a href="https://docs.github.com/en/get-started/learning-about-github/github-glossary">GitHub Docs Glossary</a>.
This <a href="https://git-scm.com/cheat-sheet">Git Cheat Sheet</a> also contains resources about git commands.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="functional-rust-1"><a href="#functional-rust-1" class="header">Functional Rust</a></h1>
<h2 id="functional-rust"><a class="header" href="#functional-rust">Functional Rust</a></h2>
<p>Consider the following oft-quoted statement about Rust:</p>
<p><em>Rust is blazingly fast and memory-efficient: with no runtime or garbage collector. Rust’s rich type system and ownership model guarantee memory-safety and thread-safety — enabling you to eliminate many classes of bugs at compile-time.</em></p>
<p>Taken specifically from the Rust Foundation’s<sup class="footnote-reference" id="fr-1-1"><a href="#footnote-1">1</a></sup> page talking about why Rust is a good language to use.</p>
<p>But let us focus on the implications of this statement on Conjure Oxide specifically. The key details that one needs to know here are that, despite arguably being imperative, Rust adopts many functional programming concepts in its design<sup class="footnote-reference" id="fr-2-1"><a href="#footnote-2">2</a></sup>. This is significant because the Conjure Oxide codebase makes extensive use of these functional programming concepts.</p>
<p>Making use of them allows the codebase to leverage Rust’s type system to eliminate error cases through coding style, making the code more robust. It also makes the code easier to write, because Rust’s safety system enforces function return types.</p>
<h3 id="result"><a class="header" href="#result">Result</a></h3>
<p>By using the <code>Result</code> type, functions can explicitly state success or failure. This also allows functions to call each other linearly in a safe manner<sup class="footnote-reference" id="fr-3-1"><a href="#footnote-3">3</a></sup>.</p>
<p>This enables the code to be written so that functions can do essentially whatever they need to do as side effects, as long as they record a success or failure result. The error type allows error propagation in a more sophisticated way than exit codes, while still being more efficient than exceptions. This structure is used in a lot of places in this codebase, because it allows for functions to be treated uniformly most anywhere<sup class="footnote-reference" id="fr-4-1"><a href="#footnote-4">4</a></sup>, meaning they can be called anywhere by any originator (or caller) function without having to resort to unsafe rust and sticking to the type safety scheme.</p>
<p>This also allows for the use of the <code>?</code> operator<sup class="footnote-reference" id="fr-5-1"><a href="#footnote-5">5</a></sup>, which means that errors can be propagated up the call stack lazily.</p>
<p>Consider the following example, written imperatively in Java-like pseudocode:</p>
<pre><code class="language-java">
public void fnReturnsError(a,b) {
    ...Some Code...
    // might throw error1
    int foo1 = maybeReturnsMyError1(a);
    ...Some More Code...
    // might throw error2
    int foo2 = maybeReturnsMyError2(b);
    ...Wow, when will this code end...
    // might throw error3
    int foo3 = maybeReturnsMyError3(a,b);
}
</code></pre>
<p>Alternatively, consider a lower-level language like C, which is far more comparable to Rust in its uses and applications, where there are no ‘error types’ and errors behave like either enums or just integral exit codes.</p>
<p>In a C-like language, a similar example would look like this:</p>
<pre><code class="language-C">int returnAnExitCode(int a, int b) {
    int exit_code = 0;
    ...Some Code Here Too...
    int exit_code = maybeReturnsMyExitCode1(a);
    ...Some More Code...
    int exit_code = maybeReturnsMyExitCode2(b);
    ...Why, if it isn't yet more code ...
    int exit_code = maybeReturnsMyExitCode3(a,b);

    return exit_code
}
</code></pre>
<p>This means that, like rust, an error is not an exception getting ‘thrown’, but a value that is being returned. However, unlike rust, they require these exit codes to be set and returned at the end.</p>
<p>This also means that the function calls must be done on some top-level data structure, and that global structure needs to be accessed at the end rather than being able to simply access the top-level data structure through the returned value.</p>
<p>In this type of application, Rust offers two advantages:</p>
<ol>
<li>The <code>Return</code> type, even though it records a success/failure, can be pattern-matched using the <code>match</code> construct to access the data structure which the functions are performing side effects on.</li>
<li>The aforementioned <code>?</code> operator can be used to force the code to return an error type as soon as it is ‘raised’ – that is, returned by one of the functions in the call stack.</li>
</ol>
<p>This example would look like this in rust-like functional code:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn returns_a_result(a: i32, b: i32) -&gt; Result&lt;i32, MyError&gt; {
    // Some code here...
    
    // The ?  operator propagates errors immediately
    let foo1 = maybe_returns_my_error1(a)?;
    
    // Some more code...
    let foo2 = maybe_returns_my_error2(b)?;
    
    // Even more code...
    let foo3 = maybe_returns_my_error3(a, b)?;
    
    // If we get here, all operations succeeded
    Ok()
}
<span class="boring">}</span></code></pre>
<h3 id="side-effects"><a class="header" href="#side-effects">Side Effects</a></h3>
<p>Throughout the above section, references are made to changing things through ‘function side effects’. Let us dive deeper into what this actually means.</p>
<p>Functions are fairly complex, but here is what Alonzo Church has to say about what they do, taken from his paper <em>The Calculi of Lambda Conversion</em>:</p>
<p><em>A function is a rule of correspondence by which when anything is given (as argument) another thing (the value of the function for that argument) may be obtained. That is, a function is an operation which may be applied on one thing (the argument) to yield another thing (the value of the function).</em></p>
<p>In quite an abstract sense, this passage establishes that a Function is simply a mapping from a set of inputs to a set of outputs.</p>
<p>Now, knowing this, the term <em>side effect</em> also begins to make sense – any persistent effects of a function which are not in the returned value are side effects. In a general sense, this is things like writing to files, printing and so on. More specifically in conjure oxide, almost all processing is done by way of side effects. While this makes sense even in an imperative context, imperative code can still have some functions chained together in ways that are only possible if the data structure being affected by them is actually returned by them. In rust, specifically when this side-effect-only style of programming is used, programs end up looking quite a bit more concise and readable.</p>
<p>Now, having all of this knowledge in the back of your head, you will understand why the following things must be kept in mind:</p>
<ol>
<li>Make the greatest effort to treat Rust as a functional language when programming in this (and indeed any) codebase. Not only does this lead to cleaner, more concise and (arguably) more readable code, it actually helps avoid errors and edge cases.</li>
<li>Learn to leverage the Rust type and safety system instead of wrestling with by writing code that uses features in the language like <code>Result&lt;T,E&gt;</code> and <code>Option&lt;T&gt;</code>. This may involve learning where to use these instead of doing things that one cannot do in imperative languages like C.</li>
<li>Rust code is only properly ‘safe’ if it uses the type system properly, meaning it is a good idea to avoid things like returning null, unwrapping <code>Result</code> instances<sup class="footnote-reference" id="fr-6-1"><a href="#footnote-6">6</a></sup>.</li>
</ol>
<hr>
<hr>
<ol class="footnote-definition">
<li id="footnote-1">
<p>Who are, of course, an entirely unbiased source <a href="#fr-1-1">↩</a></p>
</li>
<li id="footnote-2">
<p>Rust’s original implementation language was OCaml, which is functional <a href="#fr-2-1">↩</a></p>
</li>
<li id="footnote-3">
<p>Similar to calling functions in dynamically typed languages like Python, but with enforced types <a href="#fr-3-1">↩</a></p>
</li>
<li id="footnote-4">
<p>This is because, at their core, all functions are essentially of the type (..) -&gt; ReturnType. Making the return type standard allows for all functions to be of similar types. <a href="#fr-4-1">↩</a></p>
</li>
<li id="footnote-5">
<p>Which immediately propogates the error up through the call stack in rust. <a href="#fr-5-1">↩</a></p>
</li>
<li id="footnote-6">
<p>This is what caused the infamous cloudflare outage. <a href="#fr-6-1">↩</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><!-- TODO: Edit this -->
<blockquote>
<p><em>“Omit needless words”</em></p>
<p>(c) William Strunk</p>
</blockquote>
<h1 id="key-points-1"><a class="header" href="#key-points-1">Key Points</a></h1>
<h2 id="resources-1"><a class="header" href="#resources-1">Resources</a></h2>
<p>See:</p>
<ul>
<li>the <a href="https://github.com/rust-lang/rfcs/blob/master/text/1574-more-api-documentation-conventions.md">Rust doc style conventions</a></li>
</ul>
<h2 id="dos-1"><a class="header" href="#dos-1">Do’s</a></h2>
<p>Our documentation is inline with the code. The reader is likely to skim it while scrolling through the file and trying to understand what it does. So, our doc strings should:</p>
<ul>
<li>Be as brief and clear as possible</li>
<li>Ideally, fit comfortably on a standard monitor without obscuring the code</li>
<li>Contain key information about the method / structure, such as:
<ul>
<li>A single sentence explaining its purpose</li>
<li>A brief overview of arguments / return types</li>
<li>Example snippets for non-trivial methods</li>
</ul>
</li>
<li>Explain any details that are <strong>not</strong> obvious from the method signature, such as:
<ul>
<li>Details of the method’s “contract” that can’t be easily encoded in the type system
<blockquote>
<p>(E.g: <em>“The input must be a sorted slice of positive integers”</em>; <em>“The given expression will be modified in-place”</em>)</p>
</blockquote>
</li>
<li>Non-trivial situations where the method may <code>panic!</code> or cause unintended behaviour
<blockquote>
<p>(E.g: <em>“Panics if the connection terminates while the stream is being read”</em>)</p>
</blockquote>
</li>
<li>Any <code>unsafe</code> things a method does
<blockquote>
<p>(E.g: <em>“We type-cast the given pointer with <code>mem::transmute</code>. This is safe because…”</em>)</p>
</blockquote>
</li>
<li>Special cases</li>
</ul>
</li>
</ul>
<h2 id="donts-1"><a class="header" href="#donts-1">Don’ts</a></h2>
<p>Documentation generally should <strong>not</strong>:</p>
<ul>
<li>Repeat itself</li>
<li>Use long, vague, or overly complex sentences</li>
<li>Re-state things that are obvious from the types / signature of the method</li>
<li>Explain implementation details</li>
<li>Explain high-level architectural decisions
(Consider making a wiki page or opening an RFC issue instead!)</li>
</ul>
<p>And finally…
Please, don’t ask ChatGPT to document your code for you!
I know that writing documentation can be tedious, but you can always:</p>
<ul>
<li>Write a one-sentence doc string for now and come back to it later</li>
<li>Ask others if you don’t quite understand what a method does</li>
</ul>
<h1 id="types-and-tests-are-documentation-1"><a class="header" href="#types-and-tests-are-documentation-1">Types and Tests are Documentation</a></h1>
<p>Documentation is great, but we should also use the type system and other rust features to our advantage!</p>
<ul>
<li>
<p>A lot of things (e.g: error conditions, thread safety, state) can be encoded in the types of arguments / return values.
This is usually better than just <code>panic!</code>-ing and adding a doc string to explain why.</p>
</li>
<li>
<p>Tests are also a great way to illustrate the behaviour of your code and any special cases - and they also help with catching bugs!</p>
</li>
</ul>
<h1 id="example-snippets-1"><a class="header" href="#example-snippets-1">Example Snippets</a></h1>
<p>For non-trivial methods and user-facing API’s, it may be useful to include an example.
Examples should be minimal but complete snippets of code that illustrate a method’s behaviour.</p>
<p>If you wrap your example in a code block:</p>
<pre><code class="language-markdown">```rust ... ```
</code></pre>
<p>Our CI will even run it and complain if the example does not compile / contains an error!</p>
<p>However, don’t feel obliged to include an example for every method!
For simple methods they may not be necessary.</p>
<h1 id="examples-1"><a class="header" href="#examples-1">Examples</a></h1>
<p>⚠️ Good but a bit wordy:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Checks if the OPTIMIZATIONS environment variable is set to "1".
///
/// # Returns
/// - true if the environment variable is set to "1".
/// - false if the environment variable is not set or set to any other value.
fn optimizations_enabled() -&gt; bool {
    match env::var("OPTIMIZATIONS") {
        Ok(val) =&gt; val == "1",
        Err(_) =&gt; false, // Assume optimizations are disabled if the environment variable is not set
    }
}
<span class="boring">}</span></code></pre>
<p>✅ Since everything else is obvious from the signature, we can just say:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Checks if the OPTIMIZATIONS environment variable is set to "1"
fn optimizations_enabled() -&gt; bool { ... }
<span class="boring">}</span></code></pre>
<p>⚠️ Not bad, but sounds a bit robotic</p>
<pre><code class="language-markdown"># Side-Effects
- When the model is rewritten, related data structures such as the symbol table (which tracks variable names and types)
  or other top-level constraints may also be updated to reflect these changes. These updates are applied to the returned model,
  ensuring that all related components stay consistent and aligned with the changes made during the rewrite.
- The function collects statistics about the rewriting process, including the number of rule applications
  and the total runtime of the rewriter. These statistics are then stored in the model's context for
  performance monitoring and analysis.
</code></pre>
<p>✅ Same idea but shorter</p>
<pre><code class="language-markdown"># Side-Effects
- Rules can apply side-effects to the model (e.g. adding new constraints or variables).
  The original model is cloned and a modified copy is returned.
- Rule engine statistics (e.g. number of rule applications, run time) are collected and stored in the new model's context.
</code></pre>
<p>⚠️ A bit too detailed</p>
<pre><code class="language-markdown"># Parameters
- `expression`: A reference to the [`Expression`] that will be evaluated against the given rules. This is the main
   target for rule transformations and is expected to remain unchanged during the function execution.
- `model`: A reference to the [`Model`] that provides context for rule evaluation, such as constraints and symbols.
  Rules may depend on information in the model to determine if they can be applied.
- `rules`: A vector of references to [`Rule`]s that define the transformations to be applied to the expression.
  Each rule is applied independently, and all applicable rules are collected.
- `stats`: A mutable reference to [`RewriterStats`] used to track statistics about rule application, such as
  the number of attempts and successful applications.
</code></pre>
<p>✅ Just describing the meaning of arguments will do</p>
<p>(Details of the rewriting process belong on the wiki, and details of underlying types such as <code>Model</code> or <code>Expression</code> are already documented next to their implementations)</p>
<pre><code class="language-markdown">- `expression`: A reference to the [`Expression`] to evaluate.
- `model`: A reference to the [`Model`] for access to the symbol table and context.
- `rules`: A vector of references to [`Rule`]s to try.
- `stats`: A mutable reference to [`RewriterStats`] used to track the number of rule applications and other statistics.
</code></pre>
<hr>
<p><em>This section had been taken from the ‘Documentation Style’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="crate-structure"><a class="header" href="#crate-structure">Crate Structure</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>We follow a “monorepo” approach; That is, a number of related modules are developed in a single repository.
This makes it easier to integrate them and test our entire project all at once.</p>
<p>Our repository can be broken down into four key components:</p>
<ol>
<li>The user-facing <code>conjure-oxide</code> command line tool and library, and its integration tests.
This is stored in <code>conjure-oxide/conjure_oxide</code>.</li>
<li>The AST type definitions, rewrite engine, and related implementation code.
These are broken up into separate crates and stored in <code>conjure-oxide/crates/</code>.</li>
<li>Rust bindings for solvers; That is, wrapper code and build files that enable us to:
<ul>
<li>
<p>Compile solvers (which are developed outside of this project and written in other languages, such as C++) together with our project</p>
</li>
<li>
<p>“Hook into” solver methods and call them from inside our Rust code</p>
<p>These are stored in <code>conjure-oxide/solvers/</code> on a per-solver basis.</p>
</li>
</ul>
</li>
<li>Various other scripts and tools that we use to build, document and test our project.
These are stored in <code>conjure-oxide/tools/</code>.</li>
</ol>
<h2 id="cli-tool"><a class="header" href="#cli-tool">CLI Tool</a></h2>
<p>The command-line <code>conjure-oxide</code> tool is the final product we ship to users.
All logic related to the CLI, parsing user input, and displaying solutions is implemented in <code>conjure-oxide/conjure_oxide/src</code>.</p>
<p>This module (called a “crate” in Rust) also re-exports some type definitions and functions from <code>conjure_core</code> and other crates.
This is our public, user-facing API that could eventually be used by other people in their projects. At the moment, our project is under development and there is no stable API specification.</p>
<p>There are some <code>examples/</code> illustrating how various parts of the project are used.
Finally, for historical reasons, this folder contains some utility code that may be refactored or moved elsewhere in the future.</p>
<h2 id="tests"><a class="header" href="#tests">Tests</a></h2>
<p>Our suite of integration tests runs automatically on every commit to the main repository.
It tests <code>conjure-oxide</code> end-to-end: parsing an example Essence file, running the rewriter, calling the solver, and validating the solution.</p>
<p>The test files are stored in <code>conjure_oxide/tests/integration/</code>, sorted into sub-directories.
Code to run our project on these files is contained in <code>integration_tests.rs</code>.</p>
<h2 id="crates"><a class="header" href="#crates">Crates</a></h2>
<p>Most of our implementation is contained in the <code>crates/</code> directory. Here is an overview of what each crate does:</p>
<ul>
<li><code>conjure_core</code> contains:
<ul>
<li>Our rule engine implementation (<code>conjure_core/src/rule_engine/</code>)</li>
<li>The definition of our Abstract Syntax Tree (AST) for Essence; That is, the Rust representation of an Essence program (<code>conjure_core/src/ast</code>)</li>
<li>The generic <code>SolverAdaptor</code> interface for interacting with solvers (<code>conjure_core/src/solver</code>)</li>
<li>Concrete implementations of <code>SolverAdaptor</code> for each solver we support, such as Minion or RustSAT (<code>conjure_core/src/solver/adaptors</code>)</li>
<li>Other miscellaneous types and utilities</li>
</ul>
</li>
<li><code>conjure_rules</code> defines rules and rule sets for our rewrite engine to use.
Rules are grouped into files and directories based on their purpose: for example, all rules for normalising boolean expressions are in <code>conjure_rules/src/normalisers/bool.rs</code></li>
<li><code>conjure_rule_macros</code> implements the <code>#[register_rule(...)]</code> and <code>#[register_rule_set(...)]</code> procedural macros. See also: <a href="https://github.com/conjure-cp/conjure-oxide/wiki/Expression-rewriting%2C-Rules-and-RuleSets">Wiki - Rules and RuleSets</a>.</li>
<li><code>conjure_essence_parser</code> implements the native Rust parser for Essence.
It uses our Treesitter grammar, which is defined <em>separately</em> in<code>tree-sitter-essence</code></li>
<li><code>conjure_essence_macros</code> implements the <code>essence_expr!</code> procedural macro.</li>
<li><code>enum_compatability_macro</code> is a macro that allows us to indicate whether certain features of Essence are compatible with certain solvers, for documentation purposes.</li>
<li><code>randicheck</code> is a somewhat separate project developed by Ty (@TAswan) and others.
It aims to use Conjure to automatically validate Haskell code and generate minimal failing tests. (TODO is this accurate?)</li>
<li><code>tree_morph</code> is a generic library for tree transformations.
In the future, it will replace our current rule engine implementation.</li>
</ul>
<p>Also:</p>
<ul>
<li>The <code>uniplate</code> crate, which we use to traverse the AST, used to be part of this repository.
It is now maintained separately at https://github.com/conjure-cp/uniplate.</li>
</ul>
<h2 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h2>
<p>The dependencies between crates are shown bellow.</p>
<p><img src="https://github.com/user-attachments/assets/ffda823b-b5f9-4fa8-b66e-e74d2c08a75b" alt="graphviz(3)"></p>
<p>An arrow <code>A -&gt; B</code> means that <code>A</code> imports from <code>B</code>. The diagram is made using Graphviz, and its source code is located TODO.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="why-benchmark"><a class="header" href="#why-benchmark">Why benchmark?</a></h1>
<p>Benchmarking is an essential part of any coding project, especially when it is performance-oriented. While it can be a little daunting when first getting started, this guide aims to show that benchmarking can be integrated into conjure-oxide and its workflows with a little work.</p>
<h1 id="criterion"><a class="header" href="#criterion"><code>criterion</code></a></h1>
<p>By far, the most popular benchmarking tool currently available for <code>Rust</code> is the <code>criterion</code> <a href="https://bheisler.github.io/criterion.rs/book/">crate</a>. Based off the <code>Haskell</code> library of the same name, it is a statistics-based tool which aims to measure <em>wall-clock time</em> for individual functions. To get started on <code>criterion</code> benching in a rust project <code>my_project</code>, you first need to make a directory called <code>benches</code>, which <code>Rust</code> will recognise as holding all benchmarking files. Let’s now make a benchmark called <code>my_bench.rs</code> inside of <code>my_project/benches</code></p>
<p>We now add the following changes to the crate’s <code>cargo.toml</code> file</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>[dev-dependencies]
criterion = "0.3"

[[bench]]
name = "my_bench"
harness = false
<span class="boring">}</span></code></pre>
<p>Suppose that we now want to create function to benchmark the addition of two numbers (which, as expected should be very fast!). We add the following to <code>my_bench</code>.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{Criterion, black_box, criterion_group, criterion_main};

pub fn add(x: u64, y: u64) -&gt; u64 {
    x + y
}

pub fn criterion_benchmark(c: &amp;mut Criterion) {
    c.bench_function("add 20 + 20", |b| {
        b.iter(|| add(black_box(20), black_box(20)))
    });
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
<span class="boring">}</span></code></pre>
<p>The <code>.bench_function</code> method creates an instance of a benchmark. Then the <code>.iter</code> method tells Criterion to repeatedly execute the provided closure. Finally, black_box is used to prevent the compiler from optimising away the code being benchmarked. To run the benchmark simply run <code>cargo bench</code>. Among other things, your terminal should show something alone the lines of:
<img width="1322" alt="image" src="https://github.com/user-attachments/assets/53565407-11fc-43b0-afe1-2e3b582d41c5" />
Which shows the average wall-clock time, as well as providing some information on outliers and performance against previous benchmarks. For the full details, see <code>\target\criterion</code>. The <code>.html</code> reports are especially good.</p>
<p><code>criterion</code> is usually the right tool for most benchmarks, althought there are issues. Due to the statistics-driven ethos of <code>criterion</code>, there is currently no one-shot support, with 10 samples being the minimum number of samples for a benchmark. Wall-clock time also gives little insight into where things are slowing in your code, and will not catch things like poor memory locality. Even more crucially, however, is how <code>criterion</code> performs in CI pipelines. The developer’s themselves say the following:</p>
<p><em>”You probably shouldn’t (or, if you do, don’t rely on the results). The virtualization used by</em>
<em>Cloud-CI providers like Travis-CI and Github Actions introduces a great deal of noise into the</em>
<em>benchmarking process, and Criterion.rs’ statistical analysis can only do so much to mitigate</em>
<em>that. This can result in the appearance of large changes in the measured performance even</em>
<em>if the actual performance of the code is not changing.“</em></p>
<p>As such, we need some other metric apart from wall-clock time to use in order to still run benchmarks in a CI pipeline. This is where the <code>iai-callgrind</code> crate comes in.</p>
<h1 id="iai-callgrind"><a class="header" href="#iai-callgrind"><code>iai-callgrind</code></a></h1>
<p>Iai-Callgrind is a benchmarking framework which uses <a href="https://valgrind.org/docs/manual/cl-manual.html">Valgrind’s Callgrind</a> and other to provide extremely accurate and consistent measurements of Rust code. It does <strong>not</strong> provide information on wall-clock time, instead focussing on metrics like instruction count and memory hit rates. It is important to note that this will only run on <code>linux</code>, due to the valgrind dependancy. Let us create a benchmark called <code>iai-bench</code> in the <code>benches</code> folder. We add the following to <code>cargo.toml</code></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>[profile.bench]
debug = true

[dev-dependencies]
iai-callgrind = "0.14.0"
criterion = "0.3"

[[bench]]
name = "iai-bench"
harness = false
<span class="boring">}</span></code></pre>
<p>To get the benchmarking runner, we can quickly compile from source with <code>cargo install --version 0.14.0 iai-callgrind-runner</code>. To benchmark <code>add</code> using <code>iai-callgrind</code> we add the following to <code>benches/iai-bench.rs</code>.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iai_callgrind::{main, library_benchmark_group, library_benchmark};
use std::hint::black_box;

fn add(x: u64, y:u64) -&gt; u64 {
   x+y
}

#[library_benchmark]
#[bench::name(20,20)]
fn bench_add(x: u64,y:u64) -&gt; u64 {
    black_box(add(x,y))
}

library_benchmark_group!(
    name = bench_fibonacci_group;
    benchmarks = bench_add
);

main!(library_benchmark_groups = bench_fibonacci_group);
<span class="boring">}</span></code></pre>
<p>And again run using <code>cargo bench</code>. To specify only running this benchmark we can instead do <code>cargo bench --bench iai-bench</code>. Upon running, you should see something like the following.</p>
<p><img src="https://github.com/user-attachments/assets/8db29f54-0558-435e-a8ae-844bbfd3f312" alt="image">
As you can see, <code>iai</code> is lightweight, fast and can provide some really accurate statistics on instruction count and memory hits. This makes <code>iai</code> perfect for benching in CI workflows!</p>
<h1 id="workflows"><a class="header" href="#workflows">Workflows</a></h1>
<p>Once benchmarking is established, workflows are not too difficult to add too. As discussed before, for CI workflows <code>iai</code> should be used, and not <code>criterion</code>. Take the following example from the <code>tree-morph</code> crate. I will put the code below and then briefly explain each portion. It should not be too difficult to adapt to other benchmarks.</p>
<pre><code class="language-yaml">name: "iai tree-morph Benchmarks"

on:
  push:
    branches:
      - main 
      - auto-bench 
    paths:
      - conjure_oxide/**
      - solvers/**
      - crates/**
      - Cargo.*
      - conjure_oxide/tests/**
      - .github/workflows/iai-tree-morph-benches.yml
  pull_request:
    paths:
      - conjure_oxide/**
      - solvers/**
      - crates/**
      - Cargo.*
      - conjure_oxide/tests/**
      - .github/workflows/iai-tree-morph-benches.yml
  workflow_dispatch:



jobs:
  benches:
    name: "Run iai tree-morph benchmarks"
    runs-on: ubuntu-latest
    timeout-minutes: 10

    strategy:
      # run all combinations of the matrix even if one combination fails.
      fail-fast: false
      matrix:
        rust_release:
          - stable
          - nightly
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: ${{ matrix.rust_release }}

      - name: "Cache Rust dependencies"
        uses: actions/cache@v4
        with:
            path: |
              ~/.cargo/registry
              ~/.cargo/git
              target
            key: ${{ runner.os }}-cargo-${{ matrix.rust_release }}-${{ hashFiles('**/Cargo.lock') }}
            restore-keys: |
              ${{ runner.os }}-cargo-${{ matrix.rust_release }}-
      - name: Install Valgrind
        run: sudo apt-get update &amp;&amp; sudo apt-get install -y valgrind

      - name: Install iai-callgrind-runner
        run: cargo install --version 0.14.0 iai-callgrind-runner

      - name: Run tree-morph benchmarks with iai-callgrind
        run: cargo bench --manifest-path crates/tree_morph/Cargo.toml --bench iai-factorial --bench iai-identity --bench iai-modify_leafs &gt; iai_callgrind_output.txt

      - name: Upload artefact
        uses: actions/upload-artifact@v4
        with:
          name: iai-callgrind-results-${{ matrix.rust_release }}
          path: iai_callgrind_output.txt
</code></pre>
<p>Some comments:</p>
<ul>
<li><code>name</code> just tells GitHub what to call the workflows</li>
<li><code>on</code> tells GitHub <strong>when</strong> to run the workflow</li>
<li><code>jobs</code> is the core of the workflow:
<ul>
<li><code>strategy</code> specifies that we want to run both nightly and stable rust</li>
<li>In <code>steps</code>, we first check out the repository code and set up a specific stable Rust toolchain based on a matrix variable, and then cache Rust dependencies. Next we install the necessary things for valgrind to run, before running benchmarks. We tell the virtual machine to an <code>.txt</code> file and upload it as an artefact.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="design-documents"><a href="#design-documents" class="header">Design Documents</a></h1>
<div style="break-before: page; page-break-before: always;"></div><!-- maturity: draft
authors: Niklas Dewally, Hanaa Khan
created: 08-12-23
---- -->
<!-- TODO: highlight essence syntax -->
<!-- TODO: put stuff from 'improve this page', and to make complete documentation for all the crates (they all point back to the regular docs, idk if they'll need more specificity), into the 'things you could do' page -->
<h1 id="202311-high-level-plan"><a class="header" href="#202311-high-level-plan">2023‐11: High Level Plan</a></h1>
<p><em>This page is a summary of discussions about the architecture of the project circa November 2023.</em></p>
<p>In brief:</p>
<img src="developers_guide/design_documents/handDrawnDiagram.jpeg" width="300">
<h2 id="conjure-oxide-1"><a class="header" href="#conjure-oxide-1">Conjure Oxide</a></h2>
<h3 id="model-rewriting-engine"><a class="header" href="#model-rewriting-engine">Model Rewriting Engine</a></h3>
<p>The purpose of the model rewriting engine is to turn a high level constraints model into one that can be run by various solvers.
It incrementally rewrites a given model by applying a series of rules.</p>
<p>Rules have the type:</p>
<pre><code class="language-rs">rule :: fn(Expr) -&gt; Result&lt;Expr,Error&gt;
</code></pre>
<p>The use of <code>Result</code> here allows for the type checking of the Model at each stage (amongst other things).</p>
<p>A sketch of a rewriting algorithm is below. As we are using a <code>Result</code> type, backtracks occur when an <code>Err</code> is returned.</p>
<pre><code>fn apply(rules,x) {
  new_rules = getApplicable(rules)

  if shouldStop(x) {
    return Ok(x)
  }
 
 // Recursive case - multiple rules
  while len(rules') &gt; 0 {
   rule = select(new_rules)
   new_rules.remove(rule)
   res = apply(rules,rule(x))

   if res is Ok, return Ok
  }

  // No rules - base case
  if (compatibleWithSolver(x)) {
    return Ok(x)
  }

  return Err()
}
</code></pre>
<p>This is, in effect, a recursive tree search algorithm. The behaviour of the search can be changed by changing the following functions:</p>
<ul>
<li>getApplicable: <code>fn(Vec&lt;Rule&gt;) -&gt; Vec&lt;Rule&gt;</code></li>
<li>select: <code>fn(Vec&lt;Rule&gt;) -&gt; Vec&lt;Rule&gt;</code></li>
<li>shouldStop: <code>fn(x) -&gt; bool</code></li>
</ul>
<hr>
<p>The following functions are also important to implement the rewriting engine:</p>
<pre><code class="language-haskell">domainOf:: Expr -&gt; Domain
typeOf:: Expr -&gt; Type
typeOfDomain:: Domain -&gt; Type
categoryOf:: Expr -&gt; Category

data Category = Decision | Unknown | Quantified
</code></pre>
<h3 id="solver-adaptors"><a class="header" href="#solver-adaptors">Solver Adaptors</a></h3>
<p>Once we have a Model object that only uses constraints supported by a particular solver, we are able to translate it to a form the solver understands.</p>
<p>The solver adaptor layer translates a Model into solver specific data-structures, and then runs the solvers.</p>
<p>If the given Model isn’t compatible with the solver, the use of a <code>Result</code> type here could allow a type error to be thrown.</p>
<h2 id="other-crates-inside-this-repository"><a class="header" href="#other-crates-inside-this-repository">Other crates inside this repository</a></h2>
<p>This repository contains the code for Conjure Oxide as well as the code for some of its dependencies and related works.</p>
<p>Currently, these are just Rust crates that provide low level bindings to various solvers.</p>
<!-- TODO: is this still the case? should rewrite slightly if not -->
<p>There should be a strict separation of concerns between each crate and Conjure Oxide. In particular, each crate in this project should be considered a separate piece of work that could be independently published and used. Therefore:</p>
<ul>
<li>The crate should have its own complete documentation and examples.</li>
<li>The public API should be safe and make sense outside the context of Conjure Oxide.</li>
</ul>
<h3 id="solver-crates"><a class="header" href="#solver-crates">Solver Crates</a></h3>
<p>Each solver crate should have a API that matches the data structures
used by the solver itself.</p>
<p>Eventually, there will be a way to generically call solvers using common
functions and data structures. However, this is to be defined entirely in Conjure Oxide
and should not affect how the solver crates are written. See <a href="#solver-adaptors">Solver Adaptors</a>.</p>
<!-- ## Improve this page

---

- [ ] Add details about solution returning.
- [ ] Typeset the diagram using graphviz.
- [ ] Add solutions returning to the diagram.
- [ ] What specific error type do rules use? -->
<hr>
<p><em>This section had been taken from the ‘2023‐11: High Level Plan’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div><!-- maturity: draft
authors: Niklas Dewally, Hanaa Khan
created: 21-03-24
---- -->
<!-- TODOs -->
<h1 id="202403-implementing-uniplates-and-biplates-with-structure-preserving-trees"><a class="header" href="#202403-implementing-uniplates-and-biplates-with-structure-preserving-trees">2024‐03: Implementing Uniplates and Biplates with Structure Preserving Trees</a></h1>
<h2 id="contents"><a class="header" href="#contents">Contents:</a></h2>
<ul>
<li><a href="#recap-uniplates-and-biplates">Recap: Uniplates and Biplates</a></li>
<li><a href="#definition-of-children">Definition of Children</a></li>
<li><a href="#storing-the-structure-of-children">Storing The Structure of Children</a></li>
<li><a href="#uniplates-and-biplates-using-structure-preserving-trees">Uniplates and Biplates Using Structure Preserving Trees</a></li>
</ul>
<p>Comments and discussion about this document can be found in issue <a href="https://github.com/conjure-cp/conjure-oxide/issues/261">#261</a>.</p>
<hr>
<p>In <a href="https://github.com/conjure-cp/conjure-oxide/pull/180">#180</a> and <a href="https://github.com/conjure-cp/conjure-oxide/pull/259">#259</a> we implemented the basic Uniplate interface and a derive macro to automatically implement it for <code>enum</code> types. However, our current implementation is incorrect and problematic: we have defined children wrong; and our children list does not preserve structure, making more complex nested structures hard to recreate in the context function.</p>
<h2 id="recap-uniplates-and-biplates"><a class="header" href="#recap-uniplates-and-biplates">Recap: Uniplates and Biplates</a></h2>
<p><em>A quick recap of what we are trying to do - for details, see the <a href="https://hackage.haskell.org/package/uniplate">Uniplate Haskell docs</a>, our Github Issues, and the paper.</em></p>
<!-- TODO: which paper?? n are there other issues besides the stated one -->
<p>Uniplates are an easy way to perform recursion over complex recursive data types.</p>
<p>It is typically used with enums containing multiple variants, many of which may be different types.</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U
       | D [T]
</code></pre>
<p>With Uniplate, one can perform a map over this with very little or no boilerplate.</p>
<p>This is implemented with a single function <code>uniplate</code> that returns a <em>list of children</em> of the current object and a <em>context</em> function to rebuild the object from a list of children.</p>
<p>Biplates provide recursion over instances of type <code>T</code> within some other type <code>U</code>. They are implemented with a single function <code>biplate</code> of similar type to <code>uniplate</code> (returning <em>children</em> and a <em>context</em> function).</p>
<p>These functions are able to be implemented on any data type through macros making Uniplate operations boilerplate free.</p>
<h2 id="definition-of-children"><a class="header" href="#definition-of-children">Definition of Children</a></h2>
<p>We currently take <em>children of T</em> to mean <em>direct descendants of T inside T</em>. However, the correct definition of children is <em>maximal substructures of type T</em>.</p>
<p>For example, consider these Haskell types:</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U
       | D [T]

data U = E T T
       | F Integer
       | G [T] T
</code></pre>
<p>Our current implementation would define children as the following:</p>
<pre><code class="language-hs">children (A t1 _) = [t1]
children (B t1 t2) = [t1, t2]
children (C t1 u) = [t1]
children (D ts) = ts
</code></pre>
<p>However, the proper definition should support transitive children - i.e. T contains a U which contains a T:</p>
<pre><code class="language-hs">children (A t1 _) = [t1]
children (B t1 t2) = [t1, t2]
children (C t1 (E t2 t3)) = [t1,t2,t3]
children (C t1 (F _)) = [t1]
children (C t1 (G ts t3)) = [t1] ++ ts ++ [t3]
children (D ts) = ts
</code></pre>
<p>While a seemingly small difference, this complicates how we reconstruct a node from its children: we now need to create a context that takes a list of children and creates an arbitrarily deeply nested data structure containing multiple different types. In particular, the challenge is keeping track of which elements of the children list go into which fields of the enum we are creating.</p>
<p>We already had this problem dealing with children from lists, but a more general approach is needed.</p>
<h2 id="storing-the-structure-of-children"><a class="header" href="#storing-the-structure-of-children">Storing The Structure of Children</a></h2>
<p>How do we know which children go into which fields of the enum variant?</p>
<p>For example, consider this complicated instance of <code>T</code>:</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U 
       | D [T]

data U = E T T
       | F Integer
       | G [T] T

myT = C(D([t0,...,t5),G([t6,...,t12],t13))
</code></pre>
<p>Its list of children is: <code>[t0,...,t13]</code>.</p>
<p>Try creating a function to recreate <code>myT</code> based on a new list of children. <em>Hint: it is difficult, and even more so in full generality!</em></p>
<p>If we instead consider children to be a tree, where each field in the original enum variant is its own branch, we get:</p>
<pre><code class="language-hs">data Tree A = Zero | One A | Many [(Tree A)]

myTChildren = 
  Many [(Many [One(t0),...,One(t5)]),      -- C([XXX], _) field 1 of C
        (Many [                            -- C([_],XXX)  field 2 of C
          (Many [One(t6),...,One(t12)]),   -- G([XXX],_)  field 2.1 of C
          (One  t13))]                     -- G([_],XXX)) field 2.2 of C
</code></pre>
<p>This captures, in a type-independent way, the following structural information:</p>
<ol>
<li><code>myT</code> has two fields.</li>
<li>The first field is a container of Ts.</li>
<li>The second field contains two inner fields: one is a container of Ts, one is a single T.</li>
</ol>
<p><strong>Representing non-recursive and primitive types</strong></p>
<p>Often primitive and non-recursive types are found in the middle of enum variants. How do we say <em>“we don’t care about this field, it does not contain a T”</em> with our <code>Tree</code> type? <code>Zero</code> can be used for this.</p>
<p>For example:</p>
<pre><code class="language-hs">data V = V1 V Integer W
       | V2 Integer

data W = W1 V V

myV = (V1 
        (V2 1) 
        1 
        (W1 
          (V2 2) 
          (V2 3)))

myVChildren = 
  (Many [
    (One v1),  -- V1(XXX,_,_)
    Zero,      -- V1(_,XXX,_) 
    (Many [    -- V1(_,_,XXX)
      (One v2),
      (One v3)
   ]))
</code></pre>
<p>This additionally encodes the information that the second field of <code>myV</code> has no Ts at all.</p>
<p>While this information isn’t too useful for finding or traversing over the target type, it means that the tree structure defines the structure of the target type completely: there are always the same number of tree branches as there are fields in the enum variant.</p>
<h2 id="uniplates-and-biplates-using-structure-preserving-trees"><a class="header" href="#uniplates-and-biplates-using-structure-preserving-trees">Uniplates and Biplates Using Structure Preserving Trees</a></h2>
<p>Recall that the <code>uniplate</code> function returns all <em>children</em> of a data structure alongside a <em>context</em> function that rebuilds the data structure using some new children.</p>
<p>To implement this, for each field in an enum variant, we need to ask the questions: <em>“how do we get the type <code>T</code>s in the type <code>U</code>”</em>, and <em>“how can we rebuild this <code>U</code> based on some new children of type <code>T</code>?”</em>.</p>
<p>This is just a <code>Biplate&lt;U,T&gt;</code>, which gives us the <em>type <code>T</code> children within a type <code>U</code></em> as well as a <em>context function to reconstruct the <code>U</code> from the <code>T</code></em>.</p>
<p>Therefore:</p>
<ul>
<li>
<p>We build the <em>children</em> tree by combining the children trees of all fields of the enum (such that each field’s children is a branch on the tree).</p>
</li>
<li>
<p>We build the <em>context</em> function by calling each fields context function on each branch of the input tree.</p>
</li>
</ul>
<p>This is effectively a recursive invocation of <code>Biplate</code>.</p>
<p>What happens when we reach a T? Under the normal definition, <code>Biplate&lt;T,T&gt;</code> would return its children. This is wrong - we want to return <code>T</code> here, not its children!</p>
<p>When <code>T == U</code> we need to change the definition of a Biplate: <strong><code>Biplate&lt;T,T&gt;</code> operates over the input structure, not its children.</strong></p>
<p>For our example AST:</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U 
       | D [T]

data U = E T T
       | F Integer
       | G [T] T
</code></pre>
<p>Here are some Biplate and Uniplates and their resultant children trees:</p>
<ul>
<li>
<p><code>Biplate&lt;Integer,T&gt; 1</code> is <code>Zero</code>.</p>
</li>
<li>
<p><code>Uniplate&lt;T&gt; (A t [1,2,3])</code> is <code>(Many [Biplate&lt;T,T&gt; t ,Zero])</code>.</p>
<p>This evaluates to <code>(Many [(One t),Zero])</code></p>
</li>
<li>
<p><code>Biplate&lt;T,T&gt; t</code> is <code>One t</code>.</p>
</li>
<li>
<p><code>Biplate&lt;T,U&gt; (G ts t1)</code> is <code>(Many [Biplate&lt;T,[T]&gt; ts , Biplate&lt;T,T&gt; t ])</code>.</p>
<p>This evaluates to <code>(Many [(Many [(One t0),...(One tn)]),(One t)])</code></p>
</li>
<li>
<p><code>Uniplate&lt;T,T&gt; (C t (G ts t1))</code> is <code>(Many [Biplate&lt;T,T&gt; t, Biplate&lt;U,T&gt; (G ts t1))</code></p>
<p>This evaluates to <code>(Many [(One t), (Many [(Many [(One t0),...,(One tn)]), (One t)]))</code></p>
</li>
</ul>
<!-- vim: cc=100 spell
-->
<hr>
<p><em>This section had been taken from the ‘2024‐03: Implementing Uniplates and Biplates with Structure Preserving Trees’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div><!-- maturity: draft
authors: Felix Leitner, Niklas Dewally, Hanaa Khan
created: 19-09-24
---- -->
<!-- TODO edit more -->
<!-- syntax highlighting -->
<h1 id="semantics-of-rewriting-expressions-with-sideeffects"><a class="header" href="#semantics-of-rewriting-expressions-with-sideeffects">Semantics of Rewriting Expressions with Side‐Effects</a></h1>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<hr>
<p>When rewriting expressions, a rule may occasionally introduce new variables and constraints. For example, a rule which handles the <code>Min</code> expression may introduce a new variable <code>aux</code> which represents the minimum value itself, and introduce constraints <code>aux &lt;= x</code> for each <code>x</code> in the original <code>Min</code> expression. Conjure and Conjure Oxide provide similar methods of achieving these “side-effects”.</p>
<h2 id="reductions"><a class="header" href="#reductions">Reductions</a></h2>
<hr>
<p>In Conjure Oxide, reduction rules return <code>Reduction</code> values. These contain a new expression, a new (possibly empty) set of top-level constraints, and a new (possibly empty) symbol table. The two latter values are brought up to the top of the AST during rewriting and joined to the model. These reductions, or “local sub-models” therefore can define new requirements which must hold across the model for the change that is made to a specific node of the AST to be valid.</p>
<p>The example with <code>Min</code> given in the overview is one case where plain <code>Reduction</code>s are used, as a new variable with a new domain is introduced, along with constraints which must hold for that variable.</p>
<h2 id="bubbles"><a class="header" href="#bubbles">Bubbles</a></h2>
<hr>
<p>Reductions are not enough in all cases. For example, when handling a possibly undefined value, changes must be made in the context of the current expression. Simply introducing new top-level constraints may lead to incorrect reductions in these cases. The <code>Bubble</code> expression and associated rules take care of this, bringing new constraints up the tree gradually and expanding in the correct context.</p>
<p>Essentially, <code>Bubble</code> expressions are a way of attaching a constraint to an expression to say “X is only valid if Y holds”. One example of this is how Conjure Oxide handles division. Since the division expression may possibly be undefined, a constraint must be attached to it which asserts the divisor is != 0.</p>
<p>An example of division handling is shown below. Bubbles are shown as <code>{X @ Y}</code>, where X is the expression that Y is attached to.</p>
<pre><code>!(a = b / c)                 Original expression

!(a = {(b / c) @ c != 0})    b/c is possibly undefined, so introduce a bubble saying the divisor is != 0

!({(a = b / c) @ c != 0})    "bubble up" the expression, since b / c is not a bool-type expression

!(a = b / c /\ c != 0)       Now that X is a bool-type expression, we can simply expand the bubble into a conjunction
</code></pre>
<p>Why not just use <code>Reduction</code>s to assert at the top-level of the model that <code>c != 0</code>? In the context of undefinedness handling, the final reduction is dependent on the context it occurs in. In the above example, if we continue by simplifying (apply DeMorgan’s), we can see that it becomes <code>a != b / c \/ c = 0</code>. Thus, c = 0 is a valid assignment for this example to be true, and setting <code>c != 0</code> on the top-level would be incorrect.</p>
<p>In Conjure Oxide, Bubbles are often combined with the power of <code>Reduction</code>s to provide support for solvers like Minion.</p>
<hr>
<p><em>This section had been taken from the ‘Semantics of Rewriting Expressions with Side‐Effects’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="what-we-didnt-do"><a class="header" href="#what-we-didnt-do">What we didn’t do</a></h1>
<p>The intention of this page is to chronicle decisions made during the development of conjure-oxide. There have been many situations where we have thought of something interesting that ends up not being the best solution to a problem and we believe others may come up with the same ideas. This page should be read before contributing so that potential contributors do not go down rabbit holes that have already been thoroughly searched.</p>
<details>
<summary>
<h2>Nested expressions within the polymorphic metadata field </h2>
</summary>
<h3 id="background"><a class="header" href="#background">Background</a></h3>
<p>As discussed in <a href="https://github.com/conjure-cp/conjure-oxide/issues/182">Issue 182</a>, we wanted to create a polymorphic metadata field that would be contained within the expression struct and that could be changed on a case-by-case basis as metadata might only be needed for a single module for example.</p>
<h3 id="what-we-thought-of"><a class="header" href="#what-we-thought-of">What we thought of</a></h3>
<p>One interesting idea that was suggested as a structure like this:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Define a trait for metadata in each module.
pub trait Metadata {
    // Define methods specific to the metadata.
    fn print_metadata(&amp;self);
    // Add other methods as needed.
}

// Module-specific metadata types.
pub mod module1 {
    pub struct Metadata1 {
        // Define fields specific to this metadata.
        pub clean: bool,
        // Add other fields as needed.
    }

    impl super::Metadata for Metadata1 {
        fn print_metadata(&amp;self) {
            println!("Metadata1: Clean - {}", self.clean);
        }
    }
}

pub mod module2 {
    pub struct Metadata2 {
        // Define fields specific to this metadata.
        pub status: String,
        // Add other fields as needed.
    }

    impl super::Metadata for Metadata2 {
        fn print_metadata(&amp;self) {
            println!("Metadata2: Status - {}", self.status);
        }
    }
}

// Modify the Expression enum to hold a trait object for metadata.
#[derive(Clone, Debug)]
pub enum Expression {
    // Existing enum variants here...
    WithMetadata(Box&lt;Expression&gt;, Option&lt;Box&lt;dyn Metadata&gt;&gt;),
}

impl Expression {
    // Create a new expression with metadata.
    pub fn with_metadata(expr: Expression, metadata: Option&lt;Box&lt;dyn Metadata&gt;&gt;) -&gt; Expression {
        Expression::WithMetadata(Box::new(expr), metadata)
    }

    // Extract the expression and metadata.
    pub fn extract_metadata(self) -&gt; (Expression, Option&lt;Box&lt;dyn Metadata&gt;&gt;) {
        match self {
            Expression::WithMetadata(expr, metadata) =&gt; (*expr, metadata),
            _ =&gt; (self, None),
        }
    }

    // Set metadata for an expression.
    pub fn set_metadata(&amp;mut self, metadata: Option&lt;Box&lt;dyn Metadata&gt;&gt;) {
        if let Expression::WithMetadata(_, ref mut existing_metadata) = *self {
            *existing_metadata = metadata;
        }
    }

    // Get metadata for an expression.
    pub fn get_metadata(&amp;self) -&gt; Option&lt;&amp;dyn Metadata&gt; {
        if let Expression::WithMetadata(_, Some(metadata)) = self {
            Some(metadata.as_ref())
        } else {
            None
        }
    }

    // Existing methods here...
}

<span class="boring">}</span></code></pre>
<h3 id="why-we-didnt-do-it"><a class="header" href="#why-we-didnt-do-it">Why we didn’t do it</a></h3>
<p>This is nice in the sense that there is less “ugliness” when creating expressions as there is no need to have metadata in every enum variant. However, this severely effects the way that the rewriter traverses the AST as there is now WithMetadata objects sprinkled throughout the AST which would require some way to traverse up the tree while saving the context of nodes below the metadata object. This image shows the differences in a basic AST:</p>
<img src="https://github.com/conjure-cp/conjure-oxide/assets/27870413/09726bf0-c2ef-4056-b7c3-e011f148774b" width="300" height="600">
<h3 id="what-we-did-do"><a class="header" href="#what-we-did-do">What we did do</a></h3>
<p>Due to this issue we decided that a simpler implementation where metadata is explicitly required every time but could be set to some empty metadata object was more practical. More details on this implementation can found in <a href="https://github.com/conjure-cp/conjure-oxide/pull/233">Near Future PR</a></p>
</details>
<hr>
<p><em>This section had been adapted from the ‘What we didn’t do’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="cicd"><a href="#cicd" class="header">CI/CD</a></h1>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="coverage"><a href="#coverage" class="header">Coverage</a></h1>
<h2 id="user-guide"><a class="header" href="#user-guide">User Guide</a></h2>
<ol>
<li>
<p>Run coverage with <code>./tools/coverage.sh</code>.</p>
</li>
<li>
<p>Open this in a web-browser by opening <code>target/debug/coverage/index.html</code>.</p>
</li>
<li>
<p>An <code>lcov</code> file is generated at <code>target/debug/lcov.info</code> for in-editor coverage.</p>
<ul>
<li>If you use VSCode, configuration for this should be provided when you clone the repo. Click the “watch” button in the status bar to view coverage for a file.</li>
</ul>
</li>
</ol>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>See the code for full details: <a href="https://github.com/conjure-cp/conjure-oxide/blob/main/tools/coverage.sh">tools/coverage.sh</a>.</p>
<p>A high level overview is:</p>
<ol>
<li>The project is built and tested using instrumentation based coverage.</li>
<li>Grcov is used to aggregate these reports into <code>lcov.info</code> and <code>html</code> formats.</li>
<li>The <code>lcov.info</code> file can be used with the <code>lcov</code> command to generate summaries and get coverage information. This is used to make the summaries in our PR coverage comments.</li>
</ol>
<p><strong>Reading:</strong></p>
<ol>
<li><a href="https://github.com/mozilla/grcov">grcov readme - how to generate coverage reports</a>.</li>
<li><a href="https://doc.rust-lang.org/rustc/instrument-coverage.html">rustc book - details on instrumentation based coverage</a>.</li>
</ol>
<h3 id="doc-coverage"><a class="header" href="#doc-coverage">Doc Coverage</a></h3>
<p><strong>Text:</strong> This prints a doc coverage table for all crates in the repo:</p>
<pre><code class="language-sh">RUSTDOCFLAGS='-Z unstable-options --show-coverage' cargo +nightly doc --workspace --no-deps 
</code></pre>
<p><strong>JSON:</strong>
Although we don’t use it yet, we can get doc coverage information as JSON. This will be useful for prettier and more useful output:</p>
<pre><code class="language-sh">RUSTDOCFLAGS='-Z unstable-options --show-coverage --output-format json' cargo +nightly doc --workspace --no-deps 
</code></pre>
<p><strong>Reading</strong></p>
<p>See the unstable options section of the rustdoc book. <a href="https://doc.rust-lang.org/rustdoc/unstable-features.html">Link</a>.</p>
<hr>
<p><em>This section had been taken from the ‘Coverage’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div><!-- TODO: Edit this -->
<h1 id="github-actions-cookbook"><a class="header" href="#github-actions-cookbook">Github Actions Cookbook</a></h1>
<ul>
<li>This document lists common patterns and issues we’ve had in our Github actions, and practical solutions to them.</li>
<li>The first point of reference should be the official documentation, but if that is ever unclear, here would be a good place to look!</li>
</ul>
<p>Terminology used in this document:</p>
<ul>
<li>A <em>workflow</em> contains multiple independently ran <em>tasks</em>. Each task runs a series of <em>steps</em>. Steps can call predefined <em>actions</em>, or run shell commands.</li>
</ul>
<h2 id="i-want-to-have-a-step-output-multilined--complex-text"><a class="header" href="#i-want-to-have-a-step-output-multilined--complex-text">I want to have a step output multilined / complex text</a></h2>
<pre><code class="language-yml">- name: Calculate PR doc coverage
  id: prddoc
  run: |
    RUSTDOCFLAGS='-Z unstable-options --show-coverage' cargo +nightly doc --workspace --no-deps &gt; coverage.md
    echo 'coverage&lt;&lt;EOFABC' &gt;&gt; $GITHUB_OUTPUT
    echo "$(cat coverage.md)" &gt;&gt; $GITHUB_OUTPUT
    echo 'EOFABC' &gt;&gt; $GITHUB_OUTPUT```
</code></pre>
<p>The entire output of <code>cargo doc</code> can be substituted into later jobs by using <code>${{ steps.prdoc.outputs.coverage }}</code></p>
<h2 id="workflow_run-i-want-a-workflow-that-runs-on-a-pr-and-can-write-to-the-repo"><a class="header" href="#workflow_run-i-want-a-workflow-that-runs-on-a-pr-and-can-write-to-the-repo">workflow_run: I want a workflow that runs on a PR and can write to the repo</a></h2>
<p>PR branches and their workflows typically live in on a branch on an external fork. Therefore, they cannot write to the repository. The solution is to split things into two workflows - one that runs on the PR with read-only permissions, and one that runs on main and can write to the repository. This is called a <code>workflow_run</code> workflow. Read <a href="https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#workflow_run">the docs</a>.</p>
<p><strong>The workflow_run workflow should not run any user provided code as it has secrets in scope.</strong></p>
<h2 id="i-want-to-access-the-calling-pr-in-a-workflow_run-workflow"><a class="header" href="#i-want-to-access-the-calling-pr-in-a-workflow_run-workflow">I want to access the calling PR in a workflow_run workflow</a></h2>
<p><code>workflow_run</code> jobs do not get access to the calling workflows detail. While one can access some things via the Github API such as head_sha, head_repo, this may not give any PR information. <a href="https://securitylab.github.com/research/github-actions-preventing-pwn-requests/">Github</a> recommends saving the PR number to an artifact, and using this number to fetch the PR info through the API:</p>
<p>Example from <a href="https://securitylab.github.com/research/github-actions-preventing-pwn-requests/">this github blog post</a> - see this for more explanation and details!</p>
<pre><code class="language-yml">name: Receive PR

# read-only repo token
# no access to secrets
on:
  pull_request:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:        
      - uses: actions/checkout@v2

      # imitation of a build process
      - name: Build
        run: /bin/bash ./build.sh

      - name: Save PR number
        run: |
          mkdir -p ./pr
          echo ${{ github.event.number }} &gt; ./pr/NR
      - uses: actions/upload-artifact@v2
        with:
          name: pr
          path: pr/
</code></pre>
<pre><code class="language-yml">name: Comment on the pull request

# read-write repo token
# access to secrets
on:
  workflow_run:
    workflows: ["Receive PR"]
    types:
      - completed

jobs:
  upload:
    runs-on: ubuntu-latest
    if: &gt;
      github.event.workflow_run.event == 'pull_request' &amp;&amp;
      github.event.workflow_run.conclusion == 'success'
    steps:
      - name: 'Download artifact'
        uses: actions/github-script@v3.1.0
        with:
          script: |
            var artifacts = await github.actions.listWorkflowRunArtifacts({
               owner: context.repo.owner,
               repo: context.repo.repo,
               run_id: ${{github.event.workflow_run.id }},
            });
            var matchArtifact = artifacts.data.artifacts.filter((artifact) =&gt; {
              return artifact.name == "pr"
            })[0];
            var download = await github.actions.downloadArtifact({
               owner: context.repo.owner,
               repo: context.repo.repo,
               artifact_id: matchArtifact.id,
               archive_format: 'zip',
            });
            var fs = require('fs');
            fs.writeFileSync('${{github.workspace}}/pr.zip', Buffer.from(download.data));
      - run: unzip pr.zip

      - name: 'Comment on PR'
        uses: actions/github-script@v3
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            var fs = require('fs');
            var issue_number = Number(fs.readFileSync('./NR'));
            await github.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue_number,
              body: 'Everything is OK. Thank you for the PR!'
            });

</code></pre>
<h2 id="how-do-i-get-x-commit-inside-a-pr-workflow-what-do-all-the-different-github-shas-mean"><a class="header" href="#how-do-i-get-x-commit-inside-a-pr-workflow-what-do-all-the-different-github-shas-mean">How do I get x commit inside a PR workflow? What do all the different github sha’s mean?</a></h2>
<p><strong>If you are running in a workflow_run workflow, you will need to get the calling PR first. See <a href="https://github.com/conjure-cp/conjure-oxide/wiki/_new#i-want-to-access-the-calling-pr-in-a-workflow_run-workflow">I want to access the calling PR in a workflow_run workflow</a> instead.</strong></p>
<p>The default <code>github.sha</code> is a temporary commit representing the state of the repo should the PR be merged now. You probably want <code>github.event.pull_request.head.sha</code>. Read <a href="https://www.kenmuse.com/blog/the-many-shas-of-a-github-pull-request/">The many SHAs of a github pull request</a>.</p>
<hr>
<p><em>This section had been taken from the ‘Github Actions’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="overview-2"><a class="header" href="#overview-2">Overview</a></h1>
<p>The parser converts incoming Essence programs to Conjure Oxide to the <a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_core/ast/struct.Model.html">Model Object</a> that the rule engine takes in. The relevant parts of the Model object are the SymbolTable and Expression objects. The symbol table is essentially a list of the variables and their corresponding domains. The Expression object is a recursive object that hold all the constraints of the problem, nested into one object. The parser has two main parts. The first the <code>tree-sitter-essence</code> crate, which is a general Essence parser using the library tree-sitter. The second part is the <code>conjure_essence_parser</code> crate which is Rust code that uses the grammar to parse Essence programs and convert them into the above-mentioned Model object.</p>
<h1 id="tree-sitter-grammar"><a class="header" href="#tree-sitter-grammar">Tree Sitter Grammar</a></h1>
<p><a href="https://tree-sitter.github.io/tree-sitter/">Tree-sitter</a> is a parsing library that creates concrete syntax trees from programs in various languages. It contains many languages already, but Essence is unfortunately not one of them. Therefore, this crate contains a JavaScript grammar for Essence, which tree-sitter uses to create a parser. The parser is not specific to Conjure Oxide as the grammar merely describes the general Essence language, but it is used in Conjure Oxide and currently covers only parts of the Essence language that Conjure Oxide deals with and has tests written for. Therefore, it is not extensive and relatively simple in structure.</p>
<h2 id="general-structure"><a class="header" href="#general-structure">General Structure</a></h2>
<p>At the top level, there can be either find statements, letting statements, and constraint statements. Find statements consist of the keyword <code>find</code>, one or more variables, and then a domain of either type boolean or integer. Letting statements have the keyword <code>letting</code>, one or more variables, and an expression or domain to assign to those variables. Constraints contain the keyword <code>such that</code> and one or more logical or numerical expressions which include variables and constants.</p>
<h2 id="expression-hierarchy"><a class="header" href="#expression-hierarchy">Expression Hierarchy</a></h2>
<p>Expressions in the grammar are broken down into boolean expressions, comparison expressions, and arithmetic expressions. This separation helps enforce semantic constraints inherent to the language. For example, expressions like <code>x + 3 = y</code> are allowed because an arithmetic expression is permitted on either side of a comparison, but chained comparisons like <code>x = y = 3</code> are disallowed, since a comparison expression cannot itself contain another comparison expression as an operand. This also helps ensure the top-most expression in a constraint evaluates to a boolean (so <code>such that x + 3</code> wouldn’t be valid). There are also <code>atom</code> expressions such as constants, identifiers, and structured values (tuples, matrices, or slices), which are allowed as operands to most expressions since they might be booleans. This does mean, however, that a constraint like <code>such that y</code> would be valid even though <code>y</code> might be an integer. Quantifier expressions are also separated into boolean and arithmetic quantifiers for this reason (so <code>such that allDif{[a, b]}</code> is valid but <code>such that min{[a,b]}</code> isn’t).</p>
<p>The precedence levels throughout the grammar are based on the Essence prime operator precedence table found in Appendix B of the <a href="https://arxiv.org/pdf/2201.03472">Savile Row Manual</a>. This is important to ensure that nested or complicated expressions such as <code>(2*x) + (3*y) = 12</code> are parsed in the correct order, as this will determine the structure of the Expression object in the Model.</p>
<h2 id="issue-763"><a class="header" href="#issue-763"><a href="https://github.com/conjure-cp/conjure-oxide/issues/763">Issue #763</a></a></h2>
<p>Currently, the grammar allows for any combination of letters, numbers, and underscores to be parsed as a variable identifiers. This includes reserved keywords of the Essence language such as ‘find’ or ‘letting’. This is incorrect and such keyword shouldn’t be allowed as variables. A solution to this problem hasn’t been found. Below are notes about possible solutions.</p>
<ul>
<li>Tree-sitter doesn’t support lookahead assertions so grammar rules cannot exclude specific patterns or words.</li>
<li>Defining rules for each keyword (with higher precedence than the identifier rule) has been brought up but it doesn’t stop keywords from being parsed as variables within a rule searching for identifiers (more detail in linked issue).</li>
<li>It is possible to manually check all identifier nodes in the parse tree within the Rust program against a list of keywords (or by defining rules for keywords and allowing identifiers to be parsed as them or a valid identifier). This would allow for rejecting Essence programs that merely use a keyword as an identifier and have no other errors but wouldn’t allow for correct parsing of errors such as the one in line 2 of the program below. The extra ‘=’ in line two causes ‘such’ in line 3 to be parsed as an identifier and thus the whole of line 3 is parsed as an error, even though it is valid. If ‘such’ could be excluded as a valid identifier, the error would be only in line 2.</li>
</ul>
<pre><code class="language-Essence">find x,y,z : int(0..5)
such that x = y =
such that z = 3
</code></pre>
<h1 id="rust-parser"><a class="header" href="#rust-parser">Rust Parser</a></h1>
<p>This is the second part of the parser and is contained in the <a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_essence_parser/index.html">conjure_essence_parser</a> crate. The primary function is <code>parse_essence_file_native</code>, shown below, which takes in the path to the input and the context and returns the Model or an error.</p>
<pre><code class="language-Rust">pub fn parse_essence_file_native(
    path: &amp;str,
    context: Arc&lt;RwLock&lt;Context&lt;'static&gt;&gt;&gt;,
) -&gt; Result&lt;Model, EssenceParseError&gt; {...}
</code></pre>
<p>Within that function, the source code is read from the input and the tree-sitter grammar is used to parse that code and produce a parse tree. From there, a Model object is created and the <code>SymbolTable</code> and <code>Expression</code> fields are populated by traversing and extracting information from the parse tree.</p>
<h2 id="general-structure-and-utils"><a class="header" href="#general-structure-and-utils">General Structure and utils</a></h2>
<p>The top level nodes (children of the root node), are either extras (comments or language labels), find statements, letting statements, or constraints. Find and letting statements provide info that is added to the SymbolTable while constraints are added to the Expression.</p>
<p>In general, <code>kind()</code> is used to determine which rule a node represents and the corresponding function or logic is then applied to that node. Child nodes are found using their field names or indexes and the <code>named_children()</code> function is used to iterate over the named child nodes of a node. The function <code>child_expr</code> returns the Expression parsed from the first named child of the given node.</p>
<h3 id="extracting-from-the-source-code-identifiers-and-constants"><a class="header" href="#extracting-from-the-source-code-identifiers-and-constants">Extracting from the source code (identifiers and constants)</a></h3>
<p>The tree-sitter nodes have a start and end byte indicating where the node corresponds to in the source code. For variable identifiers, constants, and operators, these bytes are necessary to extract the actual values from the source code.</p>
<p>For example, the following code appears in the <code>parse_find_statement</code> function and is used to extract the specific variable name from the source code, which is represented simply by a tree-sitter node (named <code>variable</code> in this case).</p>
<pre><code class="language-Rust">let variable_name = &amp;source_code[variable.start_byte()..variable.end_byte()];
</code></pre>
<p>Another example is when parsing expressions, the node representing the operator is not always ‘named’, meaning it is not its own rule in the grammar and rather specified directly in the rule (ex. <code>exponent: $ =&gt; seq($.arithmetic_expr, "**", $.arithmetic_expr)</code> (simplified)), or the operator one of multiple choices in a rule (ex. <code>mulitcative_op: $ =&gt; choice("*", "/", "%")</code>). In this situation, the same method as for the variable identifiers is used:</p>
<pre><code class="language-Rust">let op = constraint.child_by_field_name("operator").ok_or(format!(
        "Missing operator in expression {}",
        constraint.kind()
    ))?;
let op_type = &amp;source_code[op.start_byte()..op.end_byte()];
</code></pre>
<h2 id="find-and-letting-statements"><a class="header" href="#find-and-letting-statements">Find and Letting Statements</a></h2>
<p>Find and letting statements are parsed relatively intuitively. For find statements, the list of variables is iterated over and each is added to a hash map as the key. Then, the domain is parsed and added as the value for each variable it applies to. Once all variables and domains are parsed, the hash map is returned and the caller function iterates over it and adds each pair to the <code>SymbolTable</code>. For letting statements, a new <code>SymbolTable</code> is created. The variables are again iterated over and added to the table. Letting statements can either specify a domain or an expression for the variables so the type of node is checked and either parsed as an expression or domain before being added to the table. The <code>SymbolTable</code> is returned and the caller function adds it to the existing <code>SymbolTable</code> of the <code>Model</code>.</p>
<h2 id="constraints"><a class="header" href="#constraints">Constraints</a></h2>
<p>Adding constraints to the overall constraints <code>Expression</code> requires nesting <code>Expression</code> objects in a consistent and clear manner. Each constraint is parsed using the <code>parse_expression</code> function, which returns an <code>Expression</code> object, and is then added to the model using the <code>add_constraints</code> function. The <code>parse_expression</code> function takes a node as a parameter and is recursive. It matches the node to its ‘kind’, recursively parses the children of the node, then returns an <code>Expression</code> object that correctly packages up the expressions returned from the parsing of the children nodes.</p>
<p>This structure allows for easy addition of more complex constraints as the grammar evolves. As more rules are added to the grammar, the corresponding code block must be added to the match statement in the <code>parse_expression</code> function.</p>
<h3 id="example-1"><a class="header" href="#example-1">Example</a></h3>
<p>The constraint <code>x = 3</code> would be represented by a <code>comparison_expr</code> node, which is defined in the grammar as:</p>
<pre><code class="language-Javascript">comparison_expr: $ =&gt; prec(0, prec.left(seq(
      field("left", choice($.boolean_expr, $.arithmetic_expr)), 
      field("operator", $.comparative_op),
      field("right", choice($.boolean_expr, $.arithmetic_expr))
    ))),
</code></pre>
<p>In the parse_expression function, the left expression is parsed using the <code>child_expr</code> function. The returned Expression would represent the variable <code>x</code> and be saved as <code>expr1</code>. The operator is extracted from the source code and saved as <code>op_type</code>. The right expression node is then found using its field name ‘right’ and parsed. The returned Expression would represent the integer <code>3</code> and be saved as <code>expr2</code>.</p>
<pre><code class="language-Rust">let expr1 = child_expr(constraint, source_code, root)?;
            let op = constraint.child_by_field_name("operator").ok_or(format!(
                "Missing operator in expression {}",
                constraint.kind()
            ))?;
            let op_type = &amp;source_code[op.start_byte()..op.end_byte()];
            let expr2_node = constraint.child_by_field_name("right").ok_or(format!(
                "Missing second operand in expression {}",
                constraint.kind()
            ))?;
            let expr2 = parse_expression(expr2_node, source_code, root)?;

            match op_type {...}
</code></pre>
<p>Depending on the operator type (in this case <code>=</code>), the left and right expressions are added to an Expression of the relevant type (in this case <code>Eq</code>), which is returned.</p>
<pre><code class="language-Rust">"=" =&gt; Ok(Expression::Eq(
                    Metadata::new(),
                    Box::new(expr1),
                    Box::new(expr2),
                )),
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<p>Tree-morph is a library that helps you perform boilerplate-free generic tree transformations. In its current state, tree-morph is able to perform transformations in a large number of test cases, and work is now being done to try to implement Essence with tree-morph. When completed, tree-morph will be a very powerful stand-alone crate, as well as sitting at the core of <code>conjure-oxide</code>. Despite its current power, there is a still a lot of work to be done on the <code>tree-morph</code> crate. It is currently in a completely unoptimised state, and will be very slow when performing on large trees with a rich rule set and rule hierarchy. In order to assess progress on new optimisations, it is essential to have a diverse list of benchmarks. All benchmarking has been done using the <a href="https://crates.io/crates/criterion">crtiterion</a> crate. The following section outlines some of the most important benchmarks.</p>
<h1 id="benchmarks"><a class="header" href="#benchmarks">Benchmarks</a></h1>
<h2 id="identity"><a class="header" href="#identity">identity</a></h2>
<p>The <code>identity benchmark</code> is a test designed to capture how long one tree traversal takes. There is no metadata, and the only rule is <code>do_nothing</code> which is never evaluated. The helper function <code>construct_tree</code> creates a simple tree of variable depth. This is an important benchmark to make sure that new proposed changes do not negatively effect <code>tree-morph</code> traversal speed.</p>
<p>Filename: <code>conjure-oxide/crates/tree_morph/benches/identity.rs</code></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{black_box, criterion_group, criterion_main, Criterion};
use tree_morph::prelude::*;
use uniplate::derive::Uniplate;

#[derive(Debug, Clone, PartialEq, Eq, Uniplate)]
#[uniplate()]
enum Expr {
    Branch(Box&lt;Expr&gt;, Box&lt;Expr&gt;),
    Val(i32),
}
struct Meta {}
fn do_nothing(cmds: &amp;mut Commands&lt;Expr, Meta&gt;, subtree: &amp;Expr, meta: &amp;Meta) -&gt; Option&lt;Expr&gt; {
    None
}

fn construct_tree(n: i32) -&gt; Box&lt;Expr&gt; {
    if n == 1 {
        Box::new(Expr::Val(0))
    } else {
        Box::new(Expr::Branch(Box::new(Expr::Val(0)), construct_tree(n - 1)))
    }
}

pub fn criterion_benchmark(c: &amp;mut Criterion) {
    let base: i32 = 2;
    let expr = *construct_tree(base.pow(5));
    let rules = vec![vec![do_nothing]];

    c.bench_function("Identity", |b| {
        b.iter(|| {
            morph(
                black_box(rules.clone()),
                select_first,
                black_box(expr.clone()),
                Meta {},
            )
        })
    });
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
<span class="boring">}</span></code></pre>
<h2 id="modify_leafs"><a class="header" href="#modify_leafs">modify_leafs</a></h2>
<p>The <code>modify_leafs</code> benchmark is designed to capture how long it takes for a simple modification rule to be applied to all of the leaf nodes. The function <code>construct_tree</code> creates a tree of variable depth with all leaf nodes initialised to 0. There is no metadata and the only function <code>zero_to_one</code> changes a leaf node of 0 to a leaf node of 1. It should be expected that this will take a lot longer than the identity benchmark, as when a node is changed in <code>tree-morph</code>, an entirely new tree is created.</p>
<p>Filename: <code>conjure-oxide/crates/tree_morph/benches/modify_leafs.rs</code></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{black_box, criterion_group, criterion_main, Criterion};
use tree_morph::prelude::*;
use uniplate::derive::Uniplate;

#[derive(Debug, Clone, PartialEq, Eq, Uniplate)]
#[uniplate()]
enum Expr {
    Branch(Box&lt;Expr&gt;, Box&lt;Expr&gt;),
    Val(i32),
}

struct Meta {} // not relevant for this benchmark

fn zero_to_one(cmds: &amp;mut Commands&lt;Expr, Meta&gt;, subtree: &amp;Expr, meta: &amp;Meta) -&gt; Option&lt;Expr&gt; {
    if let Expr::Val(a) = subtree {
        if let 0 = *a {
            return Some(Expr::Val(1));
        }
    }
    None
}

fn construct_tree(n: i32) -&gt; Box&lt;Expr&gt; {
    if n == 1 {
        Box::new(Expr::Val(0))
    } else {
        Box::new(Expr::Branch(Box::new(Expr::Val(0)), construct_tree(n - 1)))
    }
}

pub fn criterion_benchmark(c: &amp;mut Criterion) {
    let base: i32 = 2;
    let expr = *construct_tree(base.pow(5));
    let rules = vec![vec![zero_to_one]];

    c.bench_function("Modify_leafs", |b| {
        b.iter(|| {
            morph(
                black_box(rules.clone()),
                select_first,
                black_box(expr.clone()),
                Meta {},
            )
        })
    });
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
<span class="boring">}</span></code></pre>
<h2 id="factorial"><a class="header" href="#factorial">factorial</a></h2>
<p>The <code>factorial</code> benchmark is the most difficult benchmark currently made, and an improved score on factorial will be indicative of serious gains in optimisations. As the name suggests, <code>factorial</code> is centred around the mathematical factorial operation (<code>5! = 5*4*3*2*1</code>), which will grow the tree depth, providing a rich set of transformations for <code>tree-morph</code> to calculate. The tree generating function <code>random_exp_tree</code> here takes as input a random seed and a max depth, and generates a tree of an arithmetic expression involving values, additions, multiplications and factorials. An example of such an expression with a random seed of <code>41</code> and a max depth of <code>5</code> is shown below.</p>
<pre><code class="language-bash">(((8 + 1!) + (1 * 3)!) + (1!! * ((2 + 1) * (1 * 1))))!
</code></pre>
<p>It is worth mentioning that this expression is extremely large due to the nested factorials, and as such we need a way of making sure that calculations are bounded. This is achieved by modding the results of any additions and multiplications in the <code>rule_eval_add</code> and <code>rule_eval_mul</code> functions by <code>10</code>, which will bound all factorial expressions by <code>10!</code>. The benchmark counts the number of addition and multiplication rule applications, and also has a high priority dummy rule <code>do_nothing</code>, in order to increase the benchmark difficulty.</p>
<p>Filename: <code>conjure-oxide/crates/tree_morph/benches/factorial.rs</code></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{black_box, criterion_group, criterion_main, Criterion};
use rand::rngs::StdRng;
use rand::{Rng, SeedableRng};
use tree_morph::prelude::*;
use uniplate::derive::Uniplate;

#[derive(Debug, Clone, PartialEq, Eq, Uniplate)]
#[uniplate()]
enum Expr {
    Add(Box&lt;Expr&gt;, Box&lt;Expr&gt;),
    Mul(Box&lt;Expr&gt;, Box&lt;Expr&gt;),
    Val(i32),
    Factorial(Box&lt;Expr&gt;),
}

fn random_exp_tree(rng: &amp;mut StdRng, count: &amp;mut usize, depth: usize) -&gt; Expr {
    if depth == 0 {
        *count += 1;
        return Expr::Val(rng.random_range(1..=3));
    }

    match rng.random_range(1..=13) {
        x if (1..=4).contains(&amp;x) =&gt; Expr::Add(
            Box::new(random_exp_tree(rng, count, depth - 1)),
            Box::new(random_exp_tree(rng, count, depth - 1)),
        ),
        x if (5..=8).contains(&amp;x) =&gt; Expr::Mul(
            Box::new(random_exp_tree(rng, count, depth - 1)),
            Box::new(random_exp_tree(rng, count, depth - 1)),
        ),
        x if (8..=11).contains(&amp;x) =&gt; {
            Expr::Factorial(Box::new(random_exp_tree(rng, count, depth - 1)))
        }
        _ =&gt; Expr::Val(rng.random_range(1..=10)),
    }
}
fn do_nothing(cmds: &amp;mut Commands&lt;Expr, Meta&gt;, subtree: &amp;Expr, meta: &amp;Meta) -&gt; Option&lt;Expr&gt; {
    None
}

fn factorial_eval(cmds: &amp;mut Commands&lt;Expr, Meta&gt;, subtree: &amp;Expr, meta: &amp;Meta) -&gt; Option&lt;Expr&gt; {
    if let Expr::Factorial(a) = subtree {
        if let Expr::Val(n) = *a.as_ref() {
            if n == 0 {
                return Some(Expr::Val(1));
            }
            return Some(Expr::Mul(
                Box::new(Expr::Val(n)),
                Box::new(Expr::Factorial(Box::new(Expr::Val(n - 1)))),
            ));
        }
    }
    None
}

fn rule_eval_add(cmds: &amp;mut Commands&lt;Expr, Meta&gt;, subtree: &amp;Expr, meta: &amp;Meta) -&gt; Option&lt;Expr&gt; {
    if let Expr::Add(a, b) = subtree {
        if let (Expr::Val(a_v), Expr::Val(b_v)) = (a.as_ref(), b.as_ref()) {
            cmds.mut_meta(|m| m.num_applications_addition += 1);
            return Some(Expr::Val((a_v + b_v) % 10));
        }
    }
    None
}

fn rule_eval_mul(cmds: &amp;mut Commands&lt;Expr, Meta&gt;, subtree: &amp;Expr, meta: &amp;Meta) -&gt; Option&lt;Expr&gt; {
    if let Expr::Mul(a, b) = subtree {
        if let (Expr::Val(a_v), Expr::Val(b_v)) = (a.as_ref(), b.as_ref()) {
            cmds.mut_meta(|m| m.num_applications_multiplication += 1);
            return Some(Expr::Val((a_v * b_v) % 10));
        }
    }
    None
}

#[derive(Debug)]
struct Meta {
    num_applications_addition: i32,
    num_applications_multiplication: i32,
}

pub fn criterion_benchmark(c: &amp;mut Criterion) {
    let seed = [41; 32];
    let mut rng = StdRng::from_seed(seed);
    let mut count = 0;

    let my_expression = random_exp_tree(&amp;mut rng, &amp;mut count, 10);
    let rules = vec![
        rule_fns![do_nothing],
        rule_fns![rule_eval_add, rule_eval_mul, factorial_eval],
    ];

    c.bench_function("factorial", |b| {
        b.iter(|| {
            let meta = Meta {
                num_applications_addition: 0,
                num_applications_multiplication: 0,
            };
            morph(
                black_box(rules.clone()),
                select_first,
                black_box(my_expression.clone()),
                black_box(meta),
            )
        })
    });
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
<span class="boring">}</span></code></pre>
<h2 id="left_addleft_add_hard"><a class="header" href="#left_addleft_add_hard">left_add/left_add_hard</a></h2>
<p>The benchmarks <code>left_add</code> and <code>left_add_hard</code> are two benchmarks that evaluate a very simple nested addition expression <code>(1+(1+(1+...)))</code> of variable depth. In its unoptimised state, all but he final two instances of a <code>1</code> node will undergo several superfluous rule checks. The benchmark <code>left_add_hard</code> also is identical to <code>left_add</code>, except there are also four additional dummy rules, all assigned with a higher priority than the <code>rule_eval_add</code>. As expected, this will reduce code performance by about 400% (shown later). The code for <code>left_add_hard</code> is shown below, with <code>left_add</code> being very similar.</p>
<p>Filename: <code>conjure-oxide/crates/tree_morph/benches/left_add_hard.rs</code></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{black_box, criterion_group, criterion_main, Criterion};
use tree_morph::prelude::*;
use uniplate::derive::Uniplate;

#[derive(Debug, Clone, PartialEq, Eq, Uniplate)]
#[uniplate()]
enum Expr {
    Add(Box&lt;Expr&gt;, Box&lt;Expr&gt;),
    Val(i32),
}

fn rule_eval_add(_: &amp;mut Commands&lt;Expr, Meta&gt;, expr: &amp;Expr, _: &amp;Meta) -&gt; Option&lt;Expr&gt; {
    match expr {
        Expr::Add(a, b) =&gt; match (a.as_ref(), b.as_ref()) {
            (Expr::Val(x), Expr::Val(y)) =&gt; Some(Expr::Val(x + y)),
            _ =&gt; None,
        },
        _ =&gt; None,
    }
}

#[derive(Clone)]
enum MyRule {
    EvalAdd,
    Fee,
    Fi,
    Fo,
    Fum,
}

impl Rule&lt;Expr, Meta&gt; for MyRule {
    fn apply(&amp;self, cmd: &amp;mut Commands&lt;Expr, Meta&gt;, expr: &amp;Expr, meta: &amp;Meta) -&gt; Option&lt;Expr&gt; {
        cmd.mut_meta(|m| m.num_applications += 1); // Only applied if successful
        match self {
            MyRule::EvalAdd =&gt; rule_eval_add(cmd, expr, meta),
            MyRule::Fee =&gt; None,
            MyRule::Fi =&gt; None,
            MyRule::Fo =&gt; None,
            MyRule::Fum =&gt; None,
        }
    }
}

#[derive(Clone)]
struct Meta {
    num_applications: u32,
}

fn val(n: i32) -&gt; Box&lt;Expr&gt; {
    Box::new(Expr::Val(n))
}

fn add(lhs: Box&lt;Expr&gt;, rhs: Box&lt;Expr&gt;) -&gt; Box&lt;Expr&gt; {
    Box::new(Expr::Add(lhs, rhs))
}

fn nested_addition(n: i32) -&gt; Box&lt;Expr&gt; {
    if n == 1 {
        val(1)
    } else {
        add(val(1), nested_addition(n - 1))
    }
}

pub fn criterion_benchmark(c: &amp;mut Criterion) {
    let base: i32 = 2;
    let expr = *nested_addition(base.pow(5));
    let rules = vec![
        vec![MyRule::Fi],
        vec![MyRule::Fee],
        vec![MyRule::Fo],
        vec![MyRule::Fum],
        vec![MyRule::EvalAdd],
    ];

    c.bench_function("left_add_hard", |b| {
        b.iter(|| {
            let meta = Meta {
                num_applications: 0,
            };
            morph(rules.clone(), select_first, black_box(expr.clone()), meta)
        })
    });
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
<span class="boring">}</span></code></pre>
<h2 id="right_add"><a class="header" href="#right_add">right_add</a></h2>
<p>The benchmark <code>right_add</code> is identical to <code>left_add</code>, except there now we are evaluating <code>((...+1)+1)</code> instead. This is designed to show the inherent left bias used in <code>tree-morph</code>. Performance is a little better than <code>left_add</code>. Due to the similarity with <code>left_add</code>, the code is omitted.</p>
<h1 id="results"><a class="header" href="#results">results</a></h1>
<p>The most helpful feature that <code>criterion</code> produces is its automatic graphing software. Upon a run of <code>cargo bench</code>, <code>criterion</code> automatically produces html reports of all benchmarks, accessible in <code>conjure-oxide/target/criterion</code>. An example report is shown below.
<img width="1300" alt="image" src="https://github.com/user-attachments/assets/963c76eb-2d8c-4c77-8529-8b9b6bc22dc3" />
The left graph is a probability density function for the run time. It says that on average it takes <code>854.26 µs</code> for identity to run at a fixed depth (in this case <code>2^5</code> was used). The right graph is a cumulative time plot. The fact that the line is almost straight indicates that the run times are all very comparable in time. The additional stats provided are all standard statistics measurements, with MAD standing for the mean absolute deviation.</p>
<h2 id="identity-vs-modify_leafs"><a class="header" href="#identity-vs-modify_leafs">identity vs modify_leafs</a></h2>
<p>The probability density functions for <code>identity</code> and <code>modify_leafs</code> are shown below, both evaluated a tree depth of <code>2^5</code>.
<img width="550" alt="image" src="https://github.com/user-attachments/assets/06fd9c0e-b094-4a5f-ab5e-6d88b3ace29a" />
<img width="547.5" alt="image" src="https://github.com/user-attachments/assets/2e31067d-a848-4259-bf67-bf516c70a6cf" /></p>
<p>As you can see, <code>modify_leafs</code> takes significantly longer (<code>2300%</code>) than <code>identity</code> on average, showing how costly even simple tree transformations take. This is most likely due to the fact that <code>tree-morph</code> does not edit in-place, but rather constructs a new tree after applying a transformation.</p>
<h2 id="factorial-1"><a class="header" href="#factorial-1">factorial</a></h2>
<p>The following is the probability density function for <code>factorial</code>, ran at a max depth of <code>10</code> and a seed of <code>[41; 32]</code>.
<img src="https://github.com/user-attachments/assets/afb83193-b33c-452b-a5ba-8b9b9ae66f1a" alt="image"></p>
<p>As you can see, even for a relatively small max depth compute is large. Also note that <code>factorial</code> still has a very small amount of rule groupings, and performance would likely be orders of magnitude worse if a number of rules comparable to a <code>conjure</code> problem was presented. This shows a significant need for optimisations, and an improved score on <code>factorial</code> would indicate a lot of good progress.</p>
<h2 id="left_add-vs-left_add_hard"><a class="header" href="#left_add-vs-left_add_hard">left_add vs left_add_hard</a></h2>
<p>A comparison between <code>left_add</code> and <code>left_add_hard</code> is a clear demonstration of how detrimental duplicate rule checks can be for performance.</p>
<p><img src="https://github.com/user-attachments/assets/ae292d37-f26d-4080-9520-019f60476e93" alt="image">
<img src="https://github.com/user-attachments/assets/2f882085-71fc-4d13-a266-ead400db31e8" alt="image"></p>
<p>Ignoring the differences between the shapes of the graphs (I am unsure why this is the case), we can immediately notice how the extra 4 dummy rules in <code>left_add_hard</code> lead to almost exactly a <code>400%</code> increase in performance!</p>
<h1 id="further-work"><a class="header" href="#further-work">Further work</a></h1>
<p>Benchmarks are still in an early stage, and there is lots more to do. Some ideas for future work include:</p>
<ul>
<li>Set up some automated infrastructure for running benchmarks automatically on GitHub</li>
<li>Find out scaling laws for increasing tree depth for current benchmarks</li>
<li>Set up some head to head tests between two functions</li>
<li>Set up counters that can measure things like node counts, maximum tree depths and other useful information</li>
<li>Benchmark individual functions (such as a rule application) in order to better understand how trees grow and shrink during transformations</li>
<li>Benchmark meta applications</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="overview-3"><a class="header" href="#overview-3">Overview</a></h1>
<p>ProTrace is a tracing module created to trace rule applications on expressions when an Essence file is parsed and rewritten by Conjure Oxide. The purpose of the module is to visualise the rules applied on the expressions, and simplify the identification of errors for debugging. The module supports multiple output formats such as <strong>JSON</strong> or <strong>human</strong> readable, along with different verbosity levels to show only what the user would like to see.</p>
<h3 id="verbosity-level"><a class="header" href="#verbosity-level">Verbosity Level</a></h3>
<p>The different verbosity levels include:</p>
<ul>
<li><strong><code>High</code></strong>: All rule applications.</li>
<li><strong><code>Medium</code></strong> (default): Successful rule applications.</li>
<li><strong><code>Low</code></strong>: Only errors are shown (to be implemented).</li>
</ul>
<p>Outputs of the trace can be saved in a JSON or text file (depending on the format of trace) when specified by the user, and if the file path is not given, the output will be stored in the location of the input Essence file by default.</p>
<p>The module also provides filtering functionalities for displaying specific rule or rule set applications.</p>
<hr>
<h1 id="trace-type"><a class="header" href="#trace-type">Trace type</a></h1>
<p>The module is capable of tracing two types of objects: rule and model. A trace can be created using <code>capture_trace</code>, which takes a consumer and a trace type (<a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#rule-trace">RuleTrace</a> or <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#model-trace">ModelTrace</a>).</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn capture_trace(consumer: &amp;Consumer, trace: TraceType)
<span class="boring">}</span></code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum TraceType&lt;'a&gt; {
    RuleTrace(RuleTrace),
    ModelTrace(&amp;'a ModelTrace),
}
<span class="boring">}</span></code></pre>
<h2 id="rule-trace"><a class="header" href="#rule-trace">Rule Trace</a></h2>
<p>Rules are applied to a given expression to rewrite it into the syntax that Conjure understands. These rule applications can be traced by the module to show users what rules have been tried and successfully applied during parsing. A rule trace consists of:</p>
<ul>
<li>An <strong>initial expression</strong></li>
<li>The <strong>name</strong> of the rule being applied</li>
<li>The <strong>priority</strong> of the rule being applied</li>
<li>The <strong>rule set</strong> that the rule belongs to</li>
<li>A <strong>transformed expression</strong> as a result of rule application</li>
<li>An optional <strong>new variable</strong> created during the rule application</li>
<li>An optional <strong>new constraint</strong> added to the top of the expression tree created during the rule application</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RuleTrace {
    pub initial_expression: Expression,
    pub rule_name: String,
    pub rule_priority: u16,
    pub rule_set_name: String,
    pub transformed_expression: Option&lt;Expression&gt;,
    pub new_variables_str: Option&lt;String&gt;,
    pub top_level_str: Option&lt;String&gt;,
}
<span class="boring">}</span></code></pre>
<h2 id="model-trace"><a class="header" href="#model-trace">Model Trace</a></h2>
<p>Models of the problem contain expressions along with some constraints. A model trace consists of:</p>
<ul>
<li>An <strong>initial model</strong></li>
<li>A <strong>rewritten model</strong> after rule application</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ModelTrace {
    pub initial_model: Model,
    pub rewritten_model: Option&lt;Model&gt;,
}
<span class="boring">}</span></code></pre>
<hr>
<h1 id="formatter"><a class="header" href="#formatter">Formatter</a></h1>
<p>Formatters are responsible for converting trace information into a <strong>human-readable</strong> or <strong>JSON</strong> string format before it is output by a consumer.</p>
<p>At the core of this system is the <code>MessageFormatter</code> trait, which defines a common interface for all formatters. There are two built-in formatter implementations provided: <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#human-formatter">HumanFormatter</a> and <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#json-formatter">JsonFormatter</a>.</p>
<h3 id="message-formatter-trait"><a class="header" href="#message-formatter-trait">Message Formatter Trait</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait MessageFormatter: Any + Send + Sync {
    fn format(&amp;self, trace: TraceType) -&gt; String;
}
<span class="boring">}</span></code></pre>
<h2 id="human-formatter"><a class="header" href="#human-formatter">Human Formatter</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HumanFormatter
<span class="boring">}</span></code></pre>
<p>The <code>HumanFormatter</code> implements the <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#message-formatter-trait">MessageFormatter</a> trait by matching on <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#trace-type">TraceType</a> and returning a formatted String.
All <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#trace-type">TraceType</a> variants implement the <code>Display</code> trait, which allows for easy string conversion.</p>
<p><strong>Behaviour:</strong></p>
<ul>
<li>
<p><strong>Successful Rule Applications</strong></p>
<ul>
<li>A message “Successful Transformation” followed by the full formatted <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#rule-trace">RuleTrace</a>, displaying all of its fields.</li>
</ul>
</li>
<li>
<p><strong>Unsuccessful Rule Applications</strong></p>
<ul>
<li>
<p>A message like “Unsuccessful Transformation” followed by a partial display showing only:</p>
<ul>
<li><strong>initial expression</strong></li>
<li><strong>rule name</strong></li>
<li><strong>rule priority</strong></li>
<li><strong>rule set name</strong></li>
</ul>
</li>
<li>
<p>Only shown if the <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#verbosity-level">VerbosityLevel</a> is set to <code>High</code>.</p>
</li>
</ul>
</li>
<li>
<p><strong>Model Traces</strong></p>
<ul>
<li>For <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#model-trace">ModelTrace</a>, it simply displays the initial and rewritten model using its Display implementation.</li>
</ul>
</li>
</ul>
<p><strong>Filtering</strong>:
Before formatting, the <code>HumanFormatter</code> checks if a <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#rule-filters">rule name filter</a> or <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#rule-filters">rule set name filter</a> has been applied.</p>
<h2 id="json-formatter"><a class="header" href="#json-formatter">JSON Formatter</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct JsonFormatter
<span class="boring">}</span></code></pre>
<p>The <code>JsonFormatter</code> implements the <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#message-formatter-trait">MessageFormatter</a> trait by matching on <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#trace-type">TraceType</a> and returning a JSON-formatted String.
It uses the <code>serde_json</code> library to serialize data into a <strong>pretty-printed JSON structure</strong>.</p>
<p><strong>Behaviour</strong>:</p>
<ul>
<li>
<p><strong>Rule Transformations</strong></p>
<ul>
<li>
<p>For <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#rule-trace">RuleTrace</a>, it serializes the entire RuleTrace object into a pretty-printed JSON string using <code>serde_json::to_string_pretty</code>.</p>
</li>
<li>
<p>Similar to <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#human-formatter">HumanFormatter</a> displays both successful and unsuccessful rule applications when the verbosity is high.</p>
</li>
</ul>
</li>
<li>
<p><strong>Model Traces</strong></p>
<ul>
<li>For <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#model-trace">ModelTrace</a>, no JSON output is generated. No need since the parsed and rewritten models are produced in JSON already.</li>
</ul>
</li>
</ul>
<p><strong>Filtering:</strong>
Before formatting, the <code>JsonFormatter</code> checks if a <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#rule-filters">rule name filter</a> or <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#rule-filters">rule set name filter</a> has been applied.</p>
<hr>
<h1 id="consumer"><a class="header" href="#consumer">Consumer</a></h1>
<p>The <strong>Consumer</strong> enum represents different types of endpoints that receive, format, and output <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#trace-type">TraceType</a> data.</p>
<p>Consumers control where the trace data goes to and which format.</p>
<ul>
<li><a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#stdout-consumer">StdoutConsumer</a> prints out the trace to the console</li>
<li><a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#file-consumer">FileConsumer</a> writes the trace data to a file in one of three ways: as human-readable text, as JSON-formatted text, or to both file types simultaneously.</li>
<li><a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#both-consumer">BothConsumer</a> writes to both stdout and file(s).</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Consumer {
    StdoutConsumer(StdoutConsumer),
    FileConsumer(FileConsumer),
    BothConsumer(BothConsumer),
}
<span class="boring">}</span></code></pre>
<h3 id="trace-trait"><a class="header" href="#trace-trait">Trace Trait</a></h3>
<p>Each variant implements the <code>Trace</code> trait, meaning it can capture traces and send them to the appropriate destination.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Trace {
    fn capture(&amp;self, trace: TraceType);
}
<span class="boring">}</span></code></pre>
<h2 id="stdout-consumer"><a class="header" href="#stdout-consumer">Stdout Consumer</a></h2>
<p>A <code>StdoutConsumer</code> outputs the formatted trace data to standard output.</p>
<p>Holds:</p>
<ul>
<li>A reference-counted (Arc) <strong>formatter</strong> that implements the <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#message-formatter-trait">MessageFormatter</a> trait.
<ul>
<li><code>Arc</code> (Atomic Reference Counted pointer) allows safe shared ownership across multiple consumers.</li>
<li>Multiple Consumers might want to share the same formatter without each owning and duplicating it.</li>
</ul>
</li>
<li>A <strong>verbosity</strong> <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#verbosity-level">VerbosityLevel</a> that can influence what gets printed.</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct StdoutConsumer {
    pub formatter: Arc&lt;dyn MessageFormatter&gt;,
    pub verbosity: VerbosityLevel,
}
<span class="boring">}</span></code></pre>
<p><code>dyn</code> = dynamic dispatch. At runtime, it calls the correct format method for the actual formatter.
When capturing a trace:
It formats the trace using its assigned formatter.</p>
<h2 id="file-consumer"><a class="header" href="#file-consumer">File Consumer</a></h2>
<p>A <code>FileConsumer</code> writes the formatted trace data to one or more files.</p>
<p>Holds:</p>
<ul>
<li>A reference-counted (Arc) <strong>formatter</strong>.</li>
<li>A <strong>formatter type</strong> to determine whether to write in Human, JSON, or both formats.</li>
<li><strong>verbosity</strong></li>
<li>Path to the <strong>file for the JSON trace</strong>. (Optional)</li>
<li>Path to the <strong>file for the human-readable trace</strong>. (Optional)</li>
<li><strong>is first</strong> flag used for managing JSON array formatting when appending traces.</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FileConsumer {
    pub formatter: Arc&lt;dyn MessageFormatter&gt;,
    pub formatter_type: FormatterType,
    pub verbosity: VerbosityLevel,
    pub json_file_path: Option&lt;String&gt;, 
    pub human_file_path: Option&lt;String&gt;, 
    pub is_first: std::cell::Cell&lt;bool&gt;, 
}

<span class="boring">}</span></code></pre>
<p>When capturing a trace:</p>
<p>Based on the selected <code>FormatterType</code>:
<strong>Human</strong>: Writes human-readable output to the human file.
<strong>Json</strong>: Writes JSON output to the JSON file.
<strong>Both</strong>: Writes to both files using respective formatters (<a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#human-formatter">HumanFormatter</a> and <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#json-formatter">JsonFormatter</a> directly).</p>
<h2 id="both-consumer"><a class="header" href="#both-consumer">Both Consumer</a></h2>
<p>A <code>BothConsumer </code>sends the formatted trace data to both:</p>
<ul>
<li>Standard output (via an internal <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#stdout-consumer">StdoutConsumer</a>)</li>
<li>Files (via an internal <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#file-consumer">FileConsumer</a>)</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BothConsumer {
    stdout_consumer: StdoutConsumer,
    file_consumer: FileConsumer,
}

<span class="boring">}</span></code></pre>
<p>It combines the behaviours of <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#stdout-consumer">StdoutConsumer</a> and <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#file-consumer">FileConsumer</a> by calling method <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#trace">capture</a> on both its fields.</p>
<hr>
<h1 id="rule-filters"><a class="header" href="#rule-filters">Rule Filters</a></h1>
<p>If users would like to only see specific rules or rule sets during rule application tracing, rule filters can be applied using the command-line argument <code>--filter-rule-name</code> or <code>--filter-rule-set</code> followed by comma-separated rule names or sets. The output will only show rules that is <strong>in the rule filters</strong>, otherwise the rule application will be completely skipped. This feature was added for the abstraction of unimportant rule applications during tracing, allowing users to only see the rules they require.</p>
<p>When both rule name and rule set filters are used in tandem, any rules that pass either the rule name or the rule set filter will be displayed. For example, if the rule name filter is <code>normalise_associative_commutative</code> and the rule set filter is <code>Minion</code>, any rule that has the rule name <code>normalise_associative_commutative</code> or is in the rule set <code>Minion</code> will be displayed.</p>
<p>Rule filters will be applied to both <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#file-consumer">FileConsumer</a> and <a href="https://github.com/conjure-cp/conjure-oxide/wiki/ProTrace-module/_edit#stdout-consumer">StdoutConsumer</a>.</p>
<p>Rule filters can alse be hard-coded into the program or accessed using the following functions:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn set_rule_filter(rule_name: Option&lt;Vec&lt;String&gt;&gt;)

pub fn get_rule_filter() -&gt; Option&lt;Vec&lt;String&gt;&gt;

pub fn set_rule_set_filter(rule_set: Option&lt;Vec&lt;String&gt;&gt;)

pub fn get_rule_set_filter() -&gt; Option&lt;Vec&lt;String&gt;&gt;
<span class="boring">}</span></code></pre>
<h1 id="capturing-general-messages-independent-of-the-main-tracing-functionality-set-by"><a class="header" href="#capturing-general-messages-independent-of-the-main-tracing-functionality-set-by">Capturing general messages (independent of the main tracing functionality set by)</a></h1>
<p>This feature was motivated by the need for a unified interface that allows developers to capture messages—whether to stdout or a file—with the flexibility of a typical debug print statement, but with added control.</p>
<p><code>Default</code> messages are always printed out and additional message types can be filtered and viewed using the command-line argument <code>--get-info-about</code>, followed by the desired message <code>Kind</code>.</p>
<p>For example, running <code>--get-info-about rules</code> will display all the enabled rule sets, individual rules, their assigned priorities, and the sets they belong to. To improve readability, output is color-coded: error messages appear in red, while all other information is shown in green.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Kind {
    Parser,
    Rules,
    Error,
    Solver,
    Model,
    Default,
}
fn display_message(message: String, file_path: Option&lt;String&gt;, kind: Kind)


<span class="boring">}</span></code></pre>
<h1 id="tracing-in-integration-tests"><a class="header" href="#tracing-in-integration-tests">Tracing in integration tests</a></h1>
<p>Similar to how a <code>Consumer</code> is created in solve.rs for <code>cargo run solve</code>, a <code>combined_consumer</code> is manually constructed for each integration test, with its fields explicitly set rather than being derived from command-line arguments. This consumer is configured to log successful rule applications to two separate files—one in a human-readable format and the other in JSON. It is then passed to the <code>rewrite_naive</code> function. By establishing a uniform internal interface for tracing in both <code>cargo run</code> and <code>cargo test</code>, we were able to significantly reduce code duplication and streamline the overall tracing logic.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>   let combined_consumer = create_consumer(
            "file",
            VerbosityLevel::Medium,
            "both",
            Some(format!("{path}/{essence_base}.generated-rule-trace.json")),
            Some(format!("{path}/{essence_base}.generated-rule-trace.txt")),
        );
<span class="boring">}</span></code></pre>
<p>The rule traces is verified using the functions <code>read_human_rule_trace</code> and <code>read_json_rule_trace</code> defined in <code>testing.rs</code> which compare the generated trace output to the expected one. <code>read_json_rule_trace</code> ignores the <code>id</code> fields since they can change from one run to another.</p>
<h1 id="command-line-arguments-and-flags"><a class="header" href="#command-line-arguments-and-flags">Command line arguments and flags</a></h1>
<p>Enable rule tracing</p>
<pre><code>-T, --tracing
</code></pre>
<p>Select output location for trace result: stdout or file [default: stdout]</p>
<pre><code>-L, --trace-output &lt;TRACE_OUTPUT&gt;
</code></pre>
<p>Select verbosity level for trace [default: medium] [possible values: low, medium, high]</p>
<pre><code>--verbosity &lt;VERBOSITY&gt;
</code></pre>
<p>Select the format of the trace output: human or json [default: human]</p>
<pre><code>-F, --formatter &lt;FORMATTER&gt;
</code></pre>
<p>Optionally save traces to specific files: first for JSON, second for human format</p>
<pre><code>-f, --trace-file [&lt;JSON_TRACE&gt; &lt;HUMAN_TRACE&gt;]
</code></pre>
<p>Filter messages by given kind [possible values: parser, rules, error, solver, model, default]</p>
<pre><code>--get-info-about &lt;KIND_FILTER&gt;
</code></pre>
<p>Filter rule trace to only show given rule names (comma separated)</p>
<pre><code>--filter-rule-name &lt;RULE_NAME_FILTER&gt;
</code></pre>
<p>Filter rule trace to only show given rule set names (comma separated)</p>
<pre><code>--filter-rule-set &lt;RULE_SET_FILTER&gt;</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<blockquote>
<p>NOTE: Once the rewrite engine API is finalized, we should possibly make a separate page for it</p>
</blockquote>
<!-- maturity: draft
authors: Georgii Skorokhod
created: 16-02-24
---- -->
<!-- TODO edit more -->
<h1 id="expression-rewriting-rules-and-rulesets"><a class="header" href="#expression-rewriting-rules-and-rulesets">Expression rewriting, Rules and RuleSets</a></h1>
<blockquote>
<p>NOTE: Once the rewrite engine API is finalised, we should possibly make a separate page for it.</p>
</blockquote>
<h1 id="overview-4"><a class="header" href="#overview-4">Overview</a></h1>
<p>Conjure uses Essence, a high-level DSL for constraints modelling, and converts it into a solver-specific representation of the problem.
To do that, we parse the Essence file into an AST, then use a rule engine to walk the expression tree and rewrite constraints into a format that is accepted by the solver before passing the AST to a solver adapter.</p>
<p>The high-level process is as follows:</p>
<ol>
<li>Start with a deterministically ordered list of rules</li>
<li>For each node in the expression tree:
<ul>
<li>Find all rules that can be applied to it</li>
<li>If there are none, keep traversing the tree. Otherwise:
<ul>
<li>Take the rules with the highest priority</li>
<li>If there is only one, apply it</li>
<li>If there are multiple, use some strategy to choose a rule
(the rule selection logic is separate from the rewrite engine itself).
For testing, we currently just choose the first rule</li>
</ul>
</li>
</ul>
</li>
<li>When there are no more rules to apply, the rewrite is complete</li>
</ol>
<p>We want the rewrite process to:</p>
<ul>
<li>be <strong>flexible</strong> - instead of hard coding the rules, we want an easy way to extend the list of rules and to decide which rules to use, both for ourselves and for any users who may wish to use conjure-oxide in their projects</li>
<li>be <strong>deterministic</strong> (in a loose sense of the term) - for a given input, set of rules, and a given set of answers to all rule selection questions (see above), the rewriter must always produce the same output</li>
<li>happen in a single step, instead of doing multiple passes over the model (like it is done in Saville Row currently)</li>
</ul>
<h1 id="rules"><a class="header" href="#rules">Rules</a></h1>
<h2 id="overview-1-1"><a class="header" href="#overview-1-1">Overview</a></h2>
<p>Rules are the fundamental part of the rewrite engine.
They consist of:</p>
<ul>
<li>A unique <strong>name</strong></li>
<li>An application function which takes an <code>Expression</code> and either rewrites it or errors if the rule is not applicable.
(Checking applicability and applying the rule are not separated to avoid code duplication and inefficiency - their logic is the same)</li>
</ul>
<p>We may also store other metadata in the <code>Rule</code> struct, for example the names of the <code>RuleSet</code>s that it belongs to.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Rule&lt;'a&gt; {
    pub name: &amp;'a str,
    pub application: fn(&amp;Expression) -&gt; Result&lt;Expression, RuleApplicationError&gt;,
    pub rule_sets: &amp;'a [(&amp;'a str, u8)], // (name, priority). At runtime, we add the rule to rulesets
}
<span class="boring">}</span></code></pre>
<h2 id="registering-rules"><a class="header" href="#registering-rules">Registering Rules</a></h2>
<p>The main way to register rules is by defining their application function and decorating it with the <code>#[register_rule()]</code> macro.
When this macro is invoked, it creates a static <code>Rule</code> object and adds it to a global rule registry. Rules may be registered from the <code>conjure_oxide</code> crate, or any downstream crate (so, users may define their own rules).</p>
<p>Currently, the <code>register_rule</code> macro has the following syntax:</p>
<pre><code>#[register_rule(("&lt;RuleSet name&gt;", &lt;Rule priority within the ruleset&gt;))]
</code></pre>
<h3 id="example-2"><a class="header" href="#example-2">Example</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use conjure_core::ast::Expression;
use conjure_core::rule::RuleApplicationError;
use conjure_rules::register_rule;

#[register_rule(("RuleSetName", 10))]
fn identity(expr: &amp;Expression) -&gt; Result&lt;Expression, RuleApplicationError&gt; {
   Ok(expr.clone())
}
<span class="boring">}</span></code></pre>
<h2 id="getting-rules-from-the-registry"><a class="header" href="#getting-rules-from-the-registry">Getting Rules from the registry</a></h2>
<p>Rules may be retrieved using the following functions:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get_rule_by_name(name: &amp;str) -&gt; Option&lt;&amp;'static Rule&lt;'static&gt;&gt;
<span class="boring">}</span></code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get_rules() -&gt; Vec&lt;&amp;'static Rule&lt;'static&gt;&gt;
<span class="boring">}</span></code></pre>
<ul>
<li><code>get_rules()</code> returns a vector of static references to <code>Rule</code> structs</li>
<li><code>get_rule_by_name()</code> returns a static reference to a specific rule, if it exists</li>
</ul>
<h1 id="rule-sets"><a class="header" href="#rule-sets">Rule Sets</a></h1>
<p>Rule sets group some <code>Rule</code>s together and map them to their priorities.
The <code>rewrite</code> function takes a set of <code>RuleSet</code>s and uses it to resolve a final list of rules, ordered by their priority.</p>
<p>The <code>RuleSet</code> object contains the following fields:</p>
<ul>
<li><code>name</code> The name of the rule set.</li>
<li><code>order</code> The order of the rule set.</li>
<li><code>rules</code> A map of rules to their priorities. This is evaluated lazily at runtime.</li>
<li><code>solvers</code> The solvers that this <code>RuleSet</code> applies for.</li>
<li><code>solver_families</code> The solver families that this <code>RuleSet</code> applies for.</li>
</ul>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>A <code>RuleSet</code> would apply if EITHER of the following is true:</p>
<ul>
<li>The target solver belongs to its list of <code>solvers</code></li>
<li>The target solver belongs to a family that is listed in <code>solver_families</code>, even if it is not explicitly named in <code>solvers</code></li>
</ul>
</blockquote>
<p>It provides the following public methods:</p>
<ul>
<li><code>get_dependencies() -&gt; &amp;HashSet&lt;&amp;'static RuleSet&gt;</code> Get the dependency <code>RuleSet</code>s of this <code>RuleSet</code> (evaluating them lazily if necessary)</li>
<li><code>get_rules() -&gt; &amp;HashMap&lt;&amp;'a Rule&lt;'a&gt;, u8&gt;</code> Get a map of rules to their priorities (performing lazy evaluation - “reversing the arrows” - if necessary)</li>
</ul>
<h2 id="registering-rule-sets"><a class="header" href="#registering-rule-sets">Registering Rule Sets</a></h2>
<p>Like <code>Rule</code>s, <code>RuleSet</code>s may be registered from anywhere within the <code>conjure_oxide</code> crate or any downstream crate.
They are registered using the <code>register_rule_set!</code> macro using the following syntax:</p>
<pre><code>register_rule_set!("&lt;Rule set name&gt;", &lt;order&gt;, ("&lt;name of dependency RuleSet&gt;", ...), (&lt;list of solver families&gt;), (&lt;list of solvers&gt;));
</code></pre>
<p>If a bracketed list is omitted, the corresponding list would be empty. However, you must not break the order.
For example:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>register_rule_set!("MyRuleSet", 10) // This is legal (rule set will have no dependencies, solvers or solver families)
register_rule_set!("MyRuleSet", 10, ("DependencyRS")) // Also legal
register_rule_set!("MyRuleSet", 10, (SolverFamily::CNF)) // This is illegal because dependencies come before solver families
register_rule_set!("MyRuleSet", 10, (), (SolverFamily::CNF)) // But this is fine
<span class="boring">}</span></code></pre>
<h3 id="example-1-1"><a class="header" href="#example-1-1">Example</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>register_rule_set!("MyRuleSet", 10, ("DependencyRuleSet", "AnotherRuleSet"), (SolverFamily::CNF), (SolverName::Minion));
<span class="boring">}</span></code></pre>
<h3 id="adding-rules-to-rulesets"><a class="header" href="#adding-rules-to-rulesets">Adding Rules to RuleSets</a></h3>
<p>Notice that we do not add any rules to the <code>RuleSet</code> when we register it.
Instead, the <code>Rule</code> contains the names of the <code>RuleSets</code> that it needs to be added to.</p>
<p>At runtime, when we first request the <code>rules</code> from a <code>RuleSet</code>, it retrieves a list of all the rules that reference it by name from the registry, and stores static references to the rules along with their priorities.</p>
<p>This is done to allow us to statically initialise <code>Rule</code>s and <code>RuleSet</code>s in a decentralised way across multiple files and store them in a single registry. Dynamic data structures (like <code>Vec</code> or <code>HashMap</code>) cannot be initialised at this stage (Rust has no “life before <code>main()</code>”), so we have to initialise them lazily at runtime.</p>
<p><img src="https://github.com/conjure-cp/conjure-oxide/assets/64529579/6d63547c-6ba0-4eeb-b6ad-0f6ef46f4c43" alt="image"></p>
<p>Internally, we would sometimes refer to this lazy initialisation as “reversing the arrows”.</p>
<h2 id="getting-rulesets-from-the-registry"><a class="header" href="#getting-rulesets-from-the-registry">Getting RuleSets from the registry</a></h2>
<p>Similarly to <code>Rule</code>s, <code>RuleSet</code>s may be retrieved using the following functions:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get_rule_set_by_name(name: &amp;str) -&gt; Option&lt;&amp;'static RuleSet&lt;'static&gt;&gt;
<span class="boring">}</span></code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get_rule_sets() -&gt; Vec&lt;&amp;'static RuleSet&lt;'static&gt;&gt;
<span class="boring">}</span></code></pre>
<h1 id="resolving-a-final-list-of-rules"><a class="header" href="#resolving-a-final-list-of-rules">Resolving a final list of <code>Rule</code>s</a></h1>
<p>Our <code>rewrite</code> function takes an <code>Expression</code> along with a list of <code>RuleSet</code>s to apply:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn rewrite&lt;'a&gt;(
    expression: &amp;Expression,
    rule_sets: &amp;Vec&lt;&amp;'a RuleSet&lt;'a&gt;&gt;,
) -&gt; Result&lt;Expression, RewriteError&gt;
<span class="boring">}</span></code></pre>
<p>Before we start rewriting the AST, we must first resolve the final list of rules to apply.</p>
<p>This is done via the following steps:</p>
<ol>
<li>
<p>Add all given <code>RuleSet</code>s to a set of rulesets</p>
</li>
<li>
<p>Recursively look up all their dependencies by name and add them to the set as well</p>
</li>
<li>
<p>Once we have a final set of <code>RuleSet</code>s:</p>
<ol>
<li>
<p>Construct a <code>HashMap&lt;&amp;Rule, priority&gt;)</code>. This will hold our final mapping of rules to priorities</p>
</li>
<li>
<p>Loop over all the rules of every <code>RuleSet</code></p>
</li>
<li>
<p>If a rule is not yet present in the final <code>HashMap</code>, add it and its priority within the <code>RuleSet</code></p>
</li>
<li>
<p>If it is already present:</p>
<ul>
<li>Compare the order of the current <code>RuleSet</code> and the one that the rule originally came from</li>
<li>If the new <code>RuleSet</code> has a higher order, update the <code>Rule</code>’s priority</li>
</ul>
</li>
</ol>
</li>
<li>
<p>Once all rules have been added to the <code>HashMap</code>:</p>
<ol>
<li>Take all its keys and put them in a vector</li>
<li>Sort it by rule priority</li>
<li>In the case that two rules have the same priority, sort them lexicographically by <code>name</code></li>
</ol>
</li>
</ol>
<p>In the end, we should have a final deterministically ordered list of rules and a <code>HashMap</code> that maps them to their priorities.
Now, we can proceed with rewriting.</p>
<h2 id="why-all-this-weirdness"><a class="header" href="#why-all-this-weirdness">Why all this weirdness?</a></h2>
<h3 id="rule-ordering"><a class="header" href="#rule-ordering">Rule ordering</a></h3>
<p>We want to always have a single deterministic ordering of <code>Rule</code>s. This way, for a given set of rules, the <code>select_rule</code> strategy would always give the same result.</p>
<p>Think of it as a multiple choice quiz: if we want to know that the same numbers in the answer sheet actually correspond to the same set of answers, we must make sure that all students get the questions in the same order.</p>
<p>This is why we sort <code>Rule</code>s by priority, and then use their name (which is guaranteed to be unique) as a tie breaker.</p>
<p>Normally, one would just construct a vector of <code>Rule</code>s and use it as the final ordering, but we cannot do that, because rules are registered in a decentralised way across many files, and when we get them from the rule registry, they are not guaranteed to be in any specific order</p>
<h3 id="ruleset-ordering"><a class="header" href="#ruleset-ordering">RuleSet ordering</a></h3>
<p>As part of resolving the list of rules to use, we need to take rules from multiple <code>RuleSet</code>s and put these rules and their priorities in a <code>HashMap</code>. However, the <code>RuleSet</code>s may overlap (i.e. contain the same rules but with different priorities), and we want to make sure that, for a given set of <code>RuleSet</code>s, the final rule priorities will always be the same.</p>
<p>Normally, this would not be an issue - entries in the <code>HashMap</code> would be added and updated as needed as we loop over the <code>RuleSet</code>s. However, since the <code>RuleSet</code>s are stored in a decentralised registry and are not guaranteed to come in any particular order (i.e. this order may change every time we recompile the project), we need to ensure that the order in which the entries are added to the <code>HashMap</code> (and thus the final rule priorities) doesn’t change.</p>
<p>To achieve this, we use the following algorithm:</p>
<ol>
<li>Loop over all given <code>RuleSet</code>s</li>
<li>Loop over all the rules in a <code>RuleSet</code>
<ul>
<li>If the rule is not present in the <code>HashMap</code>, add it</li>
<li>If the rule is already there:
<ul>
<li>If this <code>RuleSet</code> has a higher <code>order</code> than the one that the rule came from, update its priority</li>
<li>Otherwise, don’t change anything</li>
</ul>
</li>
</ul>
</li>
</ol>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>The <code>order</code> of a <code>RuleSet</code> should not be thought of as a “priority” and does not affect the priorities of the rules in it.
It only provides a consistent order of operations when resolving the final set of rules
NOTE: The <code>order</code> of a <code>RuleSet</code> should not be thought of as a “priority” and does not affect the priorities of the rules in it.
It only provides a consistent order of operations when resolving the final set of rules</p>
</blockquote>
<h2 id="concrete-example--sat-backend-pipeline"><a class="header" href="#concrete-example--sat-backend-pipeline">Concrete Example:  SAT Backend Pipeline</a></h2>
<p>To see how rules and rulesets work in practice, let’s walk through the SAT backend’s transformation of a simple Essence model.</p>
<blockquote>
<p><strong>Note:</strong> The actual RuleSet names and groupings in the codebase may differ from this simplified explanation, but the general priority ordering and transformation pipeline described here is accurate.</p>
</blockquote>
<h3 id="input-model"><a class="header" href="#input-model">Input Model</a></h3>
<pre><code class="language-essence">find x : int(1..3)
find y : int(2..5)
such that x &gt; y
</code></pre>
<h3 id="transformation-pipeline"><a class="header" href="#transformation-pipeline">Transformation Pipeline</a></h3>
<p>The SAT backend applies rules in three priority groups:</p>
<h4 id="1-integer-representation-rules-highest-priority"><a class="header" href="#1-integer-representation-rules-highest-priority">1. Integer Representation Rules (Highest Priority)</a></h4>
<p><strong>RuleSet</strong>: <code>integer_repr</code></p>
<p>These rules convert integer variables into <code>SATInt</code> representations (boolean vectors):</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[register_rule(("integer_repr", 100))]
fn integer_decision_representation(expr: &amp;Expression) -&gt; Result&lt;Expression, RuleApplicationError&gt; {
    // Converts:  find x : int(1..3)
    // Into: SATInt([bool_0, bool_1, ... ])
}
<span class="boring">}</span></code></pre>
<h4 id="2-operation-transformation-rules"><a class="header" href="#2-operation-transformation-rules">2. Operation Transformation Rules</a></h4>
<p><strong>RuleSet</strong>: <code>integer_operations</code></p>
<p>These rules convert operations on <code>SATInt</code>s into boolean expressions:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[register_rule(("integer_operations", 50))]
fn cnf_int_ineq(expr: &amp;Expression) -&gt; Result&lt;Expression, RuleApplicationError&gt; {
    // Converts: SATInt(x) &gt; SATInt(y)
    // Into: complex boolean expression
}
<span class="boring">}</span></code></pre>
<h4 id="3-tseitin-transformation-rules-lowest-priority"><a class="header" href="#3-tseitin-transformation-rules-lowest-priority">3. Tseitin Transformation Rules (Lowest Priority)</a></h4>
<p><strong>RuleSet</strong>: <code>boolean</code></p>
<p>These rules convert the resulting boolean expressions into Conjunctive Normal Form:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[register_rule(("boolean", 10))]
fn tseitin_and(expr: &amp;Expression) -&gt; Result&lt;Expression, RuleApplicationError&gt; {
    // Converts: A AND B
    // Into: auxiliary variable C with clauses enforcing C &lt;-&gt; A AND B
}
<span class="boring">}</span></code></pre>
<h3 id="viewing-the-transformations"><a class="header" href="#viewing-the-transformations">Viewing the Transformations</a></h3>
<p>You can see this pipeline in action using logging:</p>
<pre><code class="language-bash">RUST_LOG=TRACE cargo run -- solve --solver sat my_problem.essence --verbose
</code></pre>
<hr>
<p><em>This section had been taken from the ‘Expression rewriting, Rules and RuleSets’ page of the conjure-oxide wiki</em></p>
<div style="break-before: page; page-break-before: always;"></div>
<p>Introductory notes on the use of “&lt;-” in generators, and the logic behind and() and or() comprehensions. Followed by horizontal set rules. These are representation-independent rules in conjure that are used to rewrite models.</p>
<h1 id="notes"><a class="header" href="#notes">Notes:</a></h1>
<ul>
<li>
<p>“&lt;-” is called an expression projection</p>
<ul>
<li>it creates a generator called GenInExpr</li>
<li>the left hand side has the type of a member of the right hand side</li>
<li>It is used to loop over elements of a set, primarily within and() and or() comprehensions</li>
<li>see <a href="https://conjure.readthedocs.io/en/latest/bits/keyword/expr_projection.html">Expression Projection</a> for more information</li>
</ul>
</li>
<li>
<p>and() - for-all quantifier</p>
<ul>
<li>essentially a series of conjunctions (a ∧ b ∧ .. ∧ z)</li>
<li>states that the body of the contained comprehension must hold <strong>for all</strong> elements specified by the generators and conditions.</li>
</ul>
</li>
<li>
<p>or() - existence quantifier</p>
<ul>
<li>essentially a series of disjunctions (a ∨ b ∨ .. ∨ z)</li>
<li>states that the body of the contained comprehension must hold <strong>for at least one</strong> element specified by the generators and conditions.</li>
</ul>
</li>
<li>
<p>example combining these three concepts:</p>
<ul>
<li>taken from the last section of this page (shown both before and after vertical rules are applied):</li>
</ul>
</li>
</ul>
<pre><code>and([ or([ q5 = q4 | q5 &lt;- A, or([ q6 = q5 | q6 &lt;- B ]) ]) | q4 &lt;- C ])
and([C_Occurrence[q4] -&gt; or([A_Occurrence[q5] ∧ B_Occurrence[q5] ∧ q5 = q4 | q5 : int(0..6)]) | q4 : int(0..6)])
</code></pre>
<p>this translates to:</p>
<pre><code>∀q4 ϵ C: ∃ q5 ϵ A∶(q5=q4) ∧ (∃ q6 ϵ B∶q6=q5 )
</code></pre>
<h1 id="horizontal-rules"><a class="header" href="#horizontal-rules">Horizontal Rules</a></h1>
<h2 id="set-comprehension-literal"><a class="header" href="#set-comprehension-literal">Set-Comprehension-Literal</a></h2>
<p>identifies set literal in model and converts to matrix literal containing the same elements of the same type as the set.</p>
<ol>
<li>takes in Comprehension containing a “body” and generators or conditions “gensOrConds”</li>
<li>matches “gensOrConds” to a tuple containing the Generator “(pat,expr)”, between two generators or conditions, “gocBefore” and “gocAfter”</li>
<li>identifies generator containing pattern and expression, attempts to match expression to a set or multiset</li>
<li>stores elements of set literal in a list of relevant type “tau”</li>
<li>creates matrix literal of type “tau” containing same elements as set literal</li>
<li>returns original comprehension with same body, gocBefore, gocAfter, middle Generator with same pattern but matrix literal replaces set literal</li>
</ol>
<h3 id="code"><a class="header" href="#code">Code:</a></h3>
<pre><code class="language-haskell">     theRule (Comprehension body gensOrConds) = do
         (gocBefore, (pat, expr), gocAfter) &lt;- matchFirst gensOrConds $ \ goc -&gt; case goc of
             Generator (GenInExpr pat@Single{} expr) -&gt; return (pat, matchDefs [opToSet, opToMSet] expr)
             Generator (GenInExpr pat@AbsPatSet{} expr) -&gt; return (pat, matchDefs [opToSet, opToMSet] expr)
             _ -&gt; na "rule_Comprehension_Literal"
         (TypeSet tau, elems) &lt;- match setLiteral expr
         let outLiteral = make matrixLiteral
                             (TypeMatrix (TypeInt TagInt) tau)
                             (DomainInt TagInt [RangeBounded 1 (fromInt (genericLength elems))])
                             elems
         return
             ( "Comprehension on set literals"
             , return $ Comprehension body
                      $  gocBefore
                      ++ [Generator (GenInExpr pat outLiteral)]
                      ++ gocAfter
             )
</code></pre>
<h3 id="example-3"><a class="header" href="#example-3">Example:</a></h3>
<ul>
<li>set-comprehension-literal rule appears within model: “letting A be {1,5,3}, find B : set of int(0..6), such that B subsetEq A”</li>
<li>here the body of the comprehension is “q3 = q2”, the gensOrConds is the single Generator “q3 &lt;- {1,3,5}”</li>
<li>the set literal expression {1,3,5} is replaced with the matrix literal [1,3,5; int(1..3)], the pattern “q3 &lt;-” and the body are left unaffected.</li>
<li>context:
<ul>
<li>q2 is a quantified variable in larger scope (Context #3) – using Occurrence representation here, used to iterate over elements in B</li>
<li>q3 is the quantified variable used to check that each q2 is an element from A = {1,3,5}</li>
</ul>
</li>
</ul>
<pre><code>Picking the first option: Question 1: [q3 = q2 | q3 &lt;- {1, 3, 5}]
                               Context #1: or([q3 = q2 | q3 &lt;- {1, 3, 5}])
                               Context #3: and([or([q3 = q2 | q3 &lt;- {1, 3, 5}]) | q2 : int(0..6), B_Occurrence[q2]])
     Answer 1: set-comprehension-literal: Comprehension on set literals
               [q3 = q2 | q3 &lt;- {1, 3, 5}]
               ~~&gt;
               [q3 = q2 | q3 &lt;- [1, 3, 5; int(1..3)]]
</code></pre>
<h2 id="set-eq-boolean"><a class="header" href="#set-eq-boolean">Set-eq (boolean)</a></h2>
<p>rule for set equality, checks if two sets are equal, i.e. they contain the same elements</p>
<ol>
<li>identifies pattern: “x eq y”</li>
<li>checks that x and y are sets</li>
<li>translates equality into conjunction of two subset-equalities</li>
</ol>
<ul>
<li>i.e. “x eq y” becomes “ “x subsetEq of y” AND “y subsetEq of x” “, using Set-subsetEq rule</li>
</ul>
<h3 id="code-1"><a class="header" href="#code-1">Code:</a></h3>
<pre><code class="language-Haskell">     theRule p = do
         (x,y)     &lt;- match opEq p
         TypeSet{} &lt;- typeOf x
         TypeSet{} &lt;- typeOf y
         return
             ( "Horizontal rule for set equality"
             , return $ make opAnd $ fromList
                 [ make opSubsetEq x y
                 , make opSubsetEq y x
                 ]
             )
</code></pre>
<h3 id="example-1-2"><a class="header" href="#example-1-2">Example:</a></h3>
<pre><code>Picking the first option: Question 1: A = B union C
     Answer 1: set-eq: Horizontal rule for set equality
               A = B union C ~~&gt; A subsetEq B union C /\ B union C subsetEq A
</code></pre>
<h2 id="set-neq-boolean"><a class="header" href="#set-neq-boolean">Set-neq (boolean)</a></h2>
<p>rule for set inequality</p>
<ol>
<li>identifies pattern: “x != y”</li>
<li>checks that x and y are sets</li>
<li>translates inequality to existence of an element that is either in x but not in y, or that is in y but not in x</li>
</ol>
<ul>
<li>i.e. “x != y” becomes “there exists i such that i in x and i not in y, or i in y and i not in x”</li>
</ul>
<h3 id="code-2"><a class="header" href="#code-2">Code:</a></h3>
<pre><code class="language-haskell">     theRule [essence| &amp;x != &amp;y |] = do
         TypeSet{} &lt;- typeOf x
         TypeSet{} &lt;- typeOf y
         return
             ( "Horizontal rule for set dis-equality"
             , do
                  (iPat, i) &lt;- quantifiedVar
                  return [essence|
                          (exists &amp;iPat in &amp;x . !(&amp;i in &amp;y))
                          \/
                          (exists &amp;iPat in &amp;y . !(&amp;i in &amp;x))
                      |]
             )
</code></pre>
<h3 id="example-2-1"><a class="header" href="#example-2-1">Example:</a></h3>
<ul>
<li>checking that the set A is not equal to set B</li>
<li>here q4 is the quantified variable, referred to as “i” above.</li>
<li>“exists” statement is translated using the existence quantifier or(), quantifying over q4 members of A.</li>
<li>The expression projection “&lt;-” creates a generator, in which the lhs has the type of a member of the rhs.
This means the body of the or() comprehension must apply to at least one member (q4) of A (see <a href="https://github.com/conjure-cp/conjure-oxide/wiki/Conjure-Horizontal-Set-Rules#notes">Notes</a>).</li>
</ul>
<pre><code>Picking the first option: Question 1: A != B union C
     Answer 1: set-neq: Horizontal rule for set dis-equality
               A != B union C
               ~~&gt;
               or([!(q4 in B union C) | q4 &lt;- A]) \/
               or([!(q4 in A) | q4 &lt;- B union C])
</code></pre>
<h2 id="set-subseteq-boolean"><a class="header" href="#set-subseteq-boolean">Set-subsetEq (boolean)</a></h2>
<p>rule for subsetEq, checks if one set is contained in another, <strong>they may be equal</strong></p>
<ol>
<li>identifies pattern: “x subsetEq y”</li>
<li>checks that x and y are sets</li>
<li>translates x is subsetEq of y to all elements in x are in y</li>
</ol>
<ul>
<li>i.e. “x subsetEq y” becomes “for all i in x, i in y”</li>
</ul>
<h3 id="code-3"><a class="header" href="#code-3">Code:</a></h3>
<pre><code class="language-haskell">     theRule p = do
         (x,y)     &lt;- match opSubsetEq p
         TypeSet{} &lt;- typeOf x
         TypeSet{} &lt;- typeOf y
         return
             ( "Horizontal rule for set subsetEq"
             , do
                  (iPat, i) &lt;- quantifiedVar
                  return [essence| forAll &amp;iPat in &amp;x . &amp;i in &amp;y |]
             )
</code></pre>
<h3 id="example-3-1"><a class="header" href="#example-3-1">Example:</a></h3>
<ul>
<li>here q3 is the quantified variable, referred to as “i” above.</li>
<li>and() is the universal quantifier, quantifying over q3. and([q3 in B | q3 &lt;- A]) translates to “for all q3 in A, q3 is in B”</li>
<li>The expression projection “&lt;-” creates a generator, in which the lhs has the type of a member of the rhs.
This means the body of the and() comprehension must apply to all members (q3) of A. (see <a href="https://github.com/conjure-cp/conjure-oxide/wiki/Conjure-Horizontal-Set-Rules#notes">Notes</a>).</li>
</ul>
<pre><code>Picking the first option: Question 1: A subsetEq B
     Answer 1: set-subsetEq: Horizontal rule for set subsetEq
               A subsetEq B ~~&gt; and([q3 in B | q3 &lt;- A])
</code></pre>
<h2 id="set-subset-boolean"><a class="header" href="#set-subset-boolean">Set-subset (boolean)</a></h2>
<p>rule for subset, checks if one set is <strong>strictly</strong> contained in another, they cannot be equal</p>
<ol>
<li>identifies pattern: “a subset b”</li>
<li>checks that a and b are sets</li>
<li>translates a is subset of b to a is subsetEq of b, and a is not equal to b</li>
</ol>
<ul>
<li>i.e. “a subset b” becomes “ “a subsetEq b” AND “a neq b” “, using rules Set-subsetEq and Set-neq</li>
</ul>
<h3 id="code-4"><a class="header" href="#code-4">Code:</a></h3>
<pre><code class="language-haskell">     theRule [essence| &amp;a subset &amp;b |] = do
         TypeSet{} &lt;- typeOf a
         TypeSet{} &lt;- typeOf b
         return
             ( "Horizontal rule for set subset"
             , return [essence| &amp;a subsetEq &amp;b /\ &amp;a != &amp;b |]
             )
     theRule _ = na "rule_Subset"
</code></pre>
<h3 id="example-4"><a class="header" href="#example-4">Example:</a></h3>
<pre><code>Picking the first option: Question 1: A subset B
     Answer 1: set-subset: Horizontal rule for set subset
               A subset B ~~&gt; A subsetEq B /\ A != B
</code></pre>
<h2 id="set-supset-boolean"><a class="header" href="#set-supset-boolean">Set-supset (boolean)</a></h2>
<p>rule for superset, checks if one set <strong>strictly</strong> contains another, they cannot be equal</p>
<ol>
<li>identifies pattern: “a supset b”</li>
<li>checks that a and b are sets</li>
<li>translates a is superset of b to b is subset of a, and applies subset rule.</li>
</ol>
<h3 id="code-5"><a class="header" href="#code-5">Code:</a></h3>
<pre><code class="language-haskell">     theRule [essence| &amp;a supset &amp;b |] = do
         TypeSet{} &lt;- typeOf a
         TypeSet{} &lt;- typeOf b
         return
             ( "Horizontal rule for set supset"
             , return [essence| &amp;b subset &amp;a |]
             )
     theRule _ = na "rule_Supset"
</code></pre>
<h3 id="example-5"><a class="header" href="#example-5">Example:</a></h3>
<pre><code>Picking the first option: Question 1: A supset B
     Answer 1: set-supset: Horizontal rule for set supset
               A supset B ~~&gt; B subset A
</code></pre>
<h2 id="set-supseteq-boolean"><a class="header" href="#set-supseteq-boolean">Set-supsetEq (boolean)</a></h2>
<p>rule for supsetEq, checks if one set contains another, <strong>they may be equal</strong></p>
<ol>
<li>identifies pattern: “x supsetEq y”</li>
<li>checks that x and y are sets</li>
<li>translates x is supsetEq of y to y is subsetEq of x, and applies subsetEq rule.</li>
</ol>
<h3 id="code-6"><a class="header" href="#code-6">Code:</a></h3>
<pre><code class="language-haskell">     theRule [essence| &amp;a supsetEq &amp;b |] = do
         TypeSet{} &lt;- typeOf a
         TypeSet{} &lt;- typeOf b
         return
             ( "Horizontal rule for set supsetEq"
             , return [essence| &amp;b subsetEq &amp;a |]
             )
     theRule _ = na "rule_SupsetEq"
</code></pre>
<h3 id="example-6"><a class="header" href="#example-6">Example:</a></h3>
<pre><code>Picking the first option: Question 1: A supsetEq B
     Answer 1: set-subsetEq: Horizontal rule for set supsetEq
               A supsetEq B ~~&gt; B subsetEq A
</code></pre>
<h2 id="set-intersect-describes-a-new-set"><a class="header" href="#set-intersect-describes-a-new-set">Set-intersect (describes a new set)</a></h2>
<p>rule for set intersection. defines that an element is in the intersection of two sets when it is in both sets. similar structure as comprehension literal rule, only used within generators or conditions</p>
<ol>
<li>attempts to match generator to pattern and expression: pattern “<em>quantified variable</em> &lt;-” and expression with a modifier operator (if present) applied to a set/multiset/relation “s”</li>
<li>attempts to match s to “x intersect y”</li>
<li>checks x is a set, multiset, function, or relation</li>
<li>replaces generator with same pattern and modifier (if present) applied to x, and adds the condition that the relevant quantified variable must be in y.</li>
</ol>
<ul>
<li>i.e. “i &lt;- x intersect y” becomes “i &lt;- x, i in y”</li>
</ul>
<h3 id="code-7"><a class="header" href="#code-7">Code:</a></h3>
<pre><code class="language-haskell">theRule (Comprehension body gensOrConds) = do
         (gocBefore, (pat, iPat, expr), gocAfter) &lt;- matchFirst gensOrConds $ \ goc -&gt; case goc of
             Generator (GenInExpr pat@(Single iPat) expr) -&gt;
                 return (pat, iPat, matchDefs [opToSet,opToMSet,opToRelation] expr)
             _ -&gt; na "rule_Intersect"
         (mkModifier, s)    &lt;- match opModifier expr
         (x, y)             &lt;- match opIntersect s
         tx                 &lt;- typeOf x
         case tx of
             TypeSet{}      -&gt; return ()
             TypeMSet{}     -&gt; return ()
             TypeFunction{} -&gt; return ()
             TypeRelation{} -&gt; return ()
             _              -&gt; failDoc "type incompatibility in intersect operator"
         let i = Reference iPat Nothing
         return
             ( "Horizontal rule for set intersection"
             , return $
                 Comprehension body
                     $  gocBefore
                     ++ [ Generator (GenInExpr pat (mkModifier x))
                        , Condition [essence| &amp;i in &amp;y |]
                        ]
                     ++ gocAfter
             )
</code></pre>
<h3 id="example-7"><a class="header" href="#example-7">Example:</a></h3>
<ul>
<li>set-intersect rule appears within model C = A intersect B, after applying set-equals, set-subsetEq, set-in</li>
<li>q4 is quantified in a former step, it is an element in C</li>
<li>see Context #1, q5 is quantified by or() - existence quantifier, translates to “there exists a q5 in A intersect B such that q5 equals q4”</li>
<li>translates “q5 &lt;- A intersect B” to “q5 &lt;- A, q5 in B”, i.e. body of or() comprehension must apply to at least one member (q5) of A, with the additional condition that q5 must be in B.</li>
</ul>
<pre><code>Picking the first option: Question 1: [q5 = q4 | q5 &lt;- A intersect B]
                               Context #1: or([q5 = q4 | q5 &lt;- A intersect B])
                               ...
     Answer 1: set-intersect: Horizontal rule for set intersection
               [q5 = q4 | q5 &lt;- A intersect B] ~~&gt; [q5 = q4 | q5 &lt;- A, q5 in B]
</code></pre>
<h2 id="set-union-describes-a-new-set"><a class="header" href="#set-union-describes-a-new-set">Set-union (describes a new set)</a></h2>
<p>rule for set union. defines that an element is in the union of two sets when it is in at least one of the sets. similar structure as comprehension literal rule, only used within generators or conditions</p>
<ol>
<li>attempts to match generator to pattern and expression: pattern “<em>quantified variable</em> &lt;-” and expression with a modifier operator (if present) applied to a set/multiset/relation “s”</li>
<li>attempts to match s to “x union y”</li>
<li>checks x is a set, multiset, function, or relation</li>
<li>creates abstract matrix containing two comprehensions:</li>
</ol>
<ul>
<li>both comprehensions have body from original comprehension</li>
<li>both comprehensions have a generator with same pattern on same quantified variable.</li>
<li>expressions in generators consist of same modifier operator (if present) applied to only set x and only set y respectively</li>
<li>for set y, the additional condition “i not in x” is added to prevent double counting (relevant for sums)</li>
</ul>
<h3 id="code-8"><a class="header" href="#code-8">Code:</a></h3>
<pre><code class="language-haskell">     theRule (Comprehension body gensOrConds) = do
         (gocBefore, (pat, iPat, expr), gocAfter) &lt;- matchFirst gensOrConds $ \ goc -&gt; case goc of
             Generator (GenInExpr pat@(Single iPat) expr) -&gt; return (pat, iPat, matchDef opToSet expr)
             _ -&gt; na "rule_Union"
         (mkModifier, s)    &lt;- match opModifier expr
         (x, y)             &lt;- match opUnion s
         tx                 &lt;- typeOf x
         case tx of
             TypeSet{}      -&gt; return ()
             TypeMSet{}     -&gt; return ()
             TypeFunction{} -&gt; return ()
             TypeRelation{} -&gt; return ()
             _              -&gt; failDoc "type incompatibility in union operator"
         let i = Reference iPat Nothing
         return
             ( "Horizontal rule for set union"
             , return $ make opFlatten $ AbstractLiteral $ AbsLitMatrix
                 (DomainInt TagInt [RangeBounded 1 2])
                 [ Comprehension body
                     $  gocBefore
                     ++ [ Generator (GenInExpr pat (mkModifier x)) ]
                     ++ gocAfter
                 , Comprehension body
                     $  gocBefore
                     ++ [ Generator (GenInExpr pat (mkModifier y))
                        , Condition [essence| !(&amp;i in &amp;x) |]
                        ]
                     ++ gocAfter
                 ]
             )
</code></pre>
<h3 id="example-8"><a class="header" href="#example-8">Example:</a></h3>
<ul>
<li>set-union rule appears within model C = A union B, after applying set-equals, set-subsetEq, set-in</li>
<li>q4 is quantified in a former step, it is an element in C (Context #3)</li>
<li>see Context #1, q5 is quantified by or() - existence quantifier, translates to “there exists a q5 in A union B such that q5 equals q4”</li>
<li>translates “[q5 = q4 | q5 &lt;- A union B]” to return the matrix “flatten([[q5 = q4 | q5 &lt;- A], [q5 = q4 | q5 &lt;- B, !(q5 in A)]; int(1..2)])”</li>
<li>“q5 = q4” is the body of the comprehension, the pattern “q5 &lt;-” is applied to both A and B in the respective entries of the matrix</li>
<li>additional condition “!(q5 in A)” for the second comprehension, to prevent double counting
<ul>
<li>i.e. check that the body “q5 = q4”, applies to at least one member (q5) in A or in B.</li>
</ul>
</li>
</ul>
<pre><code>Picking the first option: Question 1: [q5 = q4 | q5 &lt;- A union B]
                               Context #1: or([q5 = q4 | q5 &lt;- A union B])
                               Context #3: and([or([q5 = q4 | q5 &lt;- A union B]) | q4 : int(0..6), C_Occurrence[q4]])
     Answer 1: set-union: Horizontal rule for set union
               [q5 = q4 | q5 &lt;- A union B]
               ~~&gt;
               flatten([[q5 = q4 | q5 &lt;- A], [q5 = q4 | q5 &lt;- B, !(q5 in A)];
                            int(1..2)])
</code></pre>
<h2 id="set-difference-describes-a-new-set"><a class="header" href="#set-difference-describes-a-new-set">Set-difference (describes a new set)</a></h2>
<p>rule for set difference. defines that an element is in the difference of two sets when it is in the former but not in the latter. similar structure as comprehension literal rule, only used within generators or conditions</p>
<ol>
<li>attempts to match generator to pattern and expression: pattern “<em>quantified variable</em> &lt;-” and expression with a modifier operator (if present) applied to a set/multiset/relation “s”</li>
<li>attempts to match s to “x - y”</li>
<li>checks x is a set, multiset, function, or relation</li>
<li>returns comprehension with same body as original, same gocBefore, gocAfter. Generator is replaced by original generator applied only to x, with additional condition “i not in y”</li>
</ol>
<h3 id="code-9"><a class="header" href="#code-9">Code:</a></h3>
<pre><code class="language-haskell">     theRule (Comprehension body gensOrConds) = do
         (gocBefore, (pat, iPat, expr), gocAfter) &lt;- matchFirst gensOrConds $ \ goc -&gt; case goc of
             Generator (GenInExpr pat@(Single iPat) expr) -&gt; return (pat, iPat, expr)
             _ -&gt; na "rule_Difference"
         (mkModifier, s)    &lt;- match opModifier expr
         (x, y)             &lt;- match opMinus s
         tx                 &lt;- typeOf x
         case tx of
             TypeSet{}      -&gt; return ()
             TypeMSet{}     -&gt; return ()
             TypeFunction{} -&gt; return ()
             TypeRelation{} -&gt; return ()
             _              -&gt; failDoc "type incompatibility in difference operator"
         let i = Reference iPat Nothing
         return
             ( "Horizontal rule for set difference"
             , return $
                 Comprehension body
                     $  gocBefore
                     ++ [ Generator (GenInExpr pat (mkModifier x))
                        , Condition [essence| !(&amp;i in &amp;y) |]
                        ]
                     ++ gocAfter
             )
</code></pre>
<h3 id="example-9"><a class="header" href="#example-9">Example:</a></h3>
<ul>
<li>set-difference rule appears within model C = A - B, after applying set-equals, set-subsetEq, set-in</li>
<li>q4 is quantified in a former step, it is an element in C (Context #3)</li>
<li>see Context #1, q5 is quantified by or() - existence quantifier, translates to “there exists a q5 in A - B such that q5 equals q4”</li>
<li>translates “q5 &lt;- A - B” to “q5 &lt;- A, !(q5 in B)”</li>
</ul>
<pre><code>Picking the first option: Question 1: [q5 = q4 | q5 &lt;- A - B]
                               Context #1: or([q5 = q4 | q5 &lt;- A - B])
                               Context #3: and([or([q5 = q4 | q5 &lt;- A - B]) | q4 : int(0..6), C_Occurrence[q4]])
     Answer 1: set-difference: Horizontal rule for set difference
               [q5 = q4 | q5 &lt;- A - B] ~~&gt; [q5 = q4 | q5 &lt;- A, !(q5 in B)]
</code></pre>
<h2 id="set-max-min-int"><a class="header" href="#set-max-min-int">Set-max-min (int)</a></h2>
<p>rule for finding maximum and minimum of a set of integers</p>
<ul>
<li>contains two sub-rules, one for max, one for min.</li>
<li>if set is literal, converts to list and finds max.</li>
<li>otherwise creates quantified variable and uses max() operation in Essence.</li>
<li>minimum rule works analogously</li>
</ul>
<h3 id="code-10"><a class="header" href="#code-10">Code:</a></h3>
<pre><code class="language-haskell">     theRule [essence| max(&amp;s) |] = do
         TypeSet (TypeInt _) &lt;- typeOf s
         return             
             ( "Horizontal rule for set max"
             , case () of
                 _ | Just (_, xs) &lt;- match setLiteral s, length xs &gt; 0 -&gt; return $ make opMax $ fromList xs
                 _ -&gt; do
                     (iPat, i) &lt;- quantifiedVar
                     return [essence| max([&amp;i | &amp;iPat &lt;- &amp;s]) |]
             )
     theRule [essence| min(&amp;s) |] = do
         TypeSet (TypeInt _) &lt;- typeOf s
         return
             ( "Horizontal rule for set min"
             , case () of
                 _ | Just (_, xs) &lt;- match setLiteral s, length xs &gt; 0 -&gt; return $ make opMin $ fromList xs
                 _ -&gt; do
                     (iPat, i) &lt;- quantifiedVar
                     return [essence| min([&amp;i | &amp;iPat &lt;- &amp;s]) |]
             )
     theRule _ = na "rule_MaxMin"
</code></pre>
<h3 id="example-10"><a class="header" href="#example-10">Example:</a></h3>
<pre><code>Picking the first option: Question 1: max(A)
                               Context #1: max(A) = max(B)
     Answer 1: set-max-min: Horizontal rule for set max
               max(A) ~~&gt; max([q3 | q3 &lt;- A])
</code></pre>
<h3 id="set-literal-example"><a class="header" href="#set-literal-example">Set-literal example:</a></h3>
<pre><code>        letting A be {5, 6, 3}
        find i: int(0..10)
        such that i = min(A)
        branching on [i]
        such that
        such that true(i)
        
Picking the first option: Question 1: min(A)
                               Context #1: i = min(A)
     Answer 1: full-evaluate: Full evaluator
               min(A) ~~&gt; 3
</code></pre>
<h2 id="set-in-boolean"><a class="header" href="#set-in-boolean">Set-in (boolean)</a></h2>
<p>rule for set membership, checks whether something is an element of a set</p>
<ol>
<li>identifies pattern: “x in s”</li>
<li>checks s is a set</li>
<li>introduces quantified variable to go through set s and check whether any of its elements equal x</li>
</ol>
<ul>
<li>i.e. “x in s” becomes “there exists i in s such that i = x”</li>
</ul>
<h3 id="code-11"><a class="header" href="#code-11">Code:</a></h3>
<pre><code class="language-haskell">     theRule p = do
         (x,s)     &lt;- match opIn p
         TypeSet{} &lt;- typeOf s
         -- do not apply this rule to quantified variables
         -- or else we might miss the opportunity to apply a more specific vertical rule
         if referenceToComprehensionVar s
             then na "rule_In"
             else return ()
         return
             ( "Horizontal rule for set-in."
             , do
                  (iPat, i) &lt;- quantifiedVar
                  return [essence| exists &amp;iPat in &amp;s . &amp;i = &amp;x |]
             )
</code></pre>
<h3 id="example-11"><a class="header" href="#example-11">Example:</a></h3>
<ul>
<li>here we are checking for membership of q4 in B union C</li>
<li>q4 is a quantified variable in larger context</li>
<li>q5 is the quantified variable introduced by the set-in rule.</li>
</ul>
<pre><code>Picking the first option: Question 1: q4 in B union C
     Answer 1: set-in: Horizontal rule for set-in.
               q4 in B union C ~~&gt; or([q5 = q4 | q5 &lt;- B union C])
</code></pre>
<h2 id="set-card-int"><a class="header" href="#set-card-int">Set-card (int)</a></h2>
<p>rule for set cardinality, counts number of elements in a set</p>
<ol>
<li>identifies pattern: |s|</li>
<li>checks s is a set</li>
<li>if it exists, returns the set’s domain’s size attribute</li>
<li>otherwise introduces quantified variable “iPat” to iterate through set, incrementing the sum for each new element, returns sum.</li>
</ol>
<h3 id="code-12"><a class="header" href="#code-12">Code:</a></h3>
<pre><code class="language-haskell">rule_Card = "set-card" `namedRule` theRule where
     theRule p = do
         s         &lt;- match opTwoBars p
         case s of
             Domain{} -&gt; na "rule_Card"
             _        -&gt; return ()
         TypeSet{} &lt;- typeOf s
         return
             ( "Horizontal rule for set cardinality."
             , do
                 mdom &lt;- runMaybeT $ domainOf s
                 case mdom of
                     Just (DomainSet _ (SetAttr (SizeAttr_Size n)) _) -&gt; return n
                     _ -&gt; do
                         (iPat, _) &lt;- quantifiedVar
                         return [essence| sum &amp;iPat in &amp;s . 1 |]
             )
</code></pre>
<h3 id="example-12"><a class="header" href="#example-12">Example:</a></h3>
<ul>
<li>set-card rule appears within model |A| = |B|</li>
<li>here q3 is the quantified variable called “iPat” above</li>
</ul>
<pre><code>Picking the first option: Question 1: |A|
                               Context #1: |A| = |B|
     Answer 1: set-card: Horizontal rule for set cardinality.
               |A| ~~&gt; sum([1 | q3 &lt;- A])
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<p>Vertical rules for Occurrence, which are applied once all possible horizontal rules have been applied at a given stage. Followed by an example of rewriting a model in Occurrence representation, using both horizontal and vertical rules.</p>
<ul>
<li>see <a href="https://github.com/conjure-cp/conjure-oxide/wiki/Conjure-Horizontal-Set-Rules">Conjure Horizontal Set Rules</a> for representation-independent horizontal set rules.</li>
</ul>
<h1 id="vertical-rules-for-occurrence-representation-of-sets"><a class="header" href="#vertical-rules-for-occurrence-representation-of-sets">Vertical rules for Occurrence-representation of sets</a></h1>
<ul>
<li>Occurrence representation creates a matrix that has the length of the maximum integer value contained in the sets. E.g. a set {1,5,11} will be represented by a matrix of length 11. Each entry in the matrix is a boolean, representing whether that integer is contained in the set. in the matrix for the set {1,5,11}, the first, fifth and eleventh entry will all be True, all others will be False.</li>
</ul>
<h2 Occurrence="" id="set-comprehension"><a class="header" href="#set-comprehension">Set-comprehension</a></h2>
<p>Comprehension rule for Occurrence. Uses the “&lt;-” expression projection (see <a href="https://github.com/conjure-cp/conjure-oxide/wiki/Conjure-Horizontal-Set-Rules#notes">Horizontal Rules - Notes</a>).</p>
<ol>
<li>identifies a comprehension consisting of a “body” followed by “generators or conditions”</li>
<li>matches the generator to an expression of the form “iPat &lt;- s”, iPat, later called “i” is a quantified variable</li>
<li>checks that s is a set, and that it has Occurrence representation</li>
<li>retrieves matrix m representing this set, and its domain</li>
<li>returns Comprehension with same body, original generator is replaced by a generator specifying the domain of the quantified variable, followed by a condition that the ith entry of the Occurrence matrix is true.</li>
</ol>
<ul>
<li>i.e. it loops over the given domain and checks that element “i” is present in the set.</li>
</ul>
<h3 id="code-13"><a class="header" href="#code-13">Code:</a></h3>
<pre><code class="language-Haskell">    theRule (Comprehension body gensOrConds) = do
        (gocBefore, (pat, iPat, s), gocAfter) &lt;- matchFirst gensOrConds $ \ goc -&gt; case goc of
            Generator (GenInExpr pat@(Single iPat) s) -&gt; return (pat, iPat, matchDefs [opToSet,opToMSet] s)
            _ -&gt; na "rule_Comprehension"
        TypeSet{}            &lt;- typeOf s
        Set_Occurrence       &lt;- representationOf s
        [m]                  &lt;- downX1 s
        DomainMatrix index _ &lt;- domainOf m
        let i = Reference iPat Nothing
        return
            ( "Vertical rule for set-comprehension, Occurrence representation"
            , return $
                Comprehension body
                    $  gocBefore
                    ++ [ Generator (GenDomainNoRepr pat index)
                       , Condition [essence| &amp;m[&amp;i] |]
                       ]
                    ++ gocAfter
            )
    theRule _ = na "rule_Comprehension"
</code></pre>
<h3 id="example-13"><a class="header" href="#example-13">Example:</a></h3>
<ul>
<li>here the quantified variable is q3, the set is A, the domain of the matrix is int(0..6). the GenInExpr “q3 &lt;- A” is rewritten using the domain and the Occurrence matrix.</li>
<li>the larger context is an and() comprehension representing the statement “for all q3 in A: q3 in B”, where “for all q3 in A” comes from the GenInExpr (see <a href="https://github.com/conjure-cp/conjure-oxide/wiki/Conjure-Horizontal-Set-Rules#notes">Horizontal Rules - Notes</a>)</li>
<li>this is rewritten as “for all q3 in the domain int(0..6), for which the q3th index of A_Occurrence is true: q3 in B”</li>
</ul>
<pre><code>Picking the first option: Question 1: [q3 in B | q3 &lt;- A]
                              Context #1: and([q3 in B | q3 &lt;- A])
    Answer 1: set-comprehension{Occurrence}: Vertical rule for set-comprehension, Occurrence representation
              [q3 in B | q3 &lt;- A]
              ~~&gt;
              [q3 in B | q3 : int(0..6), A_Occurrence[q3]]
</code></pre>
<h2 Occurrence="" id="set-in"><a class="header" href="#set-in">Set-in</a></h2>
<p>Set-in rule for Occurrence representation. In Occurrence representation, an element “i” is in a set if and only if the “ith” entry of the Occurrence matrix is true.</p>
<ul>
<li>This rule is not necessary, “in” can be implemented using the comprehension rule above.</li>
</ul>
<ol>
<li>identifies a pattern “x in s”</li>
<li>checks s is a set of type Occurrence and retrieves its Occurrence representation matrix, m.</li>
<li>returns the value of m at x.</li>
</ol>
<h3 id="code-1-1"><a class="header" href="#code-1-1">Code:</a></h3>
<pre><code class="language-haskell">    theRule p = do
        (x, s)         &lt;- match opIn p
        TypeSet{}      &lt;- typeOf s
        Set_Occurrence &lt;- representationOf s
        [m]            &lt;- downX1 s
        return
            ( "Vertical rule for set-in, Occurrence representation"
            , return $ make opIndexing m x
            )
</code></pre>
<h3 id="example-1-3"><a class="header" href="#example-1-3">Example:</a></h3>
<ul>
<li>here we are checking for containment of a quantified variable q3 in a set B</li>
<li>the statement “q3 in B” is replaced with the value of B_Occurrence at index q3.</li>
</ul>
<pre><code>Picking the first option: Question 1: q3 in B
                              Context #1: [q3 in B | q3 : int(0..6), A_Occurrence[q3]]
    Answer 1: set-in{Occurrence}: Vertical rule for set-in, Occurrence representation
              q3 in B ~~&gt; B_Occurrence[q3]
</code></pre>
<h1 id="general-example-rewriting-the-generalised-model--c--a-intersect-b"><a class="header" href="#general-example-rewriting-the-generalised-model--c--a-intersect-b">General Example: Rewriting the generalised model  “C = A intersect B”</a></h1>
<h3 id="original-essence-model"><a class="header" href="#original-essence-model">Original Essence Model:</a></h3>
<pre><code>find A,B,C : set of int(0..6)  
such that C = A intersect B
</code></pre>
<h3 id="conjure-rewriting-the-problem-step-by-step"><a class="header" href="#conjure-rewriting-the-problem-step-by-step">Conjure rewriting the problem, step by step:</a></h3>
<ol>
<li>first set equals is converted to conjunction of subsetEq, applying horizontal Set-eq rule</li>
</ol>
<pre><code>    Answer 1: set-eq: Horizontal rule for set equality
              C = A intersect B
              ~~&gt;
              C subsetEq A intersect B /\ A intersect B subsetEq C
</code></pre>
<ol start="2">
<li>dealing with the left hand side first, subsetEq is converted into a comprehension, applying horizontal Set-subsetEq rule.
The expression projection “&lt;-” (see <a href="https://github.com/conjure-cp/conjure-oxide/wiki/Conjure-Horizontal-Set-Rules#notes">Horizontal Rules - Notes</a>) means the body of the and() comprehension must apply to all members (q4) of C</li>
</ol>
<pre><code>Picking the first option: Question 1: C subsetEq A intersect B
                              Context #1: [C subsetEq A intersect B, A intersect B subsetEq C; int(1..2)]
    Answer 1: set-subsetEq: Horizontal rule for set subsetEq
              C subsetEq A intersect B ~~&gt; and([q4 in A intersect B | q4 &lt;- C])
</code></pre>
<ol start="3">
<li>the inside of the comprehension is simplified, using the definition of the “&lt;-” expression projection in Occurrence representation. (see previous section “Set-comprehension{Occurrence}”)
“q4 &lt;- C” is converted to: all q4 in the length of the matrix (0 to 6) for which the q4th entry in the Occurrence matrix is true.</li>
</ol>
<pre><code>Picking the first option: Question 1: [q4 in A intersect B | q4 &lt;- C]
                              Context #1: and([q4 in A intersect B | q4 &lt;- C])
                              Context #3: and([q4 in A intersect B | q4 &lt;- C]) /\ A intersect B subsetEq C
    Answer 1: set-comprehension{Occurrence}: Vertical rule for set-comprehension, Occurrence representation
              [q4 in A intersect B | q4 &lt;- C]
              ~~&gt;
              [q4 in A intersect B | q4 : int(0..6), C_Occurrence[q4]] 
</code></pre>
<ol start="4">
<li>turning “q4 in A intersect B” into a comprehension, applying horizontal Set-in rule. again using the expression projection “&lt;-”, to signify that the body of the or() comprehension must apply to at least one member (q5) of A intersect B</li>
</ol>
<pre><code>Picking the first option: Question 1: q4 in A intersect B
                              Context #1: [q4 in A intersect B | q4 : int(0..6), C_Occurrence[q4]]
                              Context #3: [and([q4 in A intersect B | q4 : int(0..6), C_Occurrence[q4]]), A intersect B subsetEq C; int(1..2)]
    Answer 1: set-in: Horizontal rule for set-in.
              q4 in A intersect B ~~&gt; or([q5 = q4 | q5 &lt;- A intersect B])
</code></pre>
<ol start="5">
<li>replacing “q5 &lt;- A intersect B” generator with “q5 &lt;- A, q5 in B”, applying horizontal Set-intersect rule</li>
</ol>
<pre><code>Picking the first option: Question 1: [q5 = q4 | q5 &lt;- A intersect B]
                              Context #1: or([q5 = q4 | q5 &lt;- A intersect B])
                              Context #3: and([or([q5 = q4 | q5 &lt;- A intersect B]) | q4 : int(0..6), C_Occurrence[q4]])
                              Context #5: and([or([q5 = q4 | q5 &lt;- A intersect B]) | q4 : int(0..6), C_Occurrence[q4]]) /\ A intersect B subsetEq C
    Answer 1: set-intersect: Horizontal rule for set intersection
              [q5 = q4 | q5 &lt;- A intersect B] ~~&gt; [q5 = q4 | q5 &lt;- A, q5 in B]
</code></pre>
<ol start="6">
<li>as in step 3., “&lt;-” is replaced with its definition in Occurrence representation. (see previous section “Set-comprehension{Occurrence}”)</li>
</ol>
<pre><code>Picking the first option: Question 1: [q5 = q4 | q5 &lt;- A, q5 in B]
                              Context #1: or([q5 = q4 | q5 &lt;- A, q5 in B])
                              Context #3: and([or([q5 = q4 | q5 &lt;- A, q5 in B]) | q4 : int(0..6), C_Occurrence[q4]])
                              Context #5: and([or([q5 = q4 | q5 &lt;- A, q5 in B]) | q4 : int(0..6), C_Occurrence[q4]]) /\ A intersect B subsetEq C
    Answer 1: set-comprehension{Occurrence}: Vertical rule for set-comprehension, Occurrence representation
              [q5 = q4 | q5 &lt;- A, q5 in B]
              ~~&gt;
              [q5 = q4 | q5 : int(0..6), A_Occurrence[q5], q5 in B]
</code></pre>
<ol start="7">
<li>“q5 in B” is replaces with vertical, Occurrence-specific rule for set-in. simply checks the boolean value of the q5th entry in the occurrence matrix.</li>
</ol>
<pre><code>Picking the first option: Question 1: q5 in B
                              Context #1: [q5 = q4 | q5 : int(0..6), A_Occurrence[q5], q5 in B]
                              Context #3: [or([q5 = q4 | q5 : int(0..6), A_Occurrence[q5], q5 in B]) | q4 : int(0..6), C_Occurrence[q4]]
                              Context #5: [and([or([q5 = q4 | q5 : int(0..6), A_Occurrence[q5], q5 in B]) | q4 : int(0..6), C_Occurrence[q4]]),
                                           A intersect B subsetEq C;
                                               int(1..2)]
    Answer 1: set-in{Occurrence}: Vertical rule for set-in, Occurrence representation
              q5 in B ~~&gt; B_Occurrence[q5]
</code></pre>
<ol start="8">
<li>restructuring (“inlining conditions”) inside or and and statements in turn:</li>
</ol>
<pre><code>Picking the first option: Question 1: [q5 = q4 | q5 : int(0..6), A_Occurrence[q5], B_Occurrence[q5]]
                              Context #1: or([q5 = q4 | q5 : int(0..6), A_Occurrence[q5], B_Occurrence[q5]])
                              Context #3: and([or([q5 = q4 | q5 : int(0..6), A_Occurrence[q5], B_Occurrence[q5]]) | q4 : int(0..6), C_Occurrence[q4]])
                              Context #5: and([or([q5 = q4 | q5 : int(0..6), A_Occurrence[q5], B_Occurrence[q5]]) | q4 : int(0..6), C_Occurrence[q4]]) /\
                                          A intersect B subsetEq C
    Answer 1: inline-conditions: Inlining conditions, inside or
              [q5 = q4 | q5 : int(0..6), A_Occurrence[q5], B_Occurrence[q5]]
              ~~&gt;
              [A_Occurrence[q5] /\ B_Occurrence[q5] /\ q5 = q4 | q5 : int(0..6)] 

Picking the first option: Question 1: [or([A_Occurrence[q5] /\ B_Occurrence[q5] /\ q5 = q4 | q5 : int(0..6)])
                                           | q4 : int(0..6), C_Occurrence[q4]]
                              Context #1: and([or([A_Occurrence[q5] /\ B_Occurrence[q5] /\ q5 = q4 | q5 : int(0..6)]) | q4 : int(0..6), C_Occurrence[q4]])
                              Context #3: and([or([A_Occurrence[q5] /\ B_Occurrence[q5] /\ q5 = q4 | q5 : int(0..6)]) | q4 : int(0..6), C_Occurrence[q4]]) /\
                                          A intersect B subsetEq C
    Answer 1: inline-conditions: Inlining conditions, inside and
              [or([A_Occurrence[q5] /\ B_Occurrence[q5] /\ q5 = q4
                       | q5 : int(0..6)])
                   | q4 : int(0..6), C_Occurrence[q4]]
              ~~&gt;
              [C_Occurrence[q4] -&gt;
               or([A_Occurrence[q5] /\ B_Occurrence[q5] /\ q5 = q4
                       | q5 : int(0..6)])
                   | q4 : int(0..6)] 
</code></pre>
<ol start="9">
<li>the process is repeated for the right hand side of the conjunction in step 1, leading to a similar but simpler expression due to the order of operations.</li>
</ol>
<h3 id="final-rewritten-model"><a class="header" href="#final-rewritten-model">Final Rewritten Model:</a></h3>
<pre><code>find A_Occurrence: matrix indexed by [int(0..6)] of bool
    find B_Occurrence: matrix indexed by [int(0..6)] of bool
    find C_Occurrence: matrix indexed by [int(0..6)] of bool
    branching on [A_Occurrence, B_Occurrence, C_Occurrence]
    such that
        and([C_Occurrence[q4] -&gt; or([A_Occurrence[q5] /\ B_Occurrence[q5] /\ q5 = q4 | q5 : int(0..6)]) | q4 : int(0..6)]),
        and([A_Occurrence[q6] /\ B_Occurrence[q6] -&gt; C_Occurrence[q6] | q6 : int(0..6)])
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="syntax-errors"><a class="header" href="#syntax-errors">Syntax Errors</a></h1>
<p>(Will produce an invalid CST)</p>
<h3 id="1-missing-token-eg-variable-domain-expression"><a class="header" href="#1-missing-token-eg-variable-domain-expression">1. Missing Token (e.g variable, Domain, Expression)</a></h3>
<p>Description: expected token is absent
Detection: Empty node or a missing child node. (MISSING node is inserted)
Example: missing variable name</p>
<pre><code class="language-text">find: bool
</code></pre>
<p>Example: missing Expression</p>
<pre><code class="language-text">letting x be 
</code></pre>
<h3 id="2-missing-keyword"><a class="header" href="#2-missing-keyword">2. Missing Keyword</a></h3>
<p>Description: a token appears where a different token/keyword is expected
Detection: ERROR node containing all the tokens where that failed to match the grammar</p>
<p>Example: missing colon, <code>int</code> is unexpected (here <code>x</code> and <code>int</code> will be children of the ERROR node)</p>
<pre><code class="language-text">find x int
</code></pre>
<h3 id="3-unexpected-token"><a class="header" href="#3-unexpected-token">3. Unexpected Token</a></h3>
<p>Description: a token appearing after a valid construct is complete
Detection: ERROR node containing the extra token (ERROR node will likely be the last child of a valid construct)
Example: second <code>)</code> is extra</p>
<pre><code class="language-text">find x: int(1..2))
</code></pre>
<h3 id="4-invalid-token"><a class="header" href="#4-invalid-token">4. Invalid Token</a></h3>
<p>Description: token is malformed or not part of the grammar
Detection: look for an ERROR node with the invalid token
Example: <code>@int</code> is not a valid token (ERROR node with <code>@</code>)</p>
<pre><code class="language-text">find x: @int
</code></pre>
<p>Conjur does not identify <code>int</code> at all, just says “Skipped token”, “Missing Domain”
Tree-Sitter in conjure-oxide sees <code>int</code> as a valid token but has an ERROR node with <code>@</code> before.
So in Conjure the same error as Missing Token but might make sense to separate due to different CST structures.</p>
<h3 id="5-unclosed-delimiter"><a class="header" href="#5-unclosed-delimiter">5. Unclosed Delimiter</a></h3>
<p>Description: unmatched or missing closing bracket, parenthesis, brace
Detection: MISSING node “)”
Example: missing <code>)</code></p>
<pre><code class="language-text">find x: int(1..2
</code></pre>
<p>Conjure allows it but since out grammar enforces it Tree-Sitter produces an error.</p>
<h3 id="6-unsupported-statements"><a class="header" href="#6-unsupported-statements">6. Unsupported Statements</a></h3>
<p>Description: statement not recognised by Essence grammar
Detection: ERROR node with the unrecognised statement
Example:</p>
<pre><code class="language-text">find x: int(1..5)
print x 
</code></pre>
<p>Conjure doesn’t recognise <code>print x</code> as a separate invalid statement.</p>
<h3 id="7-general-syntax-error"><a class="header" href="#7-general-syntax-error">7. General Syntax Error</a></h3>
<p>All the other cases that cause an ERROR node in the CST tree.</p>
<h1 id="semantic-errors"><a class="header" href="#semantic-errors">Semantic Errors</a></h1>
<p>(Will produce a valid CST and AST, now can only detected at runtime, e.g typecheking)</p>
<h3 id="1-keywords-as-identifiers"><a class="header" href="#1-keywords-as-identifiers">1. Keywords as Identifiers</a></h3>
<p>Description: token’s name is not allowed<br>Detection: compare the variable names against the set of keywords
Example: Keyword “bool” used as a variable name</p>
<pre><code class="language-text">find bool: bool
</code></pre>
<pre><code class="language-text">find x: letting
</code></pre>
<p>Conjure doesn’t allow it but Tree-Sitter does so we will have to check as part of semantic checks.</p>
<h3 id="2-omitted-declaration"><a class="header" href="#2-omitted-declaration">2. Omitted Declaration</a></h3>
<p>Description: variable not declared
Detection: save the declared variables and check if the ones used in expressions are in the declared set
Example: x was not declared before</p>
<pre><code class="language-text">find y: int (1..4)
such that x = 5
</code></pre>
<h3 id="3-invalid-domain"><a class="header" href="#3-invalid-domain">3. Invalid Domain</a></h3>
<p>Description: logically or mathematically invalid bounds/domain + infinite domain</p>
<p>Example: a bigger value before smaller</p>
<pre><code class="language-text">find x: int(10..5)
</code></pre>
<p>Conjure doesn’t flag as error just says no solutions found.</p>
<p>Example: infinite domain</p>
<pre><code class="language-text">find x: int(1..) 
</code></pre>
<p>Might want to restrict infinite domain with the grammar so it could be a syntax error.</p>
<h3 id="4-type-mismatch"><a class="header" href="#4-type-mismatch">4. Type Mismatch</a></h3>
<p>Description: attempt to do an operation on illegal types</p>
<p>Example: cannot add integer and boolean</p>
<pre><code class="language-text">letting y be true 
find x: int (5..10)
such that 5 + y = 6
</code></pre>
<h3 id="5-unsafe-division"><a class="header" href="#5-unsafe-division">5. Unsafe division</a></h3>
<p>Description: cannot divide/modulo by zero</p>
<p>Example: cannot divide by zero</p>
<pre><code class="language-text">find x: int(5..10)
such that x/0 = 3
</code></pre>
<p>Conjure allows, proceeds to run the solver but just outputs no solutions. We should disallow.</p>
<h3 id="6-invalid-indexing-in-tuples-and-matrices"><a class="header" href="#6-invalid-indexing-in-tuples-and-matrices">6. Invalid indexing in tuples and matrices</a></h3>
<p>Description: Tuples and matrices are indexed from . Negative, zero or index out of bounds is invalid</p>
<p>Example: s tuple index of out bounds</p>
<pre><code class="language-text">letting s be tuple(0,1,1,0)
letting t be tuple(0,0,0,1)
find a : bool such that a = (s[5] = t[1]) $ true
</code></pre>
<h1 id="possible-semantic-errors-per-statement-type"><a class="header" href="#possible-semantic-errors-per-statement-type">Possible semantic errors per statement type</a></h1>
<p>(All syntactic errors are relevant for each)</p>
<h2 id="declarations"><a class="header" href="#declarations">Declarations</a></h2>
<h3 id="find-statement"><a class="header" href="#find-statement">Find Statement</a></h3>
<p>(Declaring decision variables)</p>
<p>Format: <em>“find”</em> <strong>Name</strong> <em>“:”</em> <strong>Domain</strong></p>
<p>Semantic Errors: Keyword as Token, Invalid Domain</p>
<h3 id="letting-statement"><a class="header" href="#letting-statement">Letting Statement</a></h3>
<p>(Declaring aliases)</p>
<p>Formats: <em>“letting”</em> <strong>Name</strong> <em>“be”</em> <strong>Expression</strong> | <em>“letting”</em> <strong>Name</strong> <em>“be”</em> <em>“domain”</em> <strong>Domain</strong></p>
<p>Semantic Errors: All except Omitted Declaration</p>
<h3 id="constraints-1"><a class="header" href="#constraints-1">Constraints</a></h3>
<p>Format: <em>“such that”</em> list(<strong>Expression</strong>, <em>“,”</em>)</p>
<p>Semantic Errors: All except for Invalid Domain</p>
<div style="break-before: page; page-break-before: always;"></div><!--
authors: Liz Dempstergit 
last-updated: 21-12-25
---- -->
<h1 id="ideal-scenario-of-testing-for-conjure-oxide"><a class="header" href="#ideal-scenario-of-testing-for-conjure-oxide">Ideal Scenario of Testing for Conjure-Oxide</a></h1>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<h3 id="what-is-the-goal-of-this-document"><a class="header" href="#what-is-the-goal-of-this-document">What is the goal of this document?</a></h3>
<p>The goal of this document is to provide an ideal testing outline for Conjure-Oxide, a project in development. To do so, this document will be split into definitions (of Conjure-Oxide and other relevant components, as well as key testing terms), current Conjure-Oxide testing, and idealised (to an extent) Conjure-Oxide testing. When discussing idealised testing, any key limitations will also be discussed. Further, this document will address the use of GitHub actions in this project, including code coverage.</p>
<h3 id="what-is-conjure-oxide"><a class="header" href="#what-is-conjure-oxide">What is Conjure-Oxide</a></h3>
<p>Conjure-Oxide is a constraint modelling tool which is implemented in Rust. Of note, it is a reimplementation of the Conjure automated constraint modelling tool and the Savile Row Modelling Assistant, functionally merged and rewritten in Rust - largely because Rust is an efficient high-performance language. Conjure-Oxide takes in a problem written in a high level constraint language, which is called Essence, and creates a model from this. This model is then transformed into a solver-friendly form, and solved using one of the available back-ends. At the moment, these solver back-ends include Minion (a Constraint Satisfiability Problem (CSP) solver) and in-development translation and bindings to a SAT (Propositional Satisfiability Problem) solver. To put it simply, Conjure-Oxide is a compiler to different modelling languages, the result of which is passed into the respective solver. These solvers act as back-ends and must be given bindings to Conjure-Oxide, but are not actually part of it themselves.</p>
<h3 id="how-is-the-model-made-solver-friendly"><a class="header" href="#how-is-the-model-made-solver-friendly">How is the model made ‘solver-friendly’?</a></h3>
<p>Conjure-Oxide has a rule engine, which applies rules onto the model passed in as Essence, to lower the level of the language into one which can be parsed and solved by the back-end solvers. This engine applies rewriting rules, such as (x = - y) to (x + y = 0), to transform the model. As Essence is a fairly high-level language, with compatibility for sets and matrices and a number of keywords, there are a lot of rewrite rules which may be needed before the model can be passed into a solver. This translation is one of the key roles of Conjure-Oxide, and this rule application refines the language from a higher level to a lower level. The exact rules applied and the degree of simplification varies on the language requirement of the solver: for example, Minion has higher-level language compatibility than a SAT solver<sup class="footnote-reference" id="fr-1-1-1"><a href="#footnote-1-1">1</a></sup>.</p>
<h3 id="conjure-and-savile-row"><a class="header" href="#conjure-and-savile-row">Conjure and Savile Row</a></h3>
<p>Also relevant to the testing of Conjure-Oxide is Conjure and Savile Row <sup class="footnote-reference" id="fr-2-1-1"><a href="#footnote-2-1">2</a></sup>. This is because as Conjure-Oxide is a merge and reimplementation of these programs, the testing can be performed comparatively against Conjure and Savile Row. When this document uses the term “Conjure suite”, it refers to both Conjure and Savile Row, being used in combination, generally using the Minion solver. Where there is deviation from this, it will be explicitly clarified.</p>
<h4 id="what-is-conjure"><a class="header" href="#what-is-conjure">What is Conjure?</a></h4>
<p>Conjure is a constraint modelling tool, implemented in Haskell. It uses a rule engine similarly to Conjure-Oxide to simplify from Essence to Essence’ (a subset of Essence which is slightly lower-level), and this “refinement” produces the lower-level model to pass to Savile Row.</p>
<h4 id="what-is-savile-row"><a class="header" href="#what-is-savile-row">What is Savile Row?</a></h4>
<p>Savile Row is a constraint modelling assistant which translates from Essence’ to a solver-friendly language. Alongside translating the model to the target language, it can reformat the model with an additional set of rules. This provides a performance increase by improving the model itself. Functionally, the better a model is, the faster a solver will solve it.</p>
<h4 id="what-is-minion"><a class="header" href="#what-is-minion">What is Minion?</a></h4>
<p>Minion is a Constraint Satisfiability Problem solver, which has bindings to both Conjure suite and Conjure-Oxide. Minion is a fast, scalable, CSP solver, designed to be capable of solving difficult models while still being time optimised. This is the main solver in use by both the Conjure suite and by Conjure-Oxide, due to its flexibility and efficiency.</p>
<h2 id="definitions-for-testing"><a class="header" href="#definitions-for-testing">Definitions for Testing</a></h2>
<p>Two main forms of testing will be addressed within this document: correctness testing and performance testing. Fuzz testing (inputting malformed instances to see the program response) is not currently intended as part of testing Conjure-Oxide, and so will not be outlined or addressed. Metamorphic testing may have applications to this project, and so will be defined, but will not be considered as part of the ideal implementation at present as it is not possible to implement at this point in time.</p>
<h3 id="what-is-correctness-testing"><a class="header" href="#what-is-correctness-testing">What is correctness testing?</a></h3>
<p>In the field of computer science, correctness can be formally defined as a program which behaves as expected by it’s formal specification, in all cases. As such, testing for correctness essentially consists of testing that the program produced the correct result for all given test cases. Correctness testing does not require exhaustiveness (checking all inputs on all states), but instead requires testing that all (or most) states function with varied inputs, which can then be used as a proof of correctness.</p>
<h3 id="what-is-performance-testing"><a class="header" href="#what-is-performance-testing">What is performance testing?</a></h3>
<p>Performance testing refers to a range of methodologies designed to measure or evaluate a software’s performance. By performance, this generally refers to time taken to complete a process and the stability under load. The time taken for processes will vary not only by system, but also by device depending on factors such as background processes. As not all performance testing methodologies are relevant to Conjure-Oxide, they will not be outlined in this document. The two most common forms of performance testing are load testing and stress testing.
<strong>Load testing</strong> examines the performance of a program to support its expected usage, and is used to identify bottlenecks in software, as well as possibly identify a relationship of usage to time.
<strong>Stress testing</strong> places the program under extremely high load to see the ability of the software to function under exceptional load. This is generally used to find the functional upper load of a program before it breaks.</p>
<h3 id="what-is-metamorphic-testing"><a class="header" href="#what-is-metamorphic-testing">What is metamorphic testing?</a></h3>
<p>Most tests use <strong>oracles</strong>, where the answer is known and is explicitly checked against. This is what is done in correctness testing, as laid out above. Metamorphic testing, instead, uses <strong>Metamorphic relations</strong> to generate new test cases from existing previous ones. A metamorphic relation is the relation between the test (the inputs) and the result (the outputs). An example of this is (sin(x) = sin( \pi -x)), where, regardless of x, there is a consistent relation between the input and output. As such, test cases can be generated to test the correctness of this output.</p>
<h2 id="test-scenario-for-conjure-oxide"><a class="header" href="#test-scenario-for-conjure-oxide">Test Scenario for Conjure-Oxide</a></h2>
<p>As Conjure-Oxide is a reimplementation, it is possible to perform a large amount of the testing comparatively. By this, it means that testing can be done independently on Conjure-Oxide, and the results can be directly compared against the results of the same test being ran in the Conjure suite. This is true not only for the correctness testing, but also for the performance testing. Tests run in the Conjure suite are run by Conjure, which uses Savile Row and the required solvers to produce the correct output.</p>
<h3 id="correctness-testing"><a class="header" href="#correctness-testing">Correctness Testing</a></h3>
<p>There are several areas which should be tested for correctness in Conjure-Oxide: that the Essence is correctly parsed; that the correct Essence translation is generated; that the correct rules are applied in the correct order; and finally that the correct solution is reached by Minion. For something to be ‘correct’ in Conjure-Oxide, it means it must behave as expected. As Conjure-Oxide reimplements Conjure and Savile Row, the expected behaviour is that of the Conjure suite. As such, correctness testing is performed exclusively comparative to the results produced by this suite.
Correctness testing as implemented is looking to ensure that all expected files match the files which are actually produced. Where there is a difference, the initial assumption is that Conjure-Oxide has the mistake. This is not necessarily always correct - the Conjure suite may have bugs or areas where it is not producing the expected outcome - but usually is.</p>
<h3 id="current-correctness-testing"><a class="header" href="#current-correctness-testing">Current Correctness Testing</a></h3>
<p>Correctness testing is the main form of testing performed in Conjure-Oxide at present, mainly through integration testing. Integration testing tests how the whole application works together as a whole, and as such is the most applicable to test all areas of testing needing to be done in Conjure-Oxide. In the current testing implementation, a test model is produced, and then the parse, rule-based transformation and result file are compared against those produced by calling the same test case on Conjure. In this, we assume that the result produced by the Conjure suite is always going to be correct.  Theoretically, this is completely functional - as Conjure-Oxide is a reimplementation, any bugs which exist in Conjure or Savile Row could also exist in Conjure-Oxide without causing Conjure-Oxide to violate it’s correctness. However, this defeats the point of an evolving project, so assuming the complete correctness of the Conjure suite is not sufficient for testing.</p>
<h3 id="comparative-correctness-testing"><a class="header" href="#comparative-correctness-testing">Comparative Correctness Testing</a></h3>
<p>As it is possible to perform the testing comparatively, the current implementation forms a functional basis for any ideal implementation, because it is built on this comparison. The current implementation functions well (although with limitations, as addressed below) in showing a degree of correctness, however it is not necessarily holistic enough to show the full correctness of the project. The primary solution for this issue is simply increasing the test coverage through developing a broader repository of models to be tested. Conjure has a very broad set of translation rules, meaning that there is a large number of rules which can be reimplemented in Conjure-Oxide. This enables a demonstration of the functionality of Conjure-Oxide in more scenarios, by ensuring not only are all rules tested individually, but rules in combination, with specific priority, are also tested and return results as expected.
There may be some benefit to having tests that are not solved and compared against results from the Conjure suite, but rather solved independently (e.g., by mathematicians) and then compared to the results of the same model produced by Conjure-Oxide. By proving these results as correct, it is possible to go beyond simply assuming Conjure and Savile Row are always right. However, this is not particularly feasible in a broader implementation and would be fairly limited in scale due to this, especially as Conjure-Oxide is not a large project.
Solver Testing
Part of the larger Conjure-Oxide project is the implementation of a Satisfiability (SAT) solver. This implementation will require integration testing alongside the rest of the Conjure-Oxide project. As Conjure has a SAT solver, this is possible to be done comparatively, although would require the implementation of the ability to select a specific solver to solve a model. The comparative testing would simply compare the translated essence to SAT, and the output of the Conjure suite’s SAT solver to that of the Conjure-Oxide SAT solver, and debug where the tests do not pass.</p>
<h3 id="limitations-of-correctness-testing"><a class="header" href="#limitations-of-correctness-testing">Limitations of Correctness Testing</a></h3>
<p>Conjure-Oxide is, in part, a refinement based program. A large part of it’s function is to refine from Essence down to a solver-friendly language. One part of the way that this is done in Conjure-Oxide is through a rule engine. This rule engine applies modifications to the constraints problems given to the project. At current, we just assume the rules applied are true. For example, (x = -y + z) becoming (x + y - z = 0) is a simple transformation which could be made by the rule engine. We do not formally prove that this transformation is correct, we just assume that it is the correct transformation. In simpler transformations such as this one, that is a valid assumption - it is possible to confirm that the modification is correct with minimal effort. In cases where more complex rules may be applied, the lack of a proof poses a limitation on the project. In an ideal scenario, this limitation could be removed by having proofs for every single rule applied in the rule engine, therefore not having to rely on an assumed correctness.
Another of the primary limitations in correctness testing as implemented is that it assumes that the output being produced by Minion (or the SAT solver in development) is correct. As there are no known bugs in Minion, this is an acceptable assumption to make. That said, it is not necessarily accurate that all output from Minion is correct. Other mature (having existed, and been used and updated, over a protracted period of time), state of the art solvers can produce incorrect results<sup class="footnote-reference" id="fr-3-1-1"><a href="#footnote-3-1">3</a></sup>.</p>
<p>If Minion has similar unknown bugs, it may fail to fulfil the correctness element of correctness testing.
The SAT solver which is being implemented is in it’s infancy and as such is much less reliable. It is likely that it will have a number of bugs and logical errors which will be gradually harder to find as time goes on (operating under the assumption that easy-to find and solve bugs will be removed earlier, leaving only more hidden or complex bugs).</p>
<h3 id="performance-testing"><a class="header" href="#performance-testing">Performance Testing</a></h3>
<p>It is of note that a large motivation behind the reimplementation of the Conjure suite into a single Rust program is to improve the performance of the compilation from Essence to a solver-friendly language, without compromising on the time taken to solve a model. Currently, Conjure translates Essence into Essence’, and then Savile Row refines and reformats the resultant Essence’ into a solver-friendly language. Conjure-Oxide translates directly from Essence into a solver-friendly language, which should cut down on the amount of steps necessary and as such result in a shorter translation time.
When testing for overall performance of Conjure-Oxide, the primary metrics that we are are concerned with is the total time taken for a model to be parsed, translated, and solved through the solver back-end. This total time can be split into two components: the translation time and the time taken by the solver. We can also use solver nodes as a measure of performance of the solver, as the time the solver takes may vary depending on background processes. In the performance testing addressed in this document, though there will be consideration for the solver time, the primary measurement of value is translation time.</p>
<h3 id="current-performance-testing"><a class="header" href="#current-performance-testing">Current Performance Testing</a></h3>
<p>At present, there is no formal performance testing implemented in Conjure-Oxide. While stats files are generated on each test run, tracking a number of fields (rewrite time, solver time, solver nodes, total time, etc.), nothing is done with this information. As such, while there is some measure of ‘performance’, it lacks context, is not reliable (since data is produced from a single run) and overall does not create a measure of Conjure-Oxide’s performance.
Performance testing, both <strong>load</strong> and <strong>stress</strong> based, can be performed both comparatively (as in checking speed or efficiency of one program directly against another (or several other) programs), but also individually on the given program. As such, both ‘methods’ of Performance testing will be discussed.</p>
<h3 id="performance-testing-of-just-conjure-oxide"><a class="header" href="#performance-testing-of-just-conjure-oxide">Performance Testing of just Conjure-Oxide</a></h3>
<p>Sole examination of the performance of Conjure-Oxide cannot show whether there is a performance improvement as desired. However, the goal of individual performance testing is rather to enable the development of a relationship between complexity (of translation) and time (to translate). In addition, this will allow for the identification of any notable bottlenecks in the program, allowing these specific problem areas to be targeted for improvement.
To performance test a program, a number of things need to be established. Firstly, what the metric(s) are being considered - as established above, for Conjure-Oxide this is the translation-, and to some degree solver-, time. Secondly, what is the independent variable - as in, what is being varied to result in different outputs. In Conjure-Oxide, this will be size or complexity of a given Essence file. Size and complexity will be defined contextually below.</p>
<h4 id="distinction-between-size-and-complexity"><a class="header" href="#distinction-between-size-and-complexity">Distinction between Size and Complexity</a></h4>
<p>Size and complexity of a given Essence file are separate, although certainly correlated. Put simply, size refers more directly to the number of components that make up an Essence input problem, whereas complexity refers to specific aspects which complicate translation, rather than directly increase its size.
When applying rules to a model, the rules are applied by priority. The implementation of this is essentially that each rule is checked against the model, and if it applies, it is applied to transform the model in order of priority (e.g., two rules are valid, the higher priority rule is the one selected). Use of a dirty-clean (this will not try to apply rules to a finished model) or naive (this will try and apply all rules until they have all been checked, applied, checked again, etc.) rewriter will also result in variance on translation time, so when experiments are being defined it is best to account that all models are using the same version of the rewriter.
Size refers to the number of variables, constraints, or size of input data (for example, a larger set or array) given as part of an input file. A ‘larger’ problem has more constraints and variables than a ‘smaller’ one. This will impact translation time (the relationship of this change should be examined by the performance testing) because there is more to parse and translate, even if the actual rule application is simple.
On the other hand, in this context, complexity can be loosely defined as elements of the model which make it difficult to translate, without regard for the size. Features which could increase complexity include nesting, conditional constraints, dynamic constraints, etc.
When testing for size, it is best to use very simple, repeated rules, and when testing complexity it is best to try to ensure that this is not also linked into increasing size, although these two features are tied together and therefore difficult to isolate from one another.</p>
<h4 id="performance-experiments-to-run"><a class="header" href="#performance-experiments-to-run">Performance Experiments to run</a></h4>
<p>There are two main types of experiment to be considered in the performance testing of Conjure-Oxide. \textbf{Load testing}, where the size or complexity is varied in order to measure translation time under different conditions; and \textbf{stress testing}, specifically to see whether higher complexity or larger files disproportionately increase translation time. As stress testing requires some measure of what is proportional and what is not, load testing is addressed first.</p>
<h4 id="load-testing-for-conjure-oxide"><a class="header" href="#load-testing-for-conjure-oxide">Load testing for Conjure-Oxide</a></h4>
<p>When designing performance testing for a system, there are several considerations to be made. Primarily, it is of importance that data gathered and aggregated is suitable to be used for graphing and building relationships. To do this, data must be reliable, consistent and accurate. Single runs of data cannot provide this, as many factors may influence the results. In order to fulfil these needs, substantial amounts of data should be gathered. Anomalies should be removed (for example, using interquartile range or using Z-Scores) or simply averaged over (this is less accurate but more achievable). As size or complexity varies, these averaged results should be plotted into a graph. This is the most effective way of providing understanding of the relationship between size/complexity and translation time.</p>
<h4 id="stress-testing-for-conjure-oxide"><a class="header" href="#stress-testing-for-conjure-oxide">Stress testing for Conjure-Oxide</a></h4>
<p>Once a relationship has been established by load testing, stress testing can occur. Although it is possible to see the point at which a program fails without prior load testing, having determined the relationship between size/complexity and time allows for a consideration of what is disproportionate. Implementing this in Conjure-Oxide would simply involve the program under abnormally high load to find it’s breaking point, using repeated results to ensure reliability and accuracy of the data.</p>
<h3 id="additional-performance-profiling"><a class="header" href="#additional-performance-profiling">Additional Performance Profiling</a></h3>
<p>Many parts of Conjure-Oxide (such as specific rules, string manipulations, memory allocation to solvers, etc.) are also not capable of being directly examined for their complexity, and the complexity of these things cannot be manipulated to perform experiments as outlined above. However, it is important that these are still being tested for their performance. This is because it is important to catch irregular memory allowances, excessive time spending, expensive Rust functions, etc., in order to ensure that Conjure-Oxide runs both as quickly and as smoothly as possible, One way to do this is to run profilers, such as Perf, which allow for the areas that time or memory is being spent to be analysed more specifically. Given this analysis, it is then possible to examine these areas for improvements, as was done in Issue #288<sup class="footnote-reference" id="fr-4-1-1"><a href="#footnote-4-1">4</a></sup>.</p>
<h3 id="comparative-performance-testing"><a class="header" href="#comparative-performance-testing">Comparative Performance Testing</a></h3>
<p>As established, Conjure-Oxide is a reimplementation of a pre-existing set of programs, these being Conjure and Savile Row. One of the primary goals of this reimplementation is to improve the performance of Translation time, while also ensuring that the time taken to solve a given essence problem is not worsened. Considering that Minion is simply rebound to Conjure-Oxide, much as it was in the Conjure suite, it is unlikely that these bindings would be responsible for a slower solve time. As such, the primary impact on solve time is the model passed into the solver. A worse model will take substantially more time than a model which has been well translated and refined, and substantial increases in the time taken to solve should be avoided. Performance testing should be performed on the Conjure suite (primarily on Savile Row, since the time of Conjure is amortised over each instance) to establish the relationship of size/complexity to time, as in Conjure-Oxide. The results of both may then be plotted on one graph, to see at which point(s) Conjure-Oxide is faster than Savile Row at translation, and vice versa.
Comparative testing also allows for the solver nodes (which represent, to some degree, solver time) from both the Conjure suite and Conjure-Oxide. As established, the goal of Conjure-Oxide is to improve translation performance without sacrificing solving performance. As such, it is vital to also consider at which size/complexity of translation the solver nodes start to vastly differ between Conjure suite and Conjure-Oxide, and to examine the rules to see why this is (and whether there is a requisite decrease in translation time which could possibly balance this increase). Though having a small number of nodes which differ (e.g., by 10) is not an issue, when there is a large disparity between number of solver nodes, this reflects poorer quality translation or (possibly) an issue with the binding to Rust.</p>
<h3 id="limitations-of-performance-testing"><a class="header" href="#limitations-of-performance-testing">Limitations of Performance Testing</a></h3>
<p>One limitation of performance testing is the impact that other processes running on the computer or server when testing. Other processes running at the same time mean that less threads can be allocated to Conjure-Oxide or its solver backends when dealing with a model, and as such slow down the speed at which these models can be parsed, translated, and solved. However, this is mainly removed as an issue by a combination of repeated runs, and identifying and removing anomalies (using Z-Score).
Another issue present in performance testing is that completely decoupling size and complexity is rather difficult, if not entirely impossible. This is because there is overlap in the definitions, and because as a model becomes more complex, it often becomes larger, and vice versa. Although fully separating these two metrics is the aim in an ideal scenario, an actual implementation would struggle to follow through with this requirement.</p>
<h2 id="github-actions-and-testing"><a class="header" href="#github-actions-and-testing">GitHub Actions and Testing</a></h2>
<p>GitHub Actions allow for integration of the CI’/CD pipeline to GitHub and the automation of the software development cycle. Automated workflows can be used to build, test and deploy code into a GitHub VM, allowing for flexibility in the development of a project.</p>
<h3 id="what-is-a-workflow"><a class="header" href="#what-is-a-workflow">What is a workflow?</a></h3>
<p>In GitHub Actions, a workflow is an automated process which is set up within a GitHub repository with the aim to accomplish a specific task. They are triggered by an Event, such as pushing or pulling code. Workflows are made up of the combination of a trigger (the Event) and a set of processes (made up of Jobs, which are sets of steps in a workflow).</p>
<h3 id="test-rerun"><a class="header" href="#test-rerun">Test Rerun</a></h3>
<p>This involves the automated rerunning of tests when a push or pull request is made on the GitHub repository. This is already implemented in Conjure-Oxide, through “test.yml”. Test.yml runs tests every push request made to the main branch, and on all pull requests. This allows for correctness testing to be performed on all pushes made to the main, to ensure that no additional tests fail.</p>
<h3 id="code-coverage"><a class="header" href="#code-coverage">Code Coverage</a></h3>
<p>When pushes are made to the main branch of Conjure-Oxide on GitHub, a code coverage automated workflow is run. This workflow generates a documentation coverage report which outlines what percentage of the code in the repository is being executed when tests are run. The higher the percentage, the more of the code can be relied upon as working under test conditions. This is also already implemented in the GitHub repository, through “code-coverage.yml”, “code-coverage-main.yml” and “code-coverage-deploy.yml”. One of the goals of correctness testing is to increase the code coverage percentage, because this would show that more of the code is functioning correctly.</p>
<h3 id="automated-performance-testing"><a class="header" href="#automated-performance-testing">Automated Performance Testing</a></h3>
<p>GitHub workflows can be used to create further custom processed to be automated. Automating performance testing in GitHub allows for them to be run routinely (e.g., every X pushes, or every X days) to ensure consistent performance of the project. As they occur automatically, this means that benchmarks can be set, and failue on any of these benchmarks can reuslt in a flag, allowing for early detection when performance of the program begins to regress, or fall far behind that of the Conjure suite. GitHub Actions allow for the results to be placed into files, and from here an interactive dashboard could be generated (as in PR #291. <sup class="footnote-reference" id="fr-5-1-1"><a href="#footnote-5-1">5</a></sup></p>
<h2 id="brief-outline-of-possible-future-sub-projects"><a class="header" href="#brief-outline-of-possible-future-sub-projects">Brief Outline of Possible Future Sub-Projects</a></h2>
<p>Having outlined at least a portion of the ideal testing scenario above, as well as some limitations of this scenario, it is now possible to outline to some degree future sub-projects which could be added to the overall Conjure-Oxide project.</p>
<h3 id="improving-code-coverage"><a class="header" href="#improving-code-coverage">Improving Code Coverage</a></h3>
<p>One method of improving the code coverage is by creating a broader repository of integration tests. This project focuses on the correctness aspect of the testing, and in itself can be split into several sub-projects or subsumed into other projects (e.g., if someone is writing a parser, they may decide to write the tests for this parser). The code coverage report is updated every-time a PR is made, and by examining the coverage report (see: {Code Coverage Report}), it is possible to see which areas would benefit from additional testing. Although code coverage testing itself is not concerned with correctness, increasing the amount of correctness testing increases code coverage, and so they are related. It may be beneficial to target areas of the code which have a very low line or function coverage, as this is likely easier to increase.</p>
<h3 id="producing-proofs-for-correctness"><a class="header" href="#producing-proofs-for-correctness">Producing Proofs for Correctness</a></h3>
<p>As established, one of the limitations of the current correctness testing is that there is an assumption of correctness, that being that we either assume the Conjure suite is correct, or we assume that the rules we are applying are correct. These assumptions are largely valid, but do limit the factual correctness of the project. One possible sub-project, which would have a heavy reliance on mathematical knowledge, is to produce these proofs. This does not necessarily have to be exhaustive: in the case of the correctness testing exhausting the proofs would be extremely time consuming, but having proofs to additionally prove correctness overcomes one of the project limitations. In the case of proving the existing rules, though there are a currently increasing set of rules, they are finite, so this may be more manageable as a project.</p>
<h3 id="measuring-performance-through-load-testing"><a class="header" href="#measuring-performance-through-load-testing">Measuring Performance Through Load Testing</a></h3>
<p>The outline of this subproject is to fulfil, at least in part, the requirement for performance testing on this project. There are several ways that this could be approached, all of which vary somewhat, so this project is flexible in its details.
One method which may be effective regarding performance testing is to use GitHub Actions to automate the performance testing, as outlined in GitHub Actions and Testing. This is because this would allow flexibility and repeated performance testing, as well as the ability to flag early on when there is a performance decrease. To outline this, it would be necessary to make a directory of tests to be run for their performance, and then create the GitHub workflow to repeatedly run tests on that directory and aggregate the translation time. This can then be plotted graphically and statistically analysed.</p>
<h3 id="comparative-load-testing"><a class="header" href="#comparative-load-testing">Comparative Load Testing</a></h3>
<p>This is an extension of the above project, in that it cannot be created until there is a basis of load performance testing. The essential outline of this project is to repeat the above, except aggregating the data from the results of Savile Row’s rewriter, and then graph both Conjure-Oxide and Conjure suite together. This will allow for a direct visual comparison, as well as help with statistical analysis. Furthermore, if GitHub Actions are used, it is possible to flag where there is a large degree of difference in rewriter or solver between Conjure suite and Conjure-Oxide.</p>
<h3 id="benchmark-testing-for-performance"><a class="header" href="#benchmark-testing-for-performance">Benchmark Testing for Performance</a></h3>
<p>Another sub-project which is possible to derive from this document is to benchmark test elements of the project which cannot be done by varied-load testing, as outlined in the Performance Testing section. Tools, such as Perf, can measure benchmarks and find specific problem areas. When problem areas have been found, these can be raised as an issue, and either fixed as part of this sub-project, or given to another member of the project to complete. This kind of benchmark testing will ensure that the entirety of the Conjure-Oxide is running as efficiently as possible.</p>
<h3 id="possible-stress-testing"><a class="header" href="#possible-stress-testing">Possible Stress Testing</a></h3>
<p>There is also the possibility of adding stress testing to see at which point the rewrite engine fails to be able to parse through an extremely long or especially complex model. This can be done following much the same outline as that of \textit{Measuring Performance Through Load Testing}, however rather than gradually changing the load (dictated by size or complexity) on the system, the change is rapid, in order to find the system’s point of failure. As with load testing, this may also be automated by GitHub Actions, though this is a lower priority, as the failure point is less likely to change than the overall system performance.</p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>This document outlines definitions relevant for understanding both the project and the types of testing most applicable. A scenario of testing is then produced, which outlines what testing exists and what testing can be added, as well as any large limitations on an implementation of this ideal state. This allows for any individuals working on testing in the future to have a holistic overview of the state of testing on this project. Finally, a number of smaller sub-projects are outlined as a product of this document, aiming to improve the tested-ness of Conjure-Oxide and compare its success as a reimplementation to Conjure and Savile Row.
In the future, it may also be worth examining the possibility and likelihood of being able to apply Metamorphic testing to Conjure-Oxide, to ensure consistency in it’s results by developing metamorphic relations between input and output. At present, this is not feasible, and although this document is idealised, it is not intended to be entirely unreasonable or detached from the current reality of the project.</p>
<hr>
<p><em>This section had been taken from the ‘Ideal Scenario of Testing (Dec 2024)’ page of the conjure-oxide wiki</em></p>
<hr>
<ol class="footnote-definition">
<li id="footnote-1-1">
<p>Ian P. Gent, Chris Jefferson, and Ian Miguel. 2006. MINION: A Fast, Scalable, Constraint Solver. In Proceedings of the 2006 conference on ECAI 2006: 17th European Conference on Artificial Intelligence August 29 – September 1, 2006, Riva del Garda, Italy. IOS Press, NLD, 98–102. <a href="#fr-1-1-1">↩</a></p>
</li>
<li id="footnote-2-1">
<p>Hussain, B. S. 2017. Model Selection and Testing for an Automated Constraint Modelling Toolchain; Thesis <a href="#fr-2-1-1">↩</a></p>
</li>
<li id="footnote-3-1">
<p>{Berg, J., Bogaerts, B., Nordström, J., Oertel, A., &amp; Vandesande, D. 2023. Certified Core-Guided MaxSAT Solving. \textit{Lecture Notes in Computer Science}, 1–22. https://doi.org/10.1007/978-3-031-38499-8_1 <a href="#fr-3-1-1">↩</a></p>
</li>
<li id="footnote-4-1">
<p>conjure-cp. 2024, April 3. Possible optimisation: Intern the UserName in Name · Issue #288 · conjure-cp/conjure-oxide. \textit{GitHub}. https://github.com/conjure-cp/conjure-oxide/issues/288 <a href="#fr-4-1-1">↩</a></p>
</li>
<li id="footnote-5-1">
<p>conjure-cp. 2024, April 3. Benchmark Visualizer: Conjure Native vs Oxide · Pull Request #291 · conjure-cp/conjure-oxide. GitHub. https://github.com/conjure-cp/conjure-oxide/pull/291 <a href="#fr-5-1-1">↩</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="overview-5"><a class="header" href="#overview-5">Overview</a></h1>
<p>Custom tests were created as a solution to the problem that integration tests do not allow for testing of error messages, which automatically return from the integration test method and therefore cannot be analyzed. The custom tests, however, work for both erroneous and non-erroneous code. Each test contains an input, a <code>run.sh</code> file to execute the test, and an expected standard output/error (or both) to compare against. Conjure Oxide is set up to automatically create and execute a test for each test folder in the <code>tests/custom </code>directory when <code>cargo test</code> is ran so to add a test case, all one must do is add a folder in the directory which contains the necessary components.</p>
<h1 id="how-to-add-a-test-case"><a class="header" href="#how-to-add-a-test-case">How to add a test case</a></h1>
<p>Adding a test case is simple. First add a folder with the test case name to the <code>tests/custom</code> directory. Tests can be organized within folders in the directory–only folders with a <code>run.sh</code> file will be treated as a test case. Within the test folder, add these components:</p>
<ol>
<li>
<p><code>run.sh</code> file: This will typically be in the format <code>conjure_oxide &lt;options&gt; &lt;command&gt;</code> with the command being <code>solve model.eprime</code> (assuming the input file is named <code>model.eprime</code>). The <code>conjure_oxide</code> executable path is added to the PATH environment variable, so the script can invoke <code>conjure_oxide</code> as a command (i.e., just by name, without the full path).</p>
<p>ex) <code>conjure_oxide --solver Minion --enable-native-parser solve model.eprime</code></p>
</li>
<li>
<p>input file: This file will be the Essence code that is inputted into Conjure Oxide. It can be named anything but be sure to reference it correctly in the <code>run.sh</code> file.</p>
<p>ex) <code>find x : bool</code></p>
</li>
<li>
<p><code>stdout.expected</code>/<code>stderr.expected</code>: These files will be what the output is compared against. They will also be what is overwritten if the test is run with <code>ACCEPT=true</code>. Avoid creating empty files: if there is no expected error from the input, do not create a <code>stderr.expected</code> file and if there is no output, do not create a <code>stdout.expected</code> file.</p>
</li>
</ol>
<p>The custom tests are run automatically when <code>cargo test</code> is run. You can run just the custom tests with <code>cargo test custom</code> and a specific test with <code>cargo test custom_&lt;test_path&gt;</code>. To overwrite the expected output/error with the actual output/error, run the tests with <code>ACCEPT=true</code>.</p>
<h1 id="code-structure"><a class="header" href="#code-structure">Code structure</a></h1>
<p>The code to run the custom tests is integrated into the <code>build.rs</code> file. Much like for the integration tests, the custom tests directory is traversed and a test is dynamically written at compile time for any folder containing a <code>run.sh</code> file. Tests are based on a custom test template (shown below) which calls the <code>custom_test</code> function (passing in the test folder path). They are written into a generated file, which is included at the bottom of the <code>custom_tests.rs</code> file (which contains the <code>custom_test</code> function).</p>
<pre><code>#[test]
fn {test_name}() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {{
    custom_test("{test_dir}")
}}
</code></pre>
<p>The <code>custom_test</code> function takes the test directory as a parameter. It adds the <code>conjure_oxide</code> executable to the PATH environment variable and runs the commands from the <code>run.sh</code> file, saving the produced output. It then overwrites the expected output and error if accept was set to true and compares the actual and expected outputs/errors if not. If either does not match, the expected and actual output are printed and the test fails. Otherwise, the test passes.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h1>
<!-- ## Contents
- [Recap: Uniplates and Biplates](#recap-uniplates-and-biplates)
- [Definition of Children](#definition-of-children)
- [Storing The Structure of Children](#storing-the-structure-of-children)
- [Uniplates and Biplates Using Structure Preserving Trees](#uniplates-and-biplates-using-structure-preserving-trees) -->
<p>Comments and discussion about this document can be found in issue <a href="https://github.com/conjure-cp/conjure-oxide/issues/261">#261</a>.</p>
<p>In <a href="https://github.com/conjure-cp/conjure-oxide/pull/180">#180</a> and <a href="https://github.com/conjure-cp/conjure-oxide/pull/259">#259</a> we implemented the basic Uniplate interface and a derive macro to automatically implement it for <code>enum</code> types. However, our current implementation is incorrect and problematic: we have defined children wrong; and our children list does not preserve structure, making more complex nested structures hard to recreate in the context function.</p>
<h2 id="recap-uniplates-and-biplates-1"><a class="header" href="#recap-uniplates-and-biplates-1">Recap: Uniplates and Biplates</a></h2>
<p><em>A quick recap of what we are trying to do - for details, see the <a href="https://hackage.haskell.org/package/uniplate">Uniplate Haskell docs</a>, our Github Issues, and the paper.</em></p>
<p>Uniplates are an easy way to perform recursion over complex recursive data types.</p>
<p>It is typically used with enums containing multiple variants, many of which may be different types.</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U
       | D [T]
</code></pre>
<p>With Uniplate, one can perform a map over this with very little or no boilerplate.</p>
<p>This is implemented with a single function <code>uniplate</code> that returns a <em>list of children</em> of the current object and a <em>context</em> function to rebuild the object from a list of children.</p>
<p>Biplates provide recursion over instances of type <code>T</code> within some other type <code>U</code>. They are implemented with a single function <code>biplate</code> of similar type to <code>uniplate</code> (returning <em>children</em> and a <em>context</em> function).</p>
<p>These functions are able to be implemented on any data type through macros making Uniplate operations boilerplate free.</p>
<h2 id="definition-of-children-1"><a class="header" href="#definition-of-children-1">Definition of Children</a></h2>
<p>We currently take <em>children of T</em> to mean <em>direct descendants of T inside T</em>. However, the correct definition of children is <em>maximal substructures of type T</em>.</p>
<p>For example, consider these Haskell types:</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U
       | D [T]

data U = E T T
       | F Integer
       | G [T] T
</code></pre>
<p>Our current implementation would define children as the following:</p>
<pre><code class="language-hs">children (A t1 _) = [t1]
children (B t1 t2) = [t1, t2]
children (C t1 u) = [t1]
children (D ts) = ts
</code></pre>
<p>However, the proper definition should support transitive children - i.e. T contains a U which contains a T:</p>
<pre><code class="language-hs">children (A t1 _) = [t1]
children (B t1 t2) = [t1, t2]
children (C t1 (E t2 t3)) = [t1,t2,t3]
children (C t1 (F _)) = [t1]
children (C t1 (G ts t3)) = [t1] ++ ts ++ [t3]
children (D ts) = ts
</code></pre>
<p>While a seemingly small difference, this complicates how we reconstruct a node from its children: we now need to create a context that takes a list of children and creates an arbitrarily deeply nested data structure containing multiple different types. In particular, the challenge is keeping track of which elements of the children list go into which fields of the enum we are creating.</p>
<p>We already had this problem dealing with children from lists, but a more general approach is needed.</p>
<h2 id="storing-the-structure-of-children-1"><a class="header" href="#storing-the-structure-of-children-1">Storing The Structure of Children</a></h2>
<p>How do we know which children go into which fields of the enum variant?</p>
<p>For example, consider this complicated instance of <code>T</code>:</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U 
       | D [T]

data U = E T T
       | F Integer
       | G [T] T

myT = C(D([t0,...,t5]),G([t6,...,t12],t13))
</code></pre>
<p>Its list of children is: <code>[t0,...,t13]</code>.</p>
<p>Try creating a function to recreate <code>myT</code> based on a new list of children. <em>Hint: it is difficult, and even more so in full generality!</em></p>
<p>If we instead consider children to be a tree, where each field in the original enum variant is its own branch, we get:</p>
<pre><code class="language-hs">data Tree A = Zero | One A | Many [(Tree A)]

myTChildren = 
  Many [(Many [One(t0),...,One(t5)]),      -- C([XXX], _) field 1 of C
        (Many [                            -- C([_],XXX)  field 2 of C
          (Many [One(t6),...,One(t12)]),   -- G([XXX],_)  field 2.1 of C
          (One  t13))]                     -- G([_],XXX)) field 2.2 of C
</code></pre>
<p>This captures, in a type-independent way, the following structural information:</p>
<ol>
<li><code>myT</code> has two fields.</li>
<li>The first field is a container of Ts.</li>
<li>The second field contains two inner fields: one is a container of Ts, one is a single T.</li>
</ol>
<p><strong>Representing non-recursive and primitive types</strong></p>
<p>Often primitive and non-recursive types are found in the middle of enum variants. How do we say <em>“we don’t care about this field, it does not contain a T”</em> with our <code>Tree</code> type? <code>Zero</code> can be used for this.</p>
<p>For example:</p>
<pre><code class="language-hs">data V = V1 V Integer W
       | V2 Integer

data W = W1 V V

myV = (V1 
        (V2 1) 
        1 
        (W1 
          (V2 2) 
          (V2 3)))

myVChildren = 
  (Many [
    (One v1),  -- V1(XXX,_,_)
    Zero,      -- V1(_,XXX,_) 
    (Many [    -- V1(_,_,XXX)
      (One v2),
      (One v3)
   ]))
</code></pre>
<p>This additionally encodes the information that the second field of <code>myV</code> has no Ts at all.</p>
<p>While this information isn’t too useful for finding or traversing over the target type, it means that the tree structure defines the structure of the target type completely: there are always the same number of tree branches as there are fields in the enum variant.</p>
<h2 id="uniplates-and-biplates-using-structure-preserving-trees-1"><a class="header" href="#uniplates-and-biplates-using-structure-preserving-trees-1">Uniplates and Biplates Using Structure Preserving Trees</a></h2>
<p>Recall that the <code>uniplate</code> function returns all <em>children</em> of a data structure alongside a <em>context</em> function that rebuilds the data structure using some new children.</p>
<p>To implement this, for each field in an enum variant, we need to ask the questions: <em>“how do we get the type <code>T</code>s in the type <code>U</code>”</em>, and <em>how can we rebuild this <code>U</code> based on some new children of type <code>T</code>?</em>.</p>
<p>This is just a <code>Biplate&lt;U,T&gt;</code>, which gives us the <em>type <code>T</code> children within a type <code>U</code></em> as well as a <em>context function to reconstruct the <code>U</code> from the <code>T</code></em>.</p>
<p>Therefore:</p>
<ul>
<li>
<p>We build the <em>children</em> tree by combining the children trees of all fields of the enum (such that each field’s children is a branch on the tree).</p>
</li>
<li>
<p>We build the <em>context</em> function by calling each fields context function on each branch of the input tree.</p>
</li>
</ul>
<p>This is effectively a recursive invocation of <code>Biplate</code>.</p>
<p>What happens when we reach a T? Under the normal definition, <code>Biplate&lt;T,T&gt;</code> would return its children. This is wrong - we want to return <code>T</code> here, not its children!</p>
<p>When <code>T == U</code> we need to change the definition of a Biplate: <strong><code>Biplate&lt;T,T&gt;</code> operates over the input structure, not its children.</strong></p>
<p>For our example AST:</p>
<pre><code class="language-hs">data T = A T [Integer]
       | B T T
       | C T U 
       | D [T]

data U = E T T
       | F Integer
       | G [T] T
</code></pre>
<p>Here are some Biplate and Uniplates and their resultant children trees:</p>
<ul>
<li>
<p><code>Biplate&lt;Integer,T&gt; 1</code> is <code>Zero</code>.</p>
</li>
<li>
<p><code>Uniplate&lt;T&gt; (A t [1,2,3])</code> is <code>(Many [Biplate&lt;T,T&gt; t ,Zero])</code>.</p>
<p>This evaluates to <code>(Many [(One t),Zero])</code></p>
</li>
<li>
<p><code>Biplate&lt;T,T&gt; t</code> is <code>One t</code>.</p>
</li>
<li>
<p><code>Biplate&lt;T,U&gt; (G ts t1)</code> is <code>(Many [Biplate&lt;T,[T]&gt; ts , Biplate&lt;T,T&gt; t ])</code>.</p>
<p>This evaluates to <code>(Many [(Many [(One t0),...(One tn)]),(One t)])</code></p>
</li>
<li>
<p><code>Uniplate&lt;T,T&gt; (C t (G ts t1))</code> is <code>(Many [Biplate&lt;T,T&gt; t, Biplate&lt;U,T&gt; (G ts t1))</code></p>
<p>This evaluates to <code>(Many [(One t), (Many [(Many [(One t0),...,(One tn)]), (One t)]))</code></p>
</li>
</ul>
<!-- vim: cc=100 spell
-->
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="sat-encoding-types"><a href="#sat-encoding-types" class="header">SAT Encoding Types</a></h1>
<h2 id="types-of-sat-encodings"><a class="header" href="#types-of-sat-encodings">Types of SAT Encodings</a></h2>
<p>There are three different types of SAT Encodings planned in conjure oxide. Of these, only Logarithmic Encodings have been implemented thus far. The three types are these:</p>
<ul>
<li>Direct Encodings</li>
<li>Logarithmic Encodings</li>
<li>Order Encodings</li>
</ul>
<p>Each type of encoding has pros and cons, and a different one may be selected based on the type of constraint problem.</p>
<h3 id="satint-expression"><a class="header" href="#satint-expression">SATInt Expression</a></h3>
<p>All encodings are stored using the same <code>SATInt</code> expression type. This expression type holds: an enum specifying the encoding, a bitvector of boolean expressions (these can be literals, variables, or complex operations), and the domain of the integer. This expression cannot be created through parsing and should only be created by SAT rules.</p>
<h3 id="logarithmic-encoding"><a class="header" href="#logarithmic-encoding">Logarithmic Encoding</a></h3>
<p>The base principle is quite simple: encode an integer as a bitvector. This allows us to represent integers as a series of boolean constraints – one for each bit.</p>
<p>For example, the integer ‘6’ can be represented in binary as ‘0110’. We can then represent this as (P = 0 ∨ 1, Q = 0 ∨ 1, R = 0 ∨ 1, S = 0 ∨ 1). The connection that is missing, however, is that this isn’t actually a representation of a constraint problem, but of a solution to a problem.</p>
<h3 id="direct-encoding"><a class="header" href="#direct-encoding">Direct Encoding</a></h3>
<p>Direct encodings are the most straightforward type of encoding - it involves creating a vector of boolean variables, one corresponding to each member of the domain. Only one of these variables can be true at a time, and it is the one corresponding to the value of the integer.</p>
<h3 id="order-encoding"><a class="header" href="#order-encoding">Order Encoding</a></h3>
<p>Order follows the same principle as direct encoding, but instead of each boolean variable ‘specifying’ a value in the way that direct encodings do, each bit specifies whether the integer corresponding to it is less than or equal to the integer variable’s value.</p>
<h3 id="why-have-multiple-types-of-encoding"><a class="header" href="#why-have-multiple-types-of-encoding">Why have multiple types of encoding?</a></h3>
<p>Only logarithmic encodings are currently implemented in conjure-oxide. We’re planning to include other encodings such as direct and order encodings. This is motivated by their potential advantages over the log encoding in some cases.</p>
<p>Direct encodings should perform well for equality-heavy constraints but may scale poorly with larger domains or inequalities. Logarithmic encodings are expected to handle inequalities more efficiently. Order encodings are often viewed as a compromise, potentially balancing these trade-offs.</p>
<h3 id="performance-comparison"><a class="header" href="#performance-comparison">Performance Comparison</a></h3>
<p>The choice of encoding significantly impacts performance depending on the constraint types used.</p>
<h4 id="direct-encoding-better-for-equality-and-disequality"><a class="header" href="#direct-encoding-better-for-equality-and-disequality">Direct Encoding: Better for Equality and Disequality</a></h4>
<p>Direct encoding excels in models dominated by <code>=</code> and <code>!=</code> constraints, such as graph coloring. It enables immediate unit propagation in the SAT solver, pruning values faster than bitwise reasoning.</p>
<p><strong>Example: Graph Coloring</strong></p>
<pre><code class="language-essence">find c1, c2, c3, c4, c5 : int(1..3)
such that
    c1 != c2, c1 != c3, c2 != c3, c2 != c4,
    c3 != c4, c3 != c5, c4 != c5
</code></pre>
<ul>
<li><strong>Direct:</strong> ~0.55s Rewriting / 0.001s Solving</li>
<li><strong>Log:</strong> ~1.61s Rewriting / 0.002s Solving</li>
</ul>
<h4 id="logarithmic-encoding-better-for-inequalities"><a class="header" href="#logarithmic-encoding-better-for-inequalities">Logarithmic Encoding: Better for Inequalities</a></h4>
<p>Logarithmic encoding is superior for arithmetic and inequalities (<code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>) over large or sparse domains. Binary bit-vectors result in a more compact representation and reduced overhead.</p>
<p><strong>Example: Sparse Domain with Inequalities</strong></p>
<pre><code class="language-essence">find x : int(1, 10, 20, 30, 40, 50)
such that x &gt; 10
</code></pre>
<ul>
<li><strong>Direct:</strong> ~1.24s Rewriting / 0.005s Solving</li>
<li><strong>Log:</strong> ~0.07s Rewriting / 0.000s Solving</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="rule-types"><a href="#rule-types" class="header">Rule Types</a></h1>
<h2 id="rule-sets-1"><a class="header" href="#rule-sets-1">Rule Sets</a></h2>
<p>While developing rule-based transformations for conjure oxide, it is useful to understand the structure of the rulesets and the <em>types</em> of rules that can be used in conjure oxide. Let us first look at how rules actually function, not programmatically, but in an abstract sense. An understanding of (and some experience of) functional programming is incredibly helpful<sup class="footnote-reference" id="fr-1-1-2"><a href="#footnote-1-2">1</a></sup>. Also useful is an understanding of the idea behind graph machines<sup class="footnote-reference" id="fr-2-1-2"><a href="#footnote-2-2">2</a></sup> and an understanding of the difference between function results and side effects<sup class="footnote-reference" id="fr-3-1-2"><a href="#footnote-3-2">3</a></sup>.</p>
<p>In conjure oxide, the rules are functions that take in the expression tree and the symbol table as arguments and return a function result<sup class="footnote-reference" id="fr-4-1-2"><a href="#footnote-4-2">4</a></sup>, meaning that the original expression tree and symbol table are only modified through side effects of <code>rule</code> functions<sup class="footnote-reference" id="fr-5-1-2"><a href="#footnote-5-2">5</a></sup>.</p>
<p>There are quite a few advantages to this system, including a few small quality-of-life things such as the ability to write more descriptive errors and to pattern match on function results. The most significant benefit, however, is the ability to express rules as functions that can do whatever they need to do as long as they return a failure or a success. This means that an application failure can be treated as a recoverable result rather than a crash.</p>
<p>Each function is self-contained<sup class="footnote-reference" id="fr-6-1-1"><a href="#footnote-6-1">6</a></sup>, meaning that the only things preserved are the initial symbol table and the expression, along with the result being passed along the call stack. The most significant benefit, however, is that this allows for code to be written in a way that enforces that errors are handled. This is quite useful in general because it means that the codebase can leverage Rust’s type system to eliminate edge cases everywhere.</p>
<p>The rule application is able to use this to avoid a situation where the rule engine fails unexpectedly and loses a large amount of work, or worse, a situation where a rule seems to have been applied and is visible in the trace but has not actually affected the tree because it failed<sup class="footnote-reference" id="fr-7-1"><a href="#footnote-7">7</a></sup>.</p>
<p>Now that we know how rules are called, we can move on to how the rules themselves are designed. Broadly, there are two categories that we can divide the rules into: <strong>Representation Rules</strong> and <strong>Transformation Rules</strong>. This is because, despite being applied in the same step in the process, they have different purposes from each other, but all rules of either type share a common goal.</p>
<h3 id="representation-rules"><a class="header" href="#representation-rules">Representation Rules</a></h3>
<p>Essence (which is the input language of conjure oxide) defines domains that are not present in the type systems of the different solvers’ input languages, meaning they need to be encoded in some way into the input languages. The encoding is done using <em>representation rules</em>.</p>
<p>Representation rules implement shared behaviour using a trait<sup class="footnote-reference" id="fr-8-1"><a href="#footnote-8">8</a></sup>. The representation rules must change Essence variables into the target solver’s input language while preserving all of the relevant information. To actually do this, write a struct that implements the relevant trait. The rule engine can then use this to encode unsupported decision variable types.</p>
<h3 id="transformation-rules"><a class="header" href="#transformation-rules">Transformation Rules</a></h3>
<p>After all of the variables in the symbol table have been encoded into the relevant types, the next thing to do is to convert all of the constraints in the conjure oxide AST into a form that has a one-to-one parallel with the input language of the target solver.</p>
<p>This done is using transformation rules, each of which is registered with a ‘priority’ and can then be used by the rule engine to convert the AST into a format that can be used by the solver adaptor.</p>
<hr>
<hr>
<ol class="footnote-definition">
<li id="footnote-1-2">
<p>Take a look at Graham Hutton’s <em>Programming in Haskell (2nd Ed)</em>, and Miran Lipovača’s <em>Learn You a Haskell for Great Good!</em> for a lighter read <a href="#fr-1-1-2">↩</a></p>
</li>
<li id="footnote-2-2">
<p>https://amelia.how/posts/the-gmachine-in-detail.html <a href="#fr-2-1-2">↩</a></p>
</li>
<li id="footnote-3-2">
<p>Read the section of this text on ‘Functional Rust’ <a href="#fr-3-1-2">↩</a></p>
</li>
<li id="footnote-4-2">
<p>In Rust, this is <code>std::Result&lt;T, E&gt;</code> <a href="#fr-4-1-2">↩</a></p>
</li>
<li id="footnote-5-2">
<p>Particularly nice in Rust due to the way it does ownership and error handling <a href="#fr-5-1-2">↩</a></p>
</li>
<li id="footnote-6-1">
<p>Extra memory is freed when the function exits <a href="#fr-6-1-1">↩</a></p>
</li>
<li id="footnote-7">
<p>Unless <code>unwrap</code> is used <a href="#fr-7-1">↩</a></p>
</li>
<li id="footnote-8">
<p>See project documentation <a href="#fr-8-1">↩</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="useful-links"><a class="header" href="#useful-links">Useful Links</a></h1>
<h2 id="api-documentation"><a class="header" href="#api-documentation">API Documentation</a></h2>
<ul>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_cp/index.html">conjure-cp</a></li>
</ul>
<!--- This link seems to be dead. Cannot find an equivalent on the docs --->
<!-- md-dead-link-check: off -->
<ul>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/tree_morph/index.html">tree-morph</a></li>
</ul>
 <!-- md-dead-link-check: on -->
<ul>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/minion_sys/index.html">minion-sys</a></li>
</ul>
<h3 id="internal-crates"><a class="header" href="#internal-crates">Internal crates</a></h3>
<p>The following crates are internal, and are re-exported by <code>conjure-cp</code>:</p>
<ul>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_cp_cli/index.html">conjure-cp-cli</a></li>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_cp_core/index.html">conjure-cp-core</a></li>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_cp_essence_macros/">conjure-cp-essence-macros</a></li>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_cp_essence_parser">conjure-cp-essence-parser</a></li>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_cp_rule_macros">conjure-cp-rule-macros</a></li>
<li><a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_cp_enum_compatibility_macro">conjure-cp-enum-compatibility-macro</a></li>
</ul>
<h2 id="code-coverage-1"><a class="header" href="#code-coverage-1">Code Coverage</a></h2>
<p>Code coverage reports can be found <a href="https://conjure-cp.github.io/conjure-oxide/coverage/main/">here</a>.</p>
<h2 id="miscellaneous"><a class="header" href="#miscellaneous">Miscellaneous</a></h2>
<ul>
<li><a href="https://conjure-cp.github.io/conjure-oxide/tools/essence-feature-usage-stats/">Essence feature usage stats</a></li>
<li><a href="https://conjure-cp.github.io/conjure-blocks/">Conjure blocks</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="essence-parser"><a class="header" href="#essence-parser">Essence Parser</a></h1>
<p>The parser converts incoming Essence programs in Conjure Oxide to the <a href="https://conjure-cp.github.io/conjure-oxide/docs/conjure_core/ast/struct.Model.html">Model Object</a> that the rule engine takes in. The relevant parts of the Model object are the SymbolTable and Expression objects. The symbol table is essentially a list of the variables and their corresponding domains. The Expression object is a recursive object that holds all the constraints of the problem, nested into one object. The parser has two main parts. The first is the <code>tree-sitter-essence</code> crate, which is a general Essence parser using the library tree-sitter. The second part is the <code>conjure-cp-essence-parser</code> crate which is Rust code that uses the grammar to parse Essence programs and convert them into the above-mentioned Model object.</p>
<h1 id="tree-sitter-grammar-1"><a class="header" href="#tree-sitter-grammar-1">Tree Sitter Grammar</a></h1>
<p><a href="https://tree-sitter.github.io/tree-sitter/">Tree-sitter</a> is a parsing library that creates concrete syntax trees from programs in various languages. It contains many languages already, but Essence is unfortunately not one of them. Therefore, the <a href="https://github.com/conjure-cp/conjure-oxide/tree/main/crates/tree-sitter-essence">tree-sitter-essence</a> crate contains a JavaScript grammar for Essence, which tree-sitter uses to create a parser. The parser is not specific to Conjure Oxide as the grammar merely describes the general Essence language, but it is used in and developed for Conjure Oxide so currently covers only parts of the Essence language that Conjure Oxide deals with and has tests written for. The grammar is based on <a href="https://conjure.readthedocs.io/en/latest/essence.html">this Essence documentation</a>.</p>
<h2 id="general-structure-1"><a class="header" href="#general-structure-1">General Structure</a></h2>
<p>At the top level, there can be either find statements, letting statements, or constraint statements. Find statements consist of the keyword <code>find</code>, one or more variables, and then a domain. Letting statements have the keyword <code>letting</code>, one or more variables, and an expression or domain to assign to those variables. Constraints contain the keyword <code>such that</code> and one or more logical or numerical expressions which include variables and constants.</p>
<h2 id="domains"><a class="header" href="#domains">Domains</a></h2>
<p>Domains in Essence specify the set of possible values that a variable can take. The grammar currently supports the following types of domains:</p>
<ul>
<li><strong><code>bool_domain</code></strong>: Boolean values (<code>bool</code>)</li>
<li><strong><code>int_domain</code></strong>: Integer values, which can be unbounded (<code>int</code>) or bounded by ranges (<code>int(1..10)</code>, <code>int(1..5, 10..15)</code>)</li>
<li><strong><code>tuple_domain</code></strong>: Tuples of multiple domains (<code>(int(1..5), bool)</code>)</li>
<li><strong><code>matrix_domain</code></strong>: Multi-dimensional arrays indexed by domains (<code>matrix indexed by [int(1..5)] of int(0..9)</code>)</li>
<li><strong><code>record_domain</code></strong>: Named records with typed fields (<code>record {x: int, y: bool}</code>)</li>
<li><strong><code>set_domain</code></strong>: Sets with optional size constraints (<code>set of int(1..10)</code>, <code>set (minSize 2, maxSize 5) of bool</code>)</li>
<li><strong><code>variable_domain</code></strong>: Domain references using identifiers, allowing domains to be parameterized or defined elsewhere</li>
</ul>
<h2 id="expression-hierarchy-1"><a class="header" href="#expression-hierarchy-1">Expression Hierarchy</a></h2>
<p>Expressions in the grammar are broken down into boolean expressions, comparison expressions, arithmetic expressions, and atoms. This separation helps enforce semantic constraints inherent to the language. For example, expressions like <code>x + 3 = y</code> are allowed because an arithmetic expression is permitted on either side of a comparison, but chained comparisons like <code>x = y = 3</code> are disallowed, since a comparison expression cannot itself contain another comparison expression as an operand. This also helps ensure the top-most expression in a constraint evaluates to a boolean (so <code>such that x + 3</code> wouldn’t be valid).</p>
<p>Atoms are the fundamental building blocks and represent constants, identifiers, and structured values (tuples, matrices, records, comprehensions, or slices). Atoms are separate from boolean and arithmetic expressions in the grammar hierarchy, though they can be used as operands in most expression contexts. This means a constraint like <code>such that y</code> would be valid syntactically even though <code>y</code> might be an integer - type checking happens at a later stage. List combining expressions are also separated into boolean and arithmetic variants for this reason (so <code>such that allDiff([a, b])</code> is valid but <code>such that min([a,b])</code> isn’t).</p>
<p>The precedence levels throughout the grammar are based on the Essence Prime operator precedence table found in Appendix B of the <a href="https://arxiv.org/pdf/2201.03472">Savile Row Manual</a>. This is important to ensure that nested or complicated expressions such as <code>(2*x) + (3*y) = 12</code> are parsed in the correct order, as this will determine the structure of the Expression object in the Model.</p>
<h2 id="limitations-of-the-tree-sitter-grammar"><a class="header" href="#limitations-of-the-tree-sitter-grammar">Limitations of the Tree-sitter Grammar</a></h2>
<h3 id="keyword-exclusion"><a class="header" href="#keyword-exclusion">Keyword Exclusion</a></h3>
<p>Currently, the grammar allows for any combination of letters, numbers, and underscores to be parsed as variable identifiers. This includes reserved keywords of the Essence language such as ‘find’ or ‘letting’. This is incorrect and such keywords shouldn’t be allowed as variables. Tree-sitter doesn’t support lookahead assertions or negative matches, so grammar rules cannot exclude specific patterns or words from identifier rules. Checking for keywords as variables happens during semantic checking (see Diagnostics section).</p>
<h3 id="error-detection"><a class="header" href="#error-detection">Error Detection</a></h3>
<p>Error detection from tree-sitter is unpredictable and can be confusing, as it simply creates ERROR nodes in the parse tree without detailed information about what was invalid. Similar errors will produce ERROR nodes in different places and impact the surrounding tree strucure in varying ways, depending on the context. More sophisticated error detection and messsaging has been implemented through Diagnostics.</p>
<h1 id="rust-parser-1"><a class="header" href="#rust-parser-1">Rust Parser</a></h1>
<p>This is the second part of the parser and is contained in the <a href="https://github.com/conjure-cp/conjure-oxide/tree/main/crates/conjure-cp-essence-parser">conjure-cp-essence-parser</a> crate. The primary function is <code>parse_essence_file_native</code>, shown below, which takes in the path to the input and the context and returns the Model or an error.</p>
<pre><code class="language-Rust">pub fn parse_essence_file_native(
    path: &amp;str,
    context: Arc&lt;RwLock&lt;Context&lt;'static&gt;&gt;&gt;,
) -&gt; Result&lt;Model, EssenceParseError&gt; {...}
</code></pre>
<p>Within that function, the source code is read from the input and the tree-sitter grammar is used to parse that code and produce a parse tree. From there, a Model object is created and the <code>SymbolTable</code> and <code>Expression</code> fields are populated by traversing and extracting information from the parse tree.</p>
<h2 id="general-structure-1-1"><a class="header" href="#general-structure-1-1">General Structure</a></h2>
<p>The top level nodes (children of the root node), are either extras (comments or language labels), find statements, letting statements, or constraints. Find and letting statements provide info that is added to the SymbolTable while constraints are added to the Expression.</p>
<p>The parser crate is organized into multiple modules, each handling a specific aspect of Essence parsing:</p>
<ul>
<li><strong><code>parse_model.rs</code></strong>: Entry point containing <code>parse_essence_file_native</code>. Handles top-level statement parsing (find, letting, constraints) and orchestrates the overall parsing process.</li>
<li><strong><code>expression.rs</code></strong>: Core expression parsing logic. Handles boolean expressions, comparisons, arithmetic operations, and dispatches to specialized parsers.</li>
<li><strong><code>atom.rs</code></strong>: Parses atomic expressions - constants, identifiers, tuples, matrices, records, set literals, and indexing/slicing operations.</li>
<li><strong><code>domain.rs</code></strong>: Domain parsing including integer domains (ranges), boolean domains, and matrix domains. Handles both ground domains (fully specified) and unresolved domains (containing references).</li>
<li><strong><code>find.rs</code></strong>: Parses find statements, extracting variable names and their domains for the symbol table.</li>
<li><strong><code>letting.rs</code></strong>: Parses letting statements, which can bind variables to either domains or expressions.</li>
<li><strong><code>comprehension.rs</code></strong>: Parses comprehensions, quantifiers (forAll, exists), and aggregate expressions (sum, product, min, max, etc.). This is a complex module handling generator expressions and nested quantification.</li>
<li><strong><code>abstract_literal.rs</code></strong>: Parses abstract literal structures like matrices, tuples, and records.</li>
</ul>
<h3 id="layered-dispatch-pattern"><a class="header" href="#layered-dispatch-pattern">Layered Dispatch Pattern</a></h3>
<p>The parser is designed with a hierarchical dispatch architecture where each module has a main entry point function that delegates to more specific functions based on the tree-sitter node type. This creates layers of abstraction:</p>
<ol>
<li><strong>Top-level dispatcher</strong>: Examines the node’s <code>kind()</code> to determine which category of parser to call (e.g., expression, domain, statement)</li>
<li><strong>Category-level parsers</strong>: Further dispatch to specialized functions based on the specific variant (e.g., <code>parse_binary_expression</code>, <code>parse_atom</code>, <code>parse_int_domain</code>)</li>
<li><strong>Specialized parsers</strong>: Handle the actual parsing logic for specific node types</li>
</ol>
<p>This layered approach mirrors the structure of the tree-sitter grammar itself, where rules contain choices of subrules. This pattern keeps the codebase maintainable by separating concerns and making additions straightforward.</p>
<h3 id="general-utils"><a class="header" href="#general-utils">General utils</a></h3>
<p><code>kind()</code> is used to determine which rule a node represents and the corresponding function or logic is then applied to that node. Child nodes are found using their field names or indexes and the <code>named_children()</code> function is used to iterate over the named child nodes of a node. The function <code>child_expr</code> returns the Expression parsed from the first named child of the given node.</p>
<h3 id="extracting-from-the-source-code-identifiers-and-constants-1"><a class="header" href="#extracting-from-the-source-code-identifiers-and-constants-1">Extracting from the source code (identifiers and constants)</a></h3>
<p>The tree-sitter nodes have a start and end byte indicating where the node corresponds to in the source code. For variable identifiers, constants, and operators, these bytes are necessary to extract the actual values from the source code.</p>
<p>For example, the following code appears in the <code>parse_find_statement</code> function and is used to extract the specific variable name from the source code, which is represented simply by a tree-sitter node (named <code>variable</code> in this case).</p>
<pre><code class="language-Rust">let variable_name = &amp;source_code[variable.start_byte()..variable.end_byte()];
</code></pre>
<p>Another example is when parsing expressions, the node representing the operator is not always ‘named’, meaning it is not its own rule in the grammar and rather specified directly in the rule (ex. <code>exponent: $ =&gt; seq($.arithmetic_expr, "**", $.arithmetic_expr)</code> (simplified)), or the operator one of multiple choices in a rule (ex. <code>mulitcative_op: $ =&gt; choice("*", "/", "%")</code>). In this situation, the same method as for the variable identifiers is used:</p>
<pre><code class="language-Rust">let op = constraint.child_by_field_name("operator").ok_or(format!(
        "Missing operator in expression {}",
        constraint.kind()
    ))?;
let op_type = &amp;source_code[op.start_byte()..op.end_byte()];
</code></pre>
<h2 id="find-and-letting-statements-1"><a class="header" href="#find-and-letting-statements-1">Find and Letting Statements</a></h2>
<p>Find and letting statements are parsed relatively intuitively. For find statements, the list of variables is iterated over and each is added to a hash map as the key. Then, the domain is parsed and added as the value for each variable it applies to. Once all variables and domains are parsed, the hash map is returned and the caller function iterates over it and adds each pair to the <code>SymbolTable</code>. For letting statements, a new <code>SymbolTable</code> is created. The variables are again iterated over and added to the table. Letting statements can either specify a domain or an expression for the variables so the type of node is checked and either parsed as an expression or domain before being added to the table. The <code>SymbolTable</code> is returned and the caller function adds it to the existing <code>SymbolTable</code> of the <code>Model</code>.</p>
<h2 id="ground-vs-unresolved-domains"><a class="header" href="#ground-vs-unresolved-domains">Ground vs Unresolved Domains</a></h2>
<p>The parser supports both <strong>ground domains</strong> (fully specified, e.g., <code>int(1..10)</code>) and <strong>unresolved domains</strong> (containing variable references, e.g., <code>int(1..n)</code>). For unresolved domains, the variable pointer must be retrieved from the existing <code>SymbolTable</code>, hich was described in the previous section. Unresolved domains are resolved during later stages of processing once all variables are known.</p>
<h2 id="constraints-2"><a class="header" href="#constraints-2">Constraints</a></h2>
<p>Adding constraints to the overall constraints <code>Expression</code> requires nesting <code>Expression</code> objects. Each constraint is parsed and then added to the model using the <code>add_constraints</code> function.</p>
<p>Following the layered dispatch pattern, expressions are organized into types (again mirroring the grammar):</p>
<ul>
<li><strong><code>parse_expression</code></strong> in <code>expression.rs</code>: The main entry point that dispatches to specialized parsers based on node type</li>
<li><strong><code>parse_binary_expression</code></strong>: Handles binary operations</li>
<li>** <code>parse_arithmetic_expression</code>**: Handles arithmetic operations</li>
<li>** <code>parse_comparison_expression</code>**: Handles comparison operations</li>
<li><strong><code>parse_atom</code></strong> in <code>atom.rs</code>: Handles atomic expressions</li>
<li><strong><code>parse_comprehension</code></strong> in <code>comprehension.rs</code>: Handles comprehensions, quantifiers, and aggregates</li>
</ul>
<h2 id="comprehensions-quantifiers-and-aggregates"><a class="header" href="#comprehensions-quantifiers-and-aggregates">Comprehensions, Quantifiers, and Aggregates</a></h2>
<p>Comprehensions are a significant feature in Essence that require special parsing logic beyond the standard node-to-expression pattern. They are parsed by the <code>comprehension.rs</code> module using the specialized <code>ComprehensionBuilder</code> type that manages the complex scoping rules inherent to comprehensions.</p>
<p>Comprehensions create their own scope with local variables (generators). The parsing process involves:</p>
<ol>
<li><strong>Creating a ComprehensionBuilder</strong>: Initialized with the parent symbol table</li>
<li><strong>Setting up scoped symbol tables</strong>: The builder creates two child symbol tables:
<ul>
<li><strong>Generator symbol table</strong>: Contains generator variables as regular variables (for parsing conditions)</li>
<li><strong>Return expression symbol table</strong>: Contains generator variables as “givens” (for parsing the return expression)</li>
</ul>
</li>
<li><strong>Parsing generators</strong>: Each generator (<code>var : domain</code> or <code>var &lt;- collection</code>) is parsed and added to both symbol tables</li>
<li><strong>Parsing conditions</strong>: Conditions are parsed using the generator symbol table, allowing them to reference generator variables</li>
<li><strong>Parsing the return expression</strong>: Parsed using the return expression symbol table where generators appear as givens</li>
<li><strong>Building the comprehension</strong>: The builder combines all components into a <code>Comprehension</code> object</li>
</ol>
<p>Example: For <code>[x + 1 | x : int(1..5), x &gt; 2]</code>:</p>
<ul>
<li>Generator <code>x : int(1..5)</code> is added to both symbol tables</li>
<li>Condition <code>x &gt; 2</code> is parsed with <code>x</code> in scope as a variable</li>
<li>Return expression <code>x + 1</code> is parsed with <code>x</code> in scope as a given</li>
<li>The result is wrapped in a <code>Comprehension</code> expression</li>
</ul>
<h3 id="quantifiers-and-aggregates"><a class="header" href="#quantifiers-and-aggregates">Quantifiers and Aggregates</a></h3>
<p>Quantifier expressions (<code>forAll</code>, <code>exists</code>) and aggregate expressions (<code>sum</code>, <code>min</code>, <code>max</code>) follow the same comprehension-based parsing approach through <code>parse_quantifier_or_aggregate_expr</code>. They:</p>
<ol>
<li>Use <code>ComprehensionBuilder</code> to set up scoped symbol tables</li>
<li>Parse generators to add variables to the scope</li>
<li>Parse the body expression using the return expression symbol table</li>
<li>Build a comprehension with an appropriate AC operator kind (<code>And</code> for <code>forAll</code>, <code>Sum</code> for <code>sum</code>, etc.)</li>
<li>Wrap the comprehension in the corresponding expression type (<code>Expression::And</code>, <code>Expression::Sum</code>, etc.)</li>
</ol>
<p>This unified approach ensures consistent scoping behavior across all comprehension-style constructs in Essence.</p>
<h1 id="testing"><a class="header" href="#testing">Testing</a></h1>
<h2 id="integration-testing"><a class="header" href="#integration-testing">Integration Testing</a></h2>
<p>The native parser (<code>parse_essence_file_native</code>) is used by default for all integration tests in the <code>tests-integration</code> crate, which include a range of tests for every feature currently supported. Also incuded in the integraiton testing suite is roundtrip testing. Some of the roundtrip tests test the parser’s error messages.</p>
<p>To explicitly disable the native parser for a specific test, add a <code>config.toml</code> file in the test directory with:</p>
<pre><code class="language-toml">enable_native_parser = false
</code></pre>
<p>This will cause the test to fall back to the legacy parser instead.</p>
<h2 id="parser-specific-tests"><a class="header" href="#parser-specific-tests">Parser-Specific Tests</a></h2>
<p>The <code>conjure-cp-essence-parser</code> crate contains its own unit tests that specifically test parser functionality. These tests can be run with:</p>
<pre><code class="language-bash">cargo test -p conjure-cp-essence-parser
</code></pre>
<p>For more details on parser testing, see the parser testing documentation.</p>
<div style="break-before: page; page-break-before: always;"></div>
<p><strong>CST</strong> - Concrete Syntax Tree. Generated by the tree-sitter parser when parsing an essence file.</p>
<p><strong>AST</strong> - Abstract Syntax Tree. Generated when the CST is parsed and Model struct is created.</p>
<h1 id="syntax-errors-1"><a class="header" href="#syntax-errors-1">Syntax Errors</a></h1>
<p>Surface level mistakes in the Essence format.
Lead to an invalid CST. They are caught by the tree-sitter when an Essence expression does not match any rules in the current <a href="https://github.com/conjure-cp/conjure-oxide/blob/main/crates/tree-sitter-essence/grammar.js">grammar</a> and cause the CST to have <code>ERROR</code> nodes.</p>
<p>Detected by inspecting and contextualising the CST.</p>
<h2 id="1-missing-token"><a class="header" href="#1-missing-token">1. Missing Token</a></h2>
<h3 id="description"><a class="header" href="#description">Description:</a></h3>
<p>Expected token is absent.</p>
<h3 id="detection"><a class="header" href="#detection">Detection:</a></h3>
<p><code>MISSING</code> node inserted or zero range node in the CST.</p>
<h3 id="example-1-missing-identifiers"><a class="header" href="#example-1-missing-identifiers">Example 1: Missing identifier(s)</a></h3>
<pre><code class="language-text">find: bool
</code></pre>
<h3 id="example-2-missing-right-operand"><a class="header" href="#example-2-missing-right-operand">Example 2: Missing right operand</a></h3>
<pre><code class="language-text">find x: int
such that x /
</code></pre>
<h3 id="example-3-missing-domain-in-tuple"><a class="header" href="#example-3-missing-domain-in-tuple">Example 3: Missing domain in tuple</a></h3>
<pre><code class="language-text">find x: tuple()
</code></pre>
<h2 id="2-unexpected-token"><a class="header" href="#2-unexpected-token">2. Unexpected Token</a></h2>
<h3 id="description-1"><a class="header" href="#description-1">Description:</a></h3>
<p>Symbol(s) that are not supposed to be there according to the grammar rule tree-sitter is matching. Can be tokens belonging to the grammar or any foreign symbols.</p>
<h3 id="detection-1"><a class="header" href="#detection-1">Detection:</a></h3>
<p><code>ERROR</code> node wrapping the unexpected symbol(s).</p>
<h3 id="example-1-extra--at-the-end"><a class="header" href="#example-1-extra--at-the-end">Example 1: Extra <code>)</code> at the end</a></h3>
<pre><code class="language-text">find x: int(1..2))
</code></pre>
<h3 id="example-2-unexpected--in-implication"><a class="header" href="#example-2-unexpected--in-implication">Example 2: Unexpected <code>%</code> in implication</a></h3>
<pre><code class="language-text">find x: int(1..3)
such that x -&gt; %9
</code></pre>
<h3 id="example-3-unexpected--inside-matrix-domain"><a class="header" href="#example-3-unexpected--inside-matrix-domain">Example 3: Unexpected <code>&amp;</code> inside matrix domain</a></h3>
<pre><code class="language-text">find x: matrix indexed by [int, &amp;] of int
</code></pre>
<h2 id="3-malformed-top-level-statement"><a class="header" href="#3-malformed-top-level-statement">3. Malformed Top Level Statement</a></h2>
<h3 id="description-2"><a class="header" href="#description-2">Description:</a></h3>
<p>A line that cannot be parsed by the tree-sitter using any of the grammar rules.</p>
<h3 id="detection-2"><a class="header" href="#detection-2">Detection:</a></h3>
<p><code>ERROR</code> node that is a direct child of the root node <code>program</code> and precedes the nodes if the parsed line.</p>
<h3 id="example-1-invalid-print-x"><a class="header" href="#example-1-invalid-print-x">Example 1: Invalid <code>print x</code></a></h3>
<pre><code class="language-text">find x: int(1..5)
print x 
</code></pre>
<h3 id="example-2-malformed-find-statement"><a class="header" href="#example-2-malformed-find-statement">Example 2: Malformed find statement</a></h3>
<p>More of an edge case. Even though the keyword <code>find</code> is present, tree-sitter does not parse the line using the <code>find_statement</code> rule since the first symbol after <code>find</code> cannot be parsed an an identifier.</p>
<pre><code class="language-text">find +,a,b: int(1..3)
</code></pre>
<h3 id="4-general-syntax-error"><a class="header" href="#4-general-syntax-error">4. General Syntax Error</a></h3>
<p>Cases that cause an error in the CST but did not fall into any of the previous categories.</p>
<h1 id="semantic-errors-1"><a class="header" href="#semantic-errors-1">Semantic Errors</a></h1>
<p>These errors concern the logical context of an expression rather than its surface-level formatting. As a result, the expression may conform to the grammar and produce a valid CST, but still fail to parse into a valid AST. Such errors are detected during the phase that converts the CST into a <code>Model</code> struct.</p>
<h2 id="1-keywords-as-identifiers-1"><a class="header" href="#1-keywords-as-identifiers-1">1. Keywords as Identifiers</a></h2>
<h3 id="description-3"><a class="header" href="#description-3">Description:</a></h3>
<p>Using grammar keywords (e.g <code>find</code>, <code>bool</code>) as a variable name.</p>
<h3 id="detection-3"><a class="header" href="#detection-3">Detection:</a></h3>
<p>Compare the variable names against the set of keywords that should not be allowed.</p>
<h3 id="example-1-keyword-bool-as-an-identifier"><a class="header" href="#example-1-keyword-bool-as-an-identifier">Example 1: Keyword <code>bool</code> as an identifier.</a></h3>
<pre><code class="language-text">find bool: bool
</code></pre>
<h3 id="example-2-keyword-letting-used-as-an-identifier"><a class="header" href="#example-2-keyword-letting-used-as-an-identifier">Example 2: Keyword <code>letting</code> used as an identifier.</a></h3>
<pre><code class="language-text">find letting,b,c: int(1..3)
</code></pre>
<h2 id="2-omitted-declaration-1"><a class="header" href="#2-omitted-declaration-1">2. Omitted Declaration</a></h2>
<h3 id="description-4"><a class="header" href="#description-4">Description:</a></h3>
<p>Variable used but not declared.</p>
<h3 id="detection-4"><a class="header" href="#detection-4">Detection:</a></h3>
<p>Checking that the identifier used in a constraint was previsouly declared in a <code>find</code> or <code>letting_statement</code>.</p>
<h3 id="example-x-was-not-declared-before"><a class="header" href="#example-x-was-not-declared-before">Example: x was not declared before</a></h3>
<pre><code class="language-text">find y: int (1..4)
such that x = 5
</code></pre>
<h2 id="3-invalid-domain-1"><a class="header" href="#3-invalid-domain-1">3. Invalid Domain</a></h2>
<p>(not yet supported)</p>
<h3 id="description-5"><a class="header" href="#description-5">Description:</a></h3>
<p>Logically or mathematically invalid bounds.</p>
<h3 id="example-a-bigger-value-before-smaller"><a class="header" href="#example-a-bigger-value-before-smaller">Example: a bigger value before smaller</a></h3>
<pre><code class="language-text">find x: int(10..5)
</code></pre>
<h2 id="4-type-mismatch-1"><a class="header" href="#4-type-mismatch-1">4. Type Mismatch</a></h2>
<h3 id="description-6"><a class="header" href="#description-6">Description:</a></h3>
<p>Attempt to do an operation on illegal types.</p>
<h3 id="detection-5"><a class="header" href="#detection-5">Detection:</a></h3>
<p>Enforcing types on operations and catching a mismatch between expected types and node <code>kind</code> that is being parsed.</p>
<h3 id="example-adding-an-integer-and-boolean"><a class="header" href="#example-adding-an-integer-and-boolean">Example: Adding an integer and boolean.</a></h3>
<pre><code class="language-text">letting y be true 
find x: int (5..10)
such that 5 + y = 6
</code></pre>
<h2 id="5-unsafe-division-1"><a class="header" href="#5-unsafe-division-1">5. Unsafe division</a></h2>
<p>(not yet implemented)</p>
<h3 id="description-7"><a class="header" href="#description-7">Description:</a></h3>
<p>Attempt to divide/modulo by zero.</p>
<h3 id="example-divide-by-zero"><a class="header" href="#example-divide-by-zero">Example: Divide by zero</a></h3>
<pre><code class="language-text">find x: int(5..10)
such that x/0 = 3
</code></pre>
<p>At the moment says no solutions found. Would want to explicitly disallow it.</p>
<h2 id="6-invalid-indexing"><a class="header" href="#6-invalid-indexing">6. Invalid indexing</a></h2>
<h3 id="description-8"><a class="header" href="#description-8">Description:</a></h3>
<p>Tuples and matrices are indexed from 1.
Negative, zero or index out of bounds is invalid.</p>
<h3 id="example-s-tuple-index-of-out-bounds"><a class="header" href="#example-s-tuple-index-of-out-bounds">Example: s tuple index of out bounds.</a></h3>
<pre><code class="language-text">letting s be tuple(0,1,1,0)
letting t be tuple(0,0,0,1)
find a : bool such that a = (s[5] = t[1]) $ true
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!--
author: Nadine Martin
last updated: 21-12-2025
-->
<h1 id="conjure-blocks"><a class="header" href="#conjure-blocks">Conjure Blocks</a></h1>
<p><img src="images/conjure_blocks.png" alt="Conjure Blocks website"></p>
<p>Conjure blocks is an online block editor for Essence. This tool allows you to write constraint programs in blocks, which are then translated into Essence. <a href="https://conjure-aas.cs.st-andrews.ac.uk/">Conjure-aaS</a> is used to solve these problems. Conjure blocks is an ongoing project.</p>
<p>See the <a href="https://github.com/conjure-cp/conjure-blocks">the Conjure Blocks repository</a>, and <a href="https://conjure-cp.github.io/conjure-blocks/">live site</a> for more information.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="for-interested-students"><a class="header" href="#for-interested-students">For Interested Students</a></h1>
<p>This project is developed as part of the “Artificial Intelligence for Decision
Making” Vertically Integrated Project module. For more information on the VIP, <a href="https://ozgurakgun.github.io/vip">click here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="contributors"><a class="header" href="#contributors">Contributors</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>


    </div>
    </body>
</html>
